[2025-04-06 11:23:20,710] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/wuzongqian/anaconda/envs/llava_crc/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()

Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]

  0%|          | 0/336 [00:00<?, ?it/s]
  0%|          | 1/336 [00:05<32:43,  5.86s/it]
  1%|          | 2/336 [00:10<28:48,  5.18s/it]
  1%|          | 3/336 [00:15<28:11,  5.08s/it]
  1%|          | 4/336 [00:20<27:32,  4.98s/it]
  1%|▏         | 5/336 [00:25<27:09,  4.92s/it]
  2%|▏         | 6/336 [00:30<27:57,  5.08s/it]
  2%|▏         | 7/336 [00:35<27:17,  4.98s/it]
  2%|▏         | 8/336 [00:40<26:55,  4.92s/it]
  3%|▎         | 9/336 [00:45<27:45,  5.09s/it]
  3%|▎         | 10/336 [00:50<27:45,  5.11s/it]
  3%|▎         | 11/336 [00:53<23:56,  4.42s/it]multi_responses: ['no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.2189, -0.5184, -0.2189, -0.2189, -0.2189, -0.5184, -0.2189, -0.5184,
        -0.2189, -0.2189])
regular_entropy: 0.308772474527359
regular_entropy_rao: 2.1572651863098145
semantic_ids: [0, 1, 0, 0, 0, 1, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2759), tensor(-1.4226)]
semantic_entropy: 0.8492448329925537
log_probs: tensor([-0.2759, -1.4226])
semantic_entropy_rao: 0.5523196458816528
cur_prompt: Is a python code shown in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes']
log_probs: tensor([-0.0680, -0.0680, -0.0680, -0.0680, -0.0680, -1.0315, -0.0680, -0.0680,
        -0.0680, -1.0315])
regular_entropy: 0.26066046953201294
regular_entropy_rao: 1.2433066368103027
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 0, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0911), tensor(-2.4409)]
semantic_entropy: 1.2660236358642578
log_probs: tensor([-0.0911, -2.4409])
semantic_entropy_rao: 0.2957267761230469
cur_prompt: Is a c++ code shown in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.5702, -0.5702, -0.1926, -0.5702, -0.1926, -0.1926, -0.1926, -0.5702,
        -0.1926, -0.1926])
regular_entropy: 0.3436431884765625
regular_entropy_rao: 2.2427573204040527
semantic_ids: [0, 0, 1, 0, 1, 1, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.1594), tensor(-0.3764)]
semantic_entropy: 0.7679147720336914
log_probs: tensor([-1.1594, -0.3764])
semantic_entropy_rao: 0.6219969391822815
cur_prompt: The image shows a python code. Is the output of the code '7'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2331, -0.4935, -0.2331, -0.4935, -0.2331, -0.2331, -0.2331, -0.2331,
        -0.2331, -0.2331])
regular_entropy: 0.2852148413658142
regular_entropy_rao: 2.0797927379608154
semantic_ids: [0, 1, 0, 1, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1762), tensor(-1.8229)]
semantic_entropy: 0.9995602965354919
log_probs: tensor([-0.1762, -1.8229])
semantic_entropy_rao: 0.4422377943992615
cur_prompt: The image shows a python code. Is the output of the code '1'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.3151, -0.3802, -0.3151, -0.3802, -0.3151, -0.3151, -0.3151, -0.3802,
        -0.3802, -0.3151])
regular_entropy: 0.34112226963043213
regular_entropy_rao: 2.419325113296509
semantic_ids: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.4853), tensor(-0.9559)]
semantic_entropy: 0.7205746173858643
log_probs: tensor([-0.4853, -0.9559])
semantic_entropy_rao: 0.6662154793739319
cur_prompt: The image shows a python code. Is the output of the code 'a cat'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.5881, -0.1844, -0.1844, -0.5881, -0.1844, -0.1844, -0.1844, -0.1844,
        -0.1844, -0.1844])
regular_entropy: 0.2651522159576416
regular_entropy_rao: 1.880130648612976
semantic_ids: [0, 1, 1, 0, 1, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-1.9444), tensor(-0.1544)]
semantic_entropy: 1.0493812561035156
log_probs: tensor([-1.9444, -0.1544])
semantic_entropy_rao: 0.4105154871940613
cur_prompt: The image shows a python code. Is the output of the code 'a dog'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no']
log_probs: tensor([-0.2430, -0.2430, -0.2430, -0.2430, -0.4774, -0.2430, -0.2430, -0.4774,
        -0.2430, -0.4774])
regular_entropy: 0.3133077025413513
regular_entropy_rao: 2.2225255966186523
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 1, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2919), tensor(-1.3736)]
semantic_entropy: 0.8327803611755371
log_probs: tensor([-0.2919, -1.3736])
semantic_entropy_rao: 0.5658121705055237
cur_prompt: The image shows a python code. Is the output of the code '36'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.7816, -0.1175, -0.1175, -0.1175, -0.1175, -0.1175, -0.1175, -0.1175,
        -0.7816, -0.1175])
regular_entropy: 0.25033825635910034
regular_entropy_rao: 1.5513859987258911
semantic_ids: [0, 1, 1, 1, 1, 1, 1, 1, 0, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-2.1714), tensor(-0.1211)]
semantic_entropy: 1.1462352275848389
log_probs: tensor([-2.1714, -0.1211])
semantic_entropy_rao: 0.3548309803009033
cur_prompt: The image shows a python code. Is the output of the code '6'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.5881, -0.1844, -0.5881, -0.5881, -0.1844, -0.1844, -0.5881, -0.5881,
        -0.1844, -0.1844])
regular_entropy: 0.3862459659576416
regular_entropy_rao: 2.3998794555664062
semantic_ids: [0, 1, 0, 0, 1, 1, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.9152), tensor(-0.5116)]
semantic_entropy: 0.713376522064209
log_probs: tensor([-0.9152, -0.5116])
semantic_entropy_rao: 0.6731882095336914
cur_prompt: The image shows a python code. Is the output of the code '12'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.2430, -0.4774, -0.4774, -0.4774, -0.2430, -0.2430, -0.4774, -0.2430,
        -0.4774, -0.4774])
regular_entropy: 0.3836202025413513
regular_entropy_rao: 2.539299964904785
semantic_ids: [0, 1, 1, 1, 0, 0, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.7823), tensor(-0.6113)]
semantic_entropy: 0.6968016624450684
log_probs: tensor([-0.7823, -0.6113])
semantic_entropy_rao: 0.6895015239715576
cur_prompt: The image shows a python code. Is the output of the code '5'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0559, -0.0559, -0.0559, -0.0559, -0.0559, -1.1236, -0.0559, -0.0559,
        -0.0559, -0.0559])
regular_entropy: 0.1626288741827011
regular_entropy_rao: 0.8407025337219238
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0375), tensor(-3.3024)]
semantic_entropy: 1.669954776763916
log_probs: tensor([-0.0375, -3.3024])
semantic_entropy_rao: 0.15761788189411163
cur_prompt: Is a c++ code shown in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0494, -0.0494, -0.0494, -0.0494, -1.1822, -0.0494, -0.0494, -0.0494,
        -0.0494, -0.0494])
regular_entropy: 0.16264484822750092
regular_entropy_rao: 0.7853418588638306

  4%|▎         | 12/336 [00:56<21:14,  3.93s/it]
  4%|▍         | 13/336 [01:01<23:34,  4.38s/it]
  4%|▍         | 14/336 [01:07<25:02,  4.67s/it]
  4%|▍         | 15/336 [01:11<24:39,  4.61s/it]
  5%|▍         | 16/336 [01:22<34:40,  6.50s/it]
  5%|▌         | 17/336 [01:26<30:03,  5.65s/it]
  5%|▌         | 18/336 [01:32<30:11,  5.70s/it]
  6%|▌         | 19/336 [01:37<29:15,  5.54s/it]
  6%|▌         | 20/336 [01:42<28:17,  5.37s/it]
  6%|▋         | 21/336 [01:45<24:38,  4.69s/it]
  7%|▋         | 22/336 [01:48<22:02,  4.21s/it]semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0352), tensor(-3.3652)]
semantic_entropy: 1.7001848220825195
log_probs: tensor([-0.0352, -3.3652])
semantic_entropy_rao: 0.1502356231212616
cur_prompt: Is a python code shown in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2380, -0.4854, -0.2380, -0.4854, -0.4854, -0.4854, -0.2380, -0.2380,
        -0.2380, -0.2380])
regular_entropy: 0.33698171377182007
regular_entropy_rao: 2.3206212520599365
semantic_ids: [0, 1, 0, 1, 1, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.4191), tensor(-1.0719)]
semantic_entropy: 0.7455055713653564
log_probs: tensor([-0.4191, -1.0719])
semantic_entropy_rao: 0.642578661441803
cur_prompt: The image shows a python code. Is the output of the code '11'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.2914, -0.2914, -0.2914, -0.4086, -0.2914, -0.2914, -0.4086, -0.4086,
        -0.4086, -0.4086])
regular_entropy: 0.34999901056289673
regular_entropy_rao: 2.4464316368103027
semantic_ids: [0, 0, 0, 1, 0, 0, 1, 1, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.6363), tensor(-0.7535)]
semantic_entropy: 0.6948626041412354
log_probs: tensor([-0.6363, -0.7535])
semantic_entropy_rao: 0.6914334297180176
cur_prompt: The image shows a python code. Is the output of the code '9'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.0907, -0.0907, -0.0907, -0.0907, -0.0907, -0.0907, -0.0907, -0.0907,
        -0.0907, -0.8980])
regular_entropy: 0.17146238684654236
regular_entropy_rao: 1.1115999221801758
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0484), tensor(-3.0529)]
semantic_entropy: 1.5506315231323242
log_probs: tensor([-0.0484, -3.0529])
semantic_entropy_rao: 0.19025388360023499
cur_prompt: The image shows a python code. Is the output of the code 'the list has more than 2 numbers'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.1122, -0.1122, -0.1122, -0.1122, -0.1122, -0.1122, -0.1122, -0.1122,
        -0.1122, -0.8023])
regular_entropy: 0.18119242787361145
regular_entropy_rao: 1.2621630430221558
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0542), tensor(-2.9416)]
semantic_entropy: 1.4978924989700317
log_probs: tensor([-0.0542, -2.9416])
semantic_entropy_rao: 0.20663070678710938
cur_prompt: The image shows a python code. Is the output of the code 'the list has less than 2 numbers'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331,
        -0.0331, -0.0331])
regular_entropy: 0.03308400884270668
regular_entropy_rao: 0.3200736939907074
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: The image shows a python code. Will the number 3 appear in the output of the code?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1804, -0.5971, -0.1804, -0.5971, -0.5971, -0.1804, -0.5971, -0.1804,
        -0.1804, -0.1804])
regular_entropy: 0.34710925817489624
regular_entropy_rao: 2.2185049057006836
semantic_ids: [0, 1, 0, 1, 1, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3643), tensor(-1.1864)]
semantic_entropy: 0.7753574848175049
log_probs: tensor([-0.3643, -1.1864])
semantic_entropy_rao: 0.6152973175048828
cur_prompt: The image shows a python code. Will the number 6 appear in the output of the code?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.1477, -0.1477, -0.1477, -0.1477, -0.1477, -0.1477, -0.6816, -0.6816,
        -0.1477, -0.6816])
regular_entropy: 0.3079055845737457
regular_entropy_rao: 1.9264655113220215
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 1, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2242), tensor(-1.6053)]
semantic_entropy: 0.9147499799728394
log_probs: tensor([-0.2242, -1.6053])
semantic_entropy_rao: 0.5015428066253662
cur_prompt: The image shows a python code. Is the output of the code 'working hard'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.1765, -0.6062, -0.1765, -0.1765, -0.1765, -0.1765, -0.1765, -0.6062,
        -0.1765, -0.1765])
regular_entropy: 0.26247188448905945
regular_entropy_rao: 1.84500253200531
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1507), tensor(-1.9667)]
semantic_entropy: 1.0587170124053955
log_probs: tensor([-0.1507, -1.9667])
semantic_entropy_rao: 0.4048123359680176
cur_prompt: The image shows a python code. Is the output of the code 'playing hard'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.3665, -0.3665, -0.3665, -0.3274, -0.3274, -0.3274, -0.3274, -0.3665,
        -0.3274, -0.3274])
regular_entropy: 0.343049019575119
regular_entropy_rao: 2.432143211364746
semantic_ids: [0, 0, 0, 1, 1, 1, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.9399), tensor(-0.4954)]
semantic_entropy: 0.7176470756530762
log_probs: tensor([-0.9399, -0.4954])
semantic_entropy_rao: 0.6690435409545898
cur_prompt: The image shows a python code. Is the output of the code 'a cat'?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.5269, -0.5269, -0.5269, -0.2144, -0.2144, -0.5269, -0.2144, -0.2144,
        -0.2144, -0.5269])
regular_entropy: 0.37060055136680603
regular_entropy_rao: 2.4203999042510986
semantic_ids: [0, 0, 0, 1, 1, 0, 1, 1, 1, 0]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.8616), tensor(-0.5491)]
semantic_entropy: 0.7053049206733704
log_probs: tensor([-0.8616, -0.5491])
semantic_entropy_rao: 0.6810876131057739
cur_prompt: The image shows a python code. Is the output of the code 'a dog'?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.1319, -0.1319, -0.1319, -0.1319, -0.7308, -0.7308, -0.1319, -0.7308,
        -0.1319, -0.1319])
regular_entropy: 0.3115702271461487
regular_entropy_rao: 1.8648220300674438
semantic_ids: [0, 0, 0, 0, 1, 1, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934

  7%|▋         | 23/336 [01:51<20:13,  3.88s/it]
  7%|▋         | 24/336 [01:54<18:55,  3.64s/it]
  7%|▋         | 25/336 [01:57<18:34,  3.58s/it]
  8%|▊         | 26/336 [02:01<18:13,  3.53s/it]
  8%|▊         | 27/336 [02:06<21:00,  4.08s/it]
  8%|▊         | 28/336 [02:11<22:07,  4.31s/it]
  9%|▊         | 29/336 [02:15<21:31,  4.21s/it]
  9%|▉         | 30/336 [02:19<20:36,  4.04s/it]
  9%|▉         | 31/336 [02:24<21:59,  4.33s/it]
 10%|▉         | 32/336 [02:29<22:50,  4.51s/it]
 10%|▉         | 33/336 [02:32<21:10,  4.19s/it]
 10%|█         | 34/336 [02:37<22:37,  4.49s/it]log_likelihood_per_semantic_id: [tensor(-0.2114), tensor(-1.6577)]
semantic_entropy: 0.9345635175704956
log_probs: tensor([-0.2114, -1.6577])
semantic_entropy_rao: 0.4870603382587433
cur_prompt: The image shows a python code. Is the output of the code '12'?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.2532, -0.2532, -0.2532, -0.2532, -0.2532, -0.4615, -0.2532, -0.4615,
        -0.2532, -0.2532])
regular_entropy: 0.2948470711708069
regular_entropy_rao: 2.154218912124634
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1848), tensor(-1.7794)]
semantic_entropy: 0.9821188449859619
log_probs: tensor([-0.1848, -1.7794])
semantic_entropy_rao: 0.4538732171058655
cur_prompt: The image shows a python code. Is the output of the code '5'?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001,
        -0.0001, -0.0001])
regular_entropy: 0.00011115030793007463
regular_entropy_rao: 0.0011113797081634402
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Does this artwork belong to the type of religious?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025,
        -0.0025, -0.0025])
regular_entropy: 0.002526623895391822
regular_entropy_rao: 0.02520248107612133
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Does this artwork belong to the type of historical?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes']
log_probs: tensor([-0.1260, -0.1260, -0.1260, -0.1260, -0.7510, -0.7510, -0.7510, -0.1260,
        -0.7510, -0.1260])
regular_entropy: 0.3759647309780121
regular_entropy_rao: 2.0838921070098877
semantic_ids: [0, 0, 0, 0, 1, 1, 1, 0, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3052), tensor(-1.3356)]
semantic_entropy: 0.8203915357589722
log_probs: tensor([-0.3052, -1.3356])
semantic_entropy_rao: 0.5761651396751404
cur_prompt: Is this artwork titled virgin and child with sts catherine, cecilia, barbara, and ursula?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes']
log_probs: tensor([-0.4615, -0.4615, -0.4615, -0.4615, -0.2532, -0.4615, -0.4615, -0.4615,
        -0.4615, -0.2532])
regular_entropy: 0.4198574125766754
regular_entropy_rao: 2.7203845977783203
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.2684), tensor(-1.4464)]
semantic_entropy: 0.8574075698852539
log_probs: tensor([-0.2684, -1.4464])
semantic_entropy_rao: 0.5457417964935303
cur_prompt: Is this artwork titled sorrow?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0071, -0.0071, -0.0071, -0.0071, -0.0071, -0.0071, -0.0071, -0.0071,
        -0.0071, -0.0071])
regular_entropy: 0.007119334302842617
regular_entropy_rao: 0.07068828493356705
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this artwork titled doge ziani receiving the benediction of pope alexander iii?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0601, -0.0601, -0.0601, -0.0601, -0.0601, -0.0601, -0.0601, -0.0601,
        -0.0601, -0.0601])
regular_entropy: 0.06013514846563339
regular_entropy_rao: 0.5662549138069153
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this artwork titled the adoration of the shepherds?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.4774, -0.2430, -0.2430, -0.2430, -0.4774, -0.4774, -0.2430, -0.4774,
        -0.2430, -0.2430])
regular_entropy: 0.33674511313438416
regular_entropy_rao: 2.3281168937683105
semantic_ids: [0, 1, 1, 1, 0, 0, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.0634), tensor(-0.4236)]
semantic_entropy: 0.7434716820716858
log_probs: tensor([-1.0634, -0.4236])
semantic_entropy_rao: 0.6444774270057678
cur_prompt: Is this artwork displayed in musée toulouse-lautrec, albi?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.2054, -0.2054, -0.5440, -0.2054, -0.5440, -0.2054, -0.2054, -0.2054,
        -0.5440, -0.2054])
regular_entropy: 0.30698680877685547
regular_entropy_rao: 2.118163585662842
semantic_ids: [0, 0, 1, 0, 1, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2666), tensor(-1.4524)]
semantic_entropy: 0.8594977259635925
log_probs: tensor([-0.2666, -1.4524])
semantic_entropy_rao: 0.5440692901611328
cur_prompt: Is this artwork displayed in kupferstichkabinett, gotha?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024,
        -0.0024, -0.0024])
regular_entropy: 0.0023956631775945425
regular_entropy_rao: 0.02389930747449398
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this artwork exist in the form of painting?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.1046, -0.1046, -0.8337, -0.1046, -0.1046, -0.8337, -0.1046, -0.1046,
        -0.8337, -0.1046])
regular_entropy: 0.3233226537704468
regular_entropy_rao: 1.745908498764038
semantic_ids: [0, 0, 1, 0, 0, 1, 0, 0, 1, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.1879), tensor(-1.7644)]
semantic_entropy: 0.9761258959770203
log_probs: tensor([-0.1879, -1.7644])
semantic_entropy_rao: 0.45793616771698
cur_prompt: Does this artwork exist in the form of stained-glass?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']

 10%|█         | 35/336 [02:40<20:17,  4.04s/it]
 11%|█         | 36/336 [02:47<23:27,  4.69s/it]
 11%|█         | 37/336 [02:50<21:29,  4.31s/it]
 11%|█▏        | 38/336 [02:55<22:38,  4.56s/it]
 12%|█▏        | 39/336 [02:58<20:14,  4.09s/it]
 12%|█▏        | 40/336 [03:02<19:19,  3.92s/it]
 12%|█▏        | 41/336 [03:07<20:55,  4.26s/it]
 12%|█▎        | 42/336 [03:12<21:49,  4.45s/it]
 13%|█▎        | 43/336 [03:17<22:31,  4.61s/it]
 13%|█▎        | 44/336 [03:20<21:26,  4.41s/it]
 13%|█▎        | 45/336 [03:24<19:49,  4.09s/it]
 14%|█▎        | 46/336 [03:29<20:58,  4.34s/it]log_probs: tensor([-0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020,
        -0.0020, -0.0020])
regular_entropy: 0.0020498281810432673
regular_entropy_rao: 0.020456308498978615
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(-2.9802e-07)]
semantic_entropy: 2.98023280720372e-07
log_probs: tensor([-2.9802e-07])
semantic_entropy_rao: 2.980231954552437e-07
cur_prompt: Does this artwork exist in the form of painting?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.3212, -0.3212, -0.3212, -0.3733, -0.3212, -0.3212, -0.3733, -0.3733,
        -0.3733, -0.3733])
regular_entropy: 0.34725144505500793
regular_entropy_rao: 2.4498140811920166
semantic_ids: [0, 0, 0, 1, 0, 0, 1, 1, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.6674), tensor(-0.7195)]
semantic_entropy: 0.6934863328933716
log_probs: tensor([-0.6674, -0.7195])
semantic_entropy_rao: 0.6928082704544067
cur_prompt: Does this artwork exist in the form of tapestry?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,
        -0.0004, -0.0004])
regular_entropy: 0.0003778698737733066
regular_entropy_rao: 0.0037772711366415024
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this artwork exist in the form of architecture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.4460, -0.2637, -0.2637, -0.2637, -0.2637, -0.2637, -0.2637, -0.4460,
        -0.4460, -0.4460])
regular_entropy: 0.3366064131259918
regular_entropy_rao: 2.3574793338775635
semantic_ids: [0, 1, 1, 1, 1, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.0296), tensor(-0.4418)]
semantic_entropy: 0.7357215285301208
log_probs: tensor([-1.0296, -0.4418])
semantic_entropy_rao: 0.6517605781555176
cur_prompt: Does this artwork exist in the form of metalwork?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,
        -0.0004, -0.0004])
regular_entropy: 0.0003587508399505168
regular_entropy_rao: 0.003586221020668745
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this artwork belong to the type of religious?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0243, -0.0243, -0.0243, -0.0243, -0.0243, -0.0243, -0.0243, -0.0243,
        -0.0243, -0.0243])
regular_entropy: 0.02429911494255066
regular_entropy_rao: 0.23715782165527344
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this artwork belong to the type of study?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes']
log_probs: tensor([-0.3401, -0.3531, -0.3401, -0.3531, -0.3401, -0.3531, -0.3401, -0.3401,
        -0.3401, -0.3531])
regular_entropy: 0.3453167974948883
regular_entropy_rao: 2.4445912837982178
semantic_ids: [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5056), tensor(-0.9241)]
semantic_entropy: 0.7148804664611816
log_probs: tensor([-0.5056, -0.9241])
semantic_entropy_rao: 0.6717261075973511
cur_prompt: Is this artwork created by courbet, gustave?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.1727, -0.1727, -0.6154, -0.6154, -0.6154, -0.1727, -0.6154, -0.1727,
        -0.1727, -0.1727])
regular_entropy: 0.3497890830039978
regular_entropy_rao: 2.202192544937134
semantic_ids: [0, 0, 1, 1, 1, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3564), tensor(-1.2046)]
semantic_entropy: 0.7804989814758301
log_probs: tensor([-0.3564, -1.2046])
semantic_entropy_rao: 0.6107082366943359
cur_prompt: Is this artwork created by milani, aureliano?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.0647, -0.0647, -1.0543, -0.0647, -0.0647, -0.0647, -0.0647, -1.0543,
        -0.0647, -0.0647])
regular_entropy: 0.26263394951820374
regular_entropy_rao: 1.2200045585632324
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0889), tensor(-2.4647)]
semantic_entropy: 1.2768038511276245
log_probs: tensor([-0.0889, -2.4647])
semantic_entropy_rao: 0.29088714718818665
cur_prompt: Is this artwork created by frangipane, niccolò?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0494, -0.0494, -0.0494, -0.0494, -0.0494, -0.0494, -0.0494, -0.0494,
        -0.0494, -0.0494])
regular_entropy: 0.0493636429309845
regular_entropy_rao: 0.46986040472984314
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this artwork created by drevet, pierre?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,
        -0.0119, -0.0119])
regular_entropy: 0.011925743892788887
regular_entropy_rao: 0.11784366518259048
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this artwork created by tintoretto?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.2430, -0.4774, -0.2430, -0.2430, -0.4774, -0.2430, -0.2430, -0.4774,
        -0.2430, -0.2430])
regular_entropy: 0.3133077025413513
regular_entropy_rao: 2.2225255966186523
semantic_ids: [0, 1, 0, 0, 1, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2919), tensor(-1.3736)]
semantic_entropy: 0.8327803611755371
log_probs: tensor([-0.2919, -1.3736])
semantic_entropy_rao: 0.5658121705055237
cur_prompt: Is this artwork created by morel, jean-baptiste?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0

 14%|█▍        | 47/336 [03:32<18:58,  3.94s/it]
 14%|█▍        | 48/336 [03:35<18:29,  3.85s/it]
 15%|█▍        | 49/336 [03:40<19:36,  4.10s/it]
 15%|█▍        | 50/336 [03:46<21:32,  4.52s/it]
 15%|█▌        | 51/336 [03:50<21:23,  4.51s/it]
 15%|█▌        | 52/336 [03:55<21:53,  4.62s/it]
 16%|█▌        | 53/336 [04:00<22:46,  4.83s/it]
 16%|█▌        | 54/336 [04:05<23:07,  4.92s/it]
 16%|█▋        | 55/336 [04:10<22:49,  4.87s/it]
 17%|█▋        | 56/336 [04:14<21:00,  4.50s/it]
 17%|█▋        | 57/336 [04:17<19:47,  4.26s/it]multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011,
        -0.0011, -0.0011])
regular_entropy: 0.001098260167054832
regular_entropy_rao: 0.010970547795295715
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Does this artwork exist in the form of painting?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0097, -0.0097, -0.0097, -0.0097, -0.0097, -0.0097, -0.0097, -0.0097,
        -0.0097, -0.0097])
regular_entropy: 0.009704569354653358
regular_entropy_rao: 0.09610847383737564
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Does this artwork exist in the form of sculpture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0180, -0.0180, -1.6716, -0.0180, -0.0180, -0.0180, -0.0180, -0.0180,
        -0.0180, -0.0180])
regular_entropy: 0.1833449900150299
regular_entropy_rao: 0.4731069803237915
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0210), tensor(-3.8719)]
semantic_entropy: 1.9464739561080933
log_probs: tensor([-0.0210, -3.8719])
semantic_entropy_rao: 0.1012081429362297
cur_prompt: Is the actor inside the red bounding box called Arnold Schwarzenegger?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.3733, -0.3212, -0.3212, -0.3212, -0.3733, -0.3212, -0.3212, -0.3212,
        -0.3733, -0.3212])
regular_entropy: 0.3368348479270935
regular_entropy_rao: 2.401745319366455
semantic_ids: [0, 1, 1, 1, 0, 1, 1, 1, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.2407), tensor(-0.3413)]
semantic_entropy: 0.7910236120223999
log_probs: tensor([-1.2407, -0.3413])
semantic_entropy_rao: 0.6014136672019958
cur_prompt: Is the actor inside the red bounding box called Dan Duran?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331,
        -0.0331, -1.3742])
regular_entropy: 0.16719868779182434
regular_entropy_rao: 0.6357938051223755
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0286), tensor(-3.5670)]
semantic_entropy: 1.7978318929672241
log_probs: tensor([-0.0286, -3.5670])
semantic_entropy_rao: 0.12856976687908173
cur_prompt: Is the actor inside the red bounding box called Dustin Hoffman?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1968, -0.5614, -0.1968, -0.5614, -0.1968, -0.5614, -0.5614, -0.1968,
        -0.1968, -0.1968])
regular_entropy: 0.3426344692707062
regular_entropy_rao: 2.250758409500122
semantic_ids: [0, 1, 0, 1, 0, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3805), tensor(-1.1505)]
semantic_entropy: 0.7655067443847656
log_probs: tensor([-0.3805, -1.1505])
semantic_entropy_rao: 0.6241791248321533
cur_prompt: Is the actor inside the red bounding box called Christopher Olsen?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.5881, -0.1844, -0.5881, -0.1844, -0.1844, -0.1844, -0.5881, -0.5881,
        -0.1844, -0.1844])
regular_entropy: 0.34588131308555603
regular_entropy_rao: 2.2266294956207275
semantic_ids: [0, 1, 0, 1, 1, 1, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.1774), tensor(-0.3683)]
semantic_entropy: 0.7728404998779297
log_probs: tensor([-1.1774, -0.3683])
semantic_entropy_rao: 0.6175556778907776
cur_prompt: Is the actor inside the red bounding box called Jon Voight?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2054, -0.2054, -0.2054, -0.2054, -0.5440, -0.5440, -0.2054, -0.2054,
        -0.2054, -0.2054])
regular_entropy: 0.2731330096721649
regular_entropy_rao: 1.9697026014328003
semantic_ids: [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1640), tensor(-1.8888)]
semantic_entropy: 1.0264074802398682
log_probs: tensor([-0.1640, -1.8888])
semantic_entropy_rao: 0.4248701333999634
cur_prompt: Is the actor inside the red bounding box called Harvey Meyer?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1319, -0.1319, -0.1319, -0.7308, -0.1319, -0.1319, -0.1319, -0.1319,
        -0.1319, -0.1319])
regular_entropy: 0.19177861511707306
regular_entropy_rao: 1.3921940326690674
semantic_ids: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0593), tensor(-2.8554)]
semantic_entropy: 1.4573429822921753
log_probs: tensor([-0.0593, -2.8554])
semantic_entropy_rao: 0.22011883556842804
cur_prompt: Is the actor inside the red bounding box named Sam Shepard?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0027, -0.0027, -0.0027, -0.0027, -0.0027, -0.0027, -0.0027, -0.0027,
        -0.0027, -0.0027])
regular_entropy: 0.002658024663105607
regular_entropy_rao: 0.026509689167141914
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the actor inside the red bounding box named Bijou Phillips?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0696, -0.0696, -0.0696, -0.0696, -0.0696, -0.0696, -0.0696, -0.0696,
        -0.0696, -0.0696])
regular_entropy: 0.06962595134973526
regular_entropy_rao: 0.6494308114051819
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the person inside the red bounding box called Dustin Hoffman?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes']
log_probs: tensor([-0.1511, -0.6719, -0.6719, -0.1511, -0.1511, -0.6719, -0.1511, -0.1511,
        -0.1511, -0.6719])
regular_entropy: 0.35944586992263794
regular_entropy_rao: 2.152204990386963
semantic_ids: [0, 1, 1, 0, 0, 1, 0, 0, 0, 1]
cluster_assignment_entropy: 0.6730116670092565

 17%|█▋        | 58/336 [04:22<20:45,  4.48s/it]
 18%|█▊        | 59/336 [04:26<19:28,  4.22s/it]
 18%|█▊        | 60/336 [04:30<18:45,  4.08s/it]
 18%|█▊        | 61/336 [04:33<17:59,  3.93s/it]
 18%|█▊        | 62/336 [04:39<19:44,  4.32s/it]
 19%|█▉        | 63/336 [04:44<20:30,  4.51s/it]
 19%|█▉        | 64/336 [04:47<19:20,  4.27s/it]
 19%|█▉        | 65/336 [04:52<20:02,  4.44s/it]
 20%|█▉        | 66/336 [04:56<18:52,  4.20s/it]
 20%|█▉        | 67/336 [05:00<19:21,  4.32s/it]
 20%|██        | 68/336 [05:04<18:23,  4.12s/it]
 21%|██        | 69/336 [05:09<19:30,  4.38s/it]log_likelihood_per_semantic_id: [tensor(-0.3336), tensor(-1.2599)]
semantic_entropy: 0.796771764755249
log_probs: tensor([-0.3336, -1.2599])
semantic_entropy_rao: 0.5963920950889587
cur_prompt: Is the person inside the red bounding box called Fernando Lueches?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0315, -0.0315, -0.0315, -0.0315, -0.0315, -0.0315, -0.0315, -0.0315,
        -0.0315, -0.0315])
regular_entropy: 0.03145670145750046
regular_entropy_rao: 0.3048257827758789
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the actor inside the red bounding box called Julia Roberts?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1231, -0.1231, -0.1231, -0.1231, -0.1231, -0.1231, -0.1231, -0.1231,
        -0.1231, -0.1231])
regular_entropy: 0.12309388816356659
regular_entropy_rao: 1.0883723497390747
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the actor inside the red bounding box called Roger Bart?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0061, -0.0061, -0.0061, -0.0061, -0.0061, -0.0061, -0.0061, -0.0061,
        -0.0061, -0.0061])
regular_entropy: 0.006094944663345814
regular_entropy_rao: 0.060579102486371994
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the actor inside the red bounding box called William Shatner?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1926, -0.5702, -0.1926, -0.1926, -0.1926, -0.1926, -0.1926, -0.5702,
        -0.5702, -0.5702])
regular_entropy: 0.3436433672904968
regular_entropy_rao: 2.242755889892578
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 1, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3764), tensor(-1.1595)]
semantic_entropy: 0.7679152488708496
log_probs: tensor([-0.3764, -1.1595])
semantic_entropy_rao: 0.6219967007637024
cur_prompt: Is the actor inside the red bounding box called Richard Rohrbough?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.7209, -0.1349, -0.7209, -0.1349, -0.7209, -0.1349, -0.1349, -0.1349,
        -0.1349, -0.7209])
regular_entropy: 0.3693068027496338
regular_entropy_rao: 2.109720230102539
semantic_ids: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.3070), tensor(-0.3156)]
semantic_entropy: 0.8112823963165283
log_probs: tensor([-1.3070, -0.3156])
semantic_entropy_rao: 0.5838894844055176
cur_prompt: Is the person inside the red bounding box called Sally Field?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0090, -0.0090, -0.0090, -0.0090, -0.0090, -0.0090, -0.0090, -0.0090,
        -0.0090, -0.0090])
regular_entropy: 0.008981846272945404
regular_entropy_rao: 0.08901534229516983
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the person inside the red bounding box called Arthur Senzy?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no']
log_probs: tensor([-0.1444, -0.1444, -0.6913, -0.6913, -0.1444, -0.1444, -0.1444, -0.1444,
        -0.6913, -0.6913])
regular_entropy: 0.36319997906684875
regular_entropy_rao: 2.13529896736145
semantic_ids: [0, 0, 1, 1, 0, 0, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3263), tensor(-1.2786)]
semantic_entropy: 0.8024742603302002
log_probs: tensor([-0.3263, -1.2786])
semantic_entropy_rao: 0.591449499130249
cur_prompt: Is the person inside the red bounding box named Marisa Berenson?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0046, -0.0046, -0.0046, -0.0046, -0.0046, -0.0046, -0.0046, -0.0046,
        -0.0046, -0.0046])
regular_entropy: 0.00458380114287138
regular_entropy_rao: 0.045628372579813004
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the person inside the red bounding box named Graham Bohea?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-1.6591, -0.0184, -0.0184, -0.0184, -0.0184, -0.0184, -0.0184, -0.0184,
        -0.0184, -0.0184])
regular_entropy: 0.18250860273838043
regular_entropy_rao: 0.47872793674468994
semantic_ids: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-3.8592), tensor(-0.0213)]
semantic_entropy: 1.9402357339859009
log_probs: tensor([-3.8592, -0.0213])
semantic_entropy_rao: 0.10223470628261566
cur_prompt: Is the actor inside the red bounding box called Jeff Bridges?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025,
        -0.0025, -0.0025])
regular_entropy: 0.00252342177554965
regular_entropy_rao: 0.025170614942908287
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the actor inside the red bounding box called Scott Adkins?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1545, -0.6624, -0.1545, -0.1545, -0.1545, -0.1545, -0.6624, -0.6624,
        -0.6624, -0.6624])
regular_entropy: 0.4084479808807373
regular_entropy_rao: 2.3697309494018555
semantic_ids: [0, 1, 0, 0, 0, 0, 1, 1, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.4711), tensor(-0.9789)]
semantic_entropy: 0.7250409126281738
log_probs: tensor([-0.4711, -0.9789])
semantic_entropy_rao: 0.6619230508804321
cur_prompt: Is the person inside the red bounding box called Will Smith?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0063, -0.0063, -0.0063, -0.0063, -0.0063, -0.0063, -0.0063, -0.0063,
        -0.0063, -0.0063])
regular_entropy: 0.006254785694181919
regular_entropy_rao: 0.062157850712537766

 21%|██        | 70/336 [05:13<18:52,  4.26s/it]
 21%|██        | 71/336 [05:17<18:59,  4.30s/it]
 21%|██▏       | 72/336 [05:22<19:59,  4.54s/it]
 22%|██▏       | 73/336 [05:26<18:38,  4.25s/it]
 22%|██▏       | 74/336 [05:32<20:57,  4.80s/it]
 22%|██▏       | 75/336 [05:37<20:47,  4.78s/it]
 23%|██▎       | 76/336 [05:42<21:03,  4.86s/it]
 23%|██▎       | 77/336 [05:47<20:52,  4.84s/it]
 23%|██▎       | 78/336 [05:53<22:14,  5.17s/it]
 24%|██▎       | 79/336 [05:57<21:13,  4.96s/it]
 24%|██▍       | 80/336 [06:02<21:42,  5.09s/it]semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the person inside the red bounding box called E. Katherine Kerr?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.1968, -0.1968, -0.1968, -0.1968, -0.1968, -0.1968, -0.1968, -0.1968,
        -0.5614, -0.1968])
regular_entropy: 0.23325984179973602
regular_entropy_rao: 1.7750176191329956
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0743), tensor(-2.6361)]
semantic_entropy: 1.3552360534667969
log_probs: tensor([-0.0743, -2.6361])
semantic_entropy_rao: 0.25785356760025024
cur_prompt: Is the person inside the red bounding box named Karen Black?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.0154, -0.0154, -0.0154, -0.0154, -0.0154, -0.0154, -1.7472, -0.0154,
        -0.0154, -0.0154])
regular_entropy: 0.18859627842903137
regular_entropy_rao: 0.44111913442611694
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0195), tensor(-3.9485)]
semantic_entropy: 1.9839705228805542
log_probs: tensor([-0.0195, -3.9485])
semantic_entropy_rao: 0.095240019261837
cur_prompt: Is the person inside the red bounding box named Nick Discenza?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0545, -0.0545, -0.0545, -0.0545, -0.0545, -0.0545, -0.0545, -0.0545,
        -0.0545, -0.0545])
regular_entropy: 0.054497815668582916
regular_entropy_rao: 0.5160728693008423
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is the answer to the arithmetic question in the image 9?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.5971, -0.5971, -0.1804, -0.1804, -0.1804, -0.1804, -0.5971, -0.1804,
        -0.1804, -0.1804])
regular_entropy: 0.3054426312446594
regular_entropy_rao: 2.0405092239379883
semantic_ids: [0, 0, 1, 1, 1, 1, 0, 1, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.5128), tensor(-0.2488)]
semantic_entropy: 0.8808180689811707
log_probs: tensor([-1.5128, -0.2488])
semantic_entropy_rao: 0.5272775888442993
cur_prompt: Is the answer to the arithmetic question in the image 45?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no']
log_probs: tensor([-0.3598, -0.3337, -0.3598, -0.3337, -0.3598, -0.3598, -0.3337, -0.3337,
        -0.3598, -0.3598])
regular_entropy: 0.34934741258621216
regular_entropy_rao: 2.4624664783477783
semantic_ids: [0, 1, 0, 1, 0, 0, 1, 1, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5213), tensor(-0.9007)]
semantic_entropy: 0.7110354900360107
log_probs: tensor([-0.5213, -0.9007])
semantic_entropy_rao: 0.6754705905914307
cur_prompt: Is the answer to the arithmetic question in the image 200?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes']
log_probs: tensor([-0.2584, -0.2584, -0.2584, -0.2584, -0.4537, -0.4537, -0.4537, -0.2584,
        -0.2584, -0.4537])
regular_entropy: 0.3365192711353302
regular_entropy_rao: 2.350236415863037
semantic_ids: [0, 0, 0, 0, 1, 1, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.4372), tensor(-1.0380)]
semantic_entropy: 0.7376013398170471
log_probs: tensor([-0.4372, -1.0380])
semantic_entropy_rao: 0.6499873995780945
cur_prompt: Is the answer to the arithmetic question in the image 400?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.1616, -0.1616, -0.6434, -0.1616, -0.1616, -0.1616, -0.1616, -0.1616,
        -0.6434, -0.1616])
regular_entropy: 0.2579535245895386
regular_entropy_rao: 1.7760918140411377
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1436), tensor(-2.0117)]
semantic_entropy: 1.0776327848434448
log_probs: tensor([-0.1436, -2.0117])
semantic_entropy_rao: 0.39348286390304565
cur_prompt: Is the area of the right triangle in the picture equal to 24?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes']
log_probs: tensor([-0.2691, -0.4383, -0.2691, -0.4383, -0.2691, -0.2691, -0.2691, -0.2691,
        -0.2691, -0.4383])
regular_entropy: 0.3198487460613251
regular_entropy_rao: 2.2874715328216553
semantic_ids: [0, 1, 0, 1, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3088), tensor(-1.3254)]
semantic_entropy: 0.8171172142028809
log_probs: tensor([-0.3088, -1.3254])
semantic_entropy_rao: 0.5789310336112976
cur_prompt: Is the area of the right triangle in the picture equal to 8?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes']
log_probs: tensor([-0.1148, -0.1148, -0.1148, -0.1148, -0.1148, -0.1148, -0.1148, -0.1148,
        -0.1148, -0.7919])
regular_entropy: 0.18253448605537415
regular_entropy_rao: 1.2800475358963013
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0549), tensor(-2.9292)]
semantic_entropy: 1.4920734167099
log_probs: tensor([-0.0549, -2.9292])
semantic_entropy_rao: 0.2085171937942505
cur_prompt: Should the value of "a" in the picture equal 2?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes']
log_probs: tensor([-0.2914, -0.2914, -0.4086, -0.4086, -0.2914, -0.4086, -0.2914, -0.4086,
        -0.2914, -0.4086])
regular_entropy: 0.34999915957450867
regular_entropy_rao: 2.446432113647461
semantic_ids: [0, 0, 1, 1, 0, 1, 0, 1, 0, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.6363), tensor(-0.7535)]
semantic_entropy: 0.6948628425598145
log_probs: tensor([-0.6363, -0.7535])
semantic_entropy_rao: 0.6914335489273071
cur_prompt: Should the value of "a" in the picture equal 3?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes']
log_probs: tensor([-0.4159, -0.4159, -0.4159, -0.2857, -0.2857, -0.4159, -0.4159, -0.2857,
        -0.4159, -0.2857])
regular_entropy: 0.36382097005844116
regular_entropy_rao: 2.5051326751708984
semantic_ids: [0, 0, 0, 1, 1, 0, 0, 1, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5650), tensor(-0.8402)]
semantic_entropy: 0.7025883197784424
log_probs: tensor([-0.5650, -0.8402])
semantic_entropy_rao: 0.6837652325630188

 24%|██▍       | 81/336 [06:07<21:22,  5.03s/it]
 24%|██▍       | 82/336 [06:12<20:53,  4.93s/it]
 25%|██▍       | 83/336 [06:17<21:08,  5.01s/it]
 25%|██▌       | 84/336 [06:23<21:46,  5.18s/it]
 25%|██▌       | 85/336 [06:28<21:16,  5.09s/it]
 26%|██▌       | 86/336 [06:33<20:53,  5.01s/it]
 26%|██▌       | 87/336 [06:38<20:48,  5.01s/it]
 26%|██▌       | 88/336 [06:42<20:03,  4.85s/it]
 26%|██▋       | 89/336 [06:47<20:26,  4.96s/it]
 27%|██▋       | 90/336 [06:51<19:12,  4.69s/it]
 27%|██▋       | 91/336 [06:56<19:10,  4.69s/it]
 27%|██▋       | 92/336 [07:01<19:44,  4.86s/it]cur_prompt: Is the answer to the arithmetic question in the image 65?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.3212, -0.3733, -0.3733, -0.3212, -0.3212, -0.3733, -0.3212, -0.3733,
        -0.3733, -0.3733])
regular_entropy: 0.35245999693870544
regular_entropy_rao: 2.473849058151245
semantic_ids: [0, 1, 1, 0, 0, 1, 0, 1, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.8854), tensor(-0.5320)]
semantic_entropy: 0.7086763381958008
log_probs: tensor([-0.8854, -0.5320])
semantic_entropy_rao: 0.6777776479721069
cur_prompt: Is the answer to the arithmetic question in the image 56?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.1844, -0.1844, -0.5881, -0.1844, -0.1844, -0.5881, -0.5881, -0.1844,
        -0.1844, -0.1844])
regular_entropy: 0.3055168092250824
regular_entropy_rao: 2.053380250930786
semantic_ids: [0, 0, 1, 0, 0, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2517), tensor(-1.5027)]
semantic_entropy: 0.8771910071372986
log_probs: tensor([-0.2517, -1.5027])
semantic_entropy_rao: 0.5300999283790588
cur_prompt: Is the answer to the arithmetic question in the image 49?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes']
log_probs: tensor([-0.3031, -0.3942, -0.3942, -0.3031, -0.3031, -0.3031, -0.3031, -0.3942,
        -0.3942, -0.3031])
regular_entropy: 0.33953315019607544
regular_entropy_rao: 2.40614652633667
semantic_ids: [0, 1, 1, 0, 0, 0, 0, 1, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.4754), tensor(-0.9720)]
semantic_entropy: 0.7236633896827698
log_probs: tensor([-0.4754, -0.9720])
semantic_entropy_rao: 0.6632442474365234
cur_prompt: Is the answer to the arithmetic question in the image 39?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no']
log_probs: tensor([-0.2236, -0.5100, -0.5100, -0.5100, -0.5100, -0.5100, -0.5100, -0.5100,
        -0.2236, -0.2236])
regular_entropy: 0.4241059422492981
regular_entropy_rao: 2.6802256107330322
semantic_ids: [0, 1, 1, 1, 1, 1, 1, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.0124), tensor(-0.4515)]
semantic_entropy: 0.731960117816925
log_probs: tensor([-1.0124, -0.4515])
semantic_entropy_rao: 0.655323326587677
cur_prompt: Is the answer to the arithmetic question in the image 11?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.7611, -0.1231, -0.7611, -0.1231, -0.7611, -0.1231, -0.1231, -0.1231,
        -0.1231, -0.1231])
regular_entropy: 0.3145005702972412
regular_entropy_rao: 1.8285163640975952
semantic_ids: [0, 1, 0, 1, 0, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.6894), tensor(-0.2041)]
semantic_entropy: 0.9467670917510986
log_probs: tensor([-1.6894, -0.2041])
semantic_entropy_rao: 0.4783349335193634
cur_prompt: Is the answer to the arithmetic question in the image 111?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.2380, -0.4854, -0.2380, -0.2380, -0.2380, -0.2380, -0.4854, -0.4854,
        -0.2380, -0.4854])
regular_entropy: 0.3369818329811096
regular_entropy_rao: 2.3206217288970947
semantic_ids: [0, 1, 0, 0, 0, 0, 1, 1, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.4191), tensor(-1.0719)]
semantic_entropy: 0.7455055713653564
log_probs: tensor([-0.4191, -1.0719])
semantic_entropy_rao: 0.642578661441803
cur_prompt: Is the answer to the arithmetic question in the image 18?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.1260, -0.1260, -0.1260, -0.1260, -0.1260, -0.1260, -0.1260, -0.1260,
        -0.1260, -0.7510])
regular_entropy: 0.1884646713733673
regular_entropy_rao: 1.3538951873779297
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0578), tensor(-2.8800)]
semantic_entropy: 1.4688842296600342
log_probs: tensor([-0.0578, -2.8800])
semantic_entropy_rao: 0.21619746088981628
cur_prompt: Is the answer to the arithmetic question in the image 36?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1652, -0.1652, -0.1652, -0.6340, -0.1652, -0.1652, -0.1652, -0.1652,
        -0.1652, -0.1652])
regular_entropy: 0.2121042013168335
regular_entropy_rao: 1.596893548965454
semantic_ids: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0672), tensor(-2.7332)]
semantic_entropy: 1.4002078771591187
log_probs: tensor([-0.0672, -2.7332])
semantic_entropy_rao: 0.24053877592086792
cur_prompt: Is the answer to the arithmetic question in the image 14?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0375, -0.0375, -0.0375, -0.0375, -0.0375, -0.0375, -0.0375, -0.0375,
        -0.0375, -0.0375])
regular_entropy: 0.03751638904213905
regular_entropy_rao: 0.36134985089302063
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the answer to the arithmetic question in the image 83?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1096, -0.1096, -0.1096, -0.1096, -0.8127, -0.1096, -0.1096, -0.1096,
        -0.1096, -0.1096])
regular_entropy: 0.17990469932556152
regular_entropy_rao: 1.2445107698440552
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0535), tensor(-2.9539)]
semantic_entropy: 1.5037193298339844
log_probs: tensor([-0.0535, -2.9539])
semantic_entropy_rao: 0.20475801825523376
cur_prompt: Should the value of "a" in the picture equal 9?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.7510, -0.1260, -0.1260, -0.1260, -0.1260, -0.7510, -0.7510, -0.1260,
        -0.1260, -0.1260])
regular_entropy: 0.3134646713733673
regular_entropy_rao: 1.840559720993042
semantic_ids: [0, 1, 1, 1, 1, 0, 0, 1, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.6788), tensor(-0.2065)]
semantic_entropy: 0.9426733255386353
log_probs: tensor([-1.6788, -0.2065])
semantic_entropy_rao: 0.4812457859516144
cur_prompt: Should the value of "a" in the picture equal 1?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0154, -0.0154, -0.0154, -0.0154, -1.7472, -0.0154, -0.0154, -0.0154,
        -0.0154, -0.0154])
 28%|██▊       | 93/336 [07:06<19:13,  4.75s/it]
 28%|██▊       | 94/336 [07:11<19:29,  4.83s/it]
 28%|██▊       | 95/336 [07:16<20:12,  5.03s/it]
 29%|██▊       | 96/336 [07:22<21:23,  5.35s/it]
 29%|██▉       | 97/336 [07:27<20:49,  5.23s/it]
 29%|██▉       | 98/336 [07:33<21:41,  5.47s/it]
 29%|██▉       | 99/336 [07:39<21:17,  5.39s/it]
 30%|██▉       | 100/336 [07:44<21:05,  5.36s/it]
 30%|███       | 101/336 [07:49<21:11,  5.41s/it]
 30%|███       | 102/336 [07:54<20:30,  5.26s/it]
 31%|███       | 103/336 [07:59<20:13,  5.21s/it]
regular_entropy: 0.18859627842903137
regular_entropy_rao: 0.44111910462379456
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0195), tensor(-3.9485)]
semantic_entropy: 1.9839705228805542
log_probs: tensor([-0.0195, -3.9485])
semantic_entropy_rao: 0.095240019261837
cur_prompt: Is the answer to the arithmetic question in the image 340?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.4383, -0.4383, -0.2691, -0.2691, -0.4383, -0.2691, -0.2691, -0.4383,
        -0.2691, -0.2691])
regular_entropy: 0.33677583932876587
regular_entropy_rao: 2.364654541015625
semantic_ids: [0, 0, 1, 1, 0, 1, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.0212), tensor(-0.4465)]
semantic_entropy: 0.7338814735412598
log_probs: tensor([-1.0212, -0.4465])
semantic_entropy_rao: 0.6535013914108276
cur_prompt: Is the answer to the arithmetic question in the image 17?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.1231, -0.1231, -0.1231, -0.1231, -0.1231, -0.7611, -0.1231, -0.1231,
        -0.7611, -0.7611])
regular_entropy: 0.314500629901886
regular_entropy_rao: 1.8285163640975952
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2041), tensor(-1.6894)]
semantic_entropy: 0.9467670917510986
log_probs: tensor([-0.2041, -1.6894])
semantic_entropy_rao: 0.4783349335193634
cur_prompt: Is the area of the square in the picture equal to 40?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes']
log_probs: tensor([-0.4086, -0.4086, -0.2914, -0.2914, -0.2914, -0.4086, -0.2914, -0.4086,
        -0.4086, -0.2914])
regular_entropy: 0.3499990403652191
regular_entropy_rao: 2.4464313983917236
semantic_ids: [0, 0, 1, 1, 1, 0, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.7535), tensor(-0.6363)]
semantic_entropy: 0.6948628425598145
log_probs: tensor([-0.7535, -0.6363])
semantic_entropy_rao: 0.6914335489273071
cur_prompt: Is the area of the square in the picture equal to 8?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no']
log_probs: tensor([-0.3337, -0.3598, -0.3598, -0.3337, -0.3598, -0.3598, -0.3337, -0.3598,
        -0.3337, -0.3598])
regular_entropy: 0.34934741258621216
regular_entropy_rao: 2.4624667167663574
semantic_ids: [0, 1, 1, 0, 1, 1, 0, 1, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.9007), tensor(-0.5213)]
semantic_entropy: 0.7110354900360107
log_probs: tensor([-0.9007, -0.5213])
semantic_entropy_rao: 0.6754705905914307
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'rank first' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1545, -0.1545, -0.6624, -0.6624, -0.1545, -0.1545, -0.1545, -0.1545,
        -0.1545, -0.1545])
regular_entropy: 0.2561042606830597
regular_entropy_rao: 1.7423678636550903
semantic_ids: [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1402), tensor(-2.0343)]
semantic_entropy: 1.0872089862823486
log_probs: tensor([-0.1402, -2.0343])
semantic_entropy_rao: 0.3878609538078308
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'to add the finishing touches' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.2584, -0.4537, -0.4537, -0.2584, -0.2584, -0.2584, -0.2584, -0.4537,
        -0.2584, -0.2584])
regular_entropy: 0.3169887363910675
regular_entropy_rao: 2.2615694999694824
semantic_ids: [0, 1, 1, 0, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3020), tensor(-1.3446)]
semantic_entropy: 0.8232845067977905
log_probs: tensor([-0.3020, -1.3446])
semantic_entropy_rao: 0.5737321972846985
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'waiting for a long time' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.4159, -0.2857, -0.4159, -0.2857, -0.4159, -0.2857, -0.2857, -0.4159,
        -0.4159, -0.4159])
regular_entropy: 0.36382144689559937
regular_entropy_rao: 2.5051348209381104
semantic_ids: [0, 1, 0, 1, 0, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5650), tensor(-0.8402)]
semantic_entropy: 0.7025880813598633
log_probs: tensor([-0.5650, -0.8402])
semantic_entropy_rao: 0.6837653517723083
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'sleeping for a long time' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes']
log_probs: tensor([-0.3665, -0.3274, -0.3665, -0.3665, -0.3274, -0.3665, -0.3665, -0.3274,
        -0.3665, -0.3274])
regular_entropy: 0.3508613705635071
regular_entropy_rao: 2.468214511871338
semantic_ids: [0, 1, 0, 0, 1, 0, 0, 1, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5266), tensor(-0.8930)]
semantic_entropy: 0.7098355293273926
log_probs: tensor([-0.5266, -0.8930])
semantic_entropy_rao: 0.6766433715820312
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'feeling frustrated' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes']
log_probs: tensor([-0.1260, -0.7510, -0.1260, -0.1260, -0.1260, -0.1260, -0.1260, -0.7510,
        -0.1260, -0.7510])
regular_entropy: 0.3134646713733673
regular_entropy_rao: 1.840559959411621
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 1, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2065), tensor(-1.6788)]
semantic_entropy: 0.9426733255386353
log_probs: tensor([-0.2065, -1.6788])
semantic_entropy_rao: 0.4812457859516144
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'feeling relaxed' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.3665, -0.3274, -0.3665, -0.3274, -0.3274, -0.3665, -0.3274, -0.3665,
        -0.3665, -0.3665])
regular_entropy: 0.3508613407611847
regular_entropy_rao: 2.468214273452759
semantic_ids: [0, 1, 0, 1, 1, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5266), tensor(-0.8930)]
semantic_entropy: 0.7098355293273926
log_probs: tensor([-0.5266, -0.8930])
semantic_entropy_rao: 0.6766433715820312
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'creative people' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes']

 31%|███       | 104/336 [08:04<19:46,  5.12s/it]
 31%|███▏      | 105/336 [08:09<19:31,  5.07s/it]
 32%|███▏      | 106/336 [08:14<19:22,  5.05s/it]
 32%|███▏      | 107/336 [08:20<19:55,  5.22s/it]
 32%|███▏      | 108/336 [08:25<19:28,  5.13s/it]
 32%|███▏      | 109/336 [08:30<19:01,  5.03s/it]
 33%|███▎      | 110/336 [08:35<19:15,  5.11s/it]
 33%|███▎      | 111/336 [08:40<18:48,  5.02s/it]
 33%|███▎      | 112/336 [08:45<19:23,  5.19s/it]
 34%|███▎      | 113/336 [08:51<20:07,  5.42s/it]log_probs: tensor([-0.4159, -0.2857, -0.4159, -0.2857, -0.2857, -0.4159, -0.4159, -0.2857,
        -0.4159, -0.4159])
regular_entropy: 0.36382097005844116
regular_entropy_rao: 2.5051326751708984
semantic_ids: [0, 1, 0, 1, 1, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5650), tensor(-0.8402)]
semantic_entropy: 0.7025883197784424
log_probs: tensor([-0.5650, -0.8402])
semantic_entropy_rao: 0.6837652325630188
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'leading people' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.2144, -0.2144, -0.2144, -0.5269, -0.5269, -0.2144, -0.2144, -0.2144,
        -0.2144, -0.2144])
regular_entropy: 0.2768506407737732
regular_entropy_rao: 2.006129741668701
semantic_ids: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1680), tensor(-1.8668)]
semantic_entropy: 1.0173697471618652
log_probs: tensor([-0.1680, -1.8668])
semantic_entropy_rao: 0.43064481019973755
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'sunny weather' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2054, -0.2054, -0.2054, -0.2054, -0.5440, -0.5440, -0.2054, -0.2054,
        -0.2054, -0.2054])
regular_entropy: 0.27313297986984253
regular_entropy_rao: 1.9697022438049316
semantic_ids: [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1640), tensor(-1.8888)]
semantic_entropy: 1.0264077186584473
log_probs: tensor([-0.1640, -1.8888])
semantic_entropy_rao: 0.42487019300460815
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'cold weather' in the picture?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.4383, -0.4383, -0.2691, -0.4383, -0.2691, -0.2691, -0.4383, -0.4383,
        -0.2691, -0.2691])
regular_entropy: 0.35370302200317383
regular_entropy_rao: 2.441838026046753
semantic_ids: [0, 0, 1, 0, 1, 1, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.7814), tensor(-0.6121)]
semantic_entropy: 0.6967244148254395
log_probs: tensor([-0.7814, -0.6121])
semantic_entropy_rao: 0.6895783543586731
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'walking very slowly' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.5614, -0.5614, -0.1968, -0.1968, -0.1968, -0.1968, -0.1968, -0.1968,
        -0.1968, -0.1968])
regular_entropy: 0.2697177827358246
regular_entropy_rao: 1.9335949420928955
semantic_ids: [0, 0, 1, 1, 1, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-1.9110), tensor(-0.1601)]
semantic_entropy: 1.0355331897735596
log_probs: tensor([-1.9110, -0.1601])
semantic_entropy_rao: 0.41911280155181885
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'runing very slowly' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1727, -0.1727, -0.6154, -0.1727, -0.6154, -0.1727, -0.1727, -0.1727,
        -0.1727, -0.1727])
regular_entropy: 0.26123759150505066
regular_entropy_rao: 1.827597737312317
semantic_ids: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1489), tensor(-1.9779)]
semantic_entropy: 1.0634160041809082
log_probs: tensor([-0.1489, -1.9779])
semantic_entropy_rao: 0.401969850063324
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'very powerful' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2584, -0.4537, -0.4537, -0.4537, -0.2584, -0.2584, -0.2584, -0.2584,
        -0.2584, -0.2584])
regular_entropy: 0.3169880211353302
regular_entropy_rao: 2.261565923690796
semantic_ids: [0, 1, 1, 1, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3020), tensor(-1.3446)]
semantic_entropy: 0.8232845067977905
log_probs: tensor([-0.3020, -1.3446])
semantic_entropy_rao: 0.5737321972846985
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'to be fragile throughout the world' in the picture?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.3337, -0.3598, -0.3598, -0.3337, -0.3598, -0.3598, -0.3337, -0.3337,
        -0.3598, -0.3598])
regular_entropy: 0.34934741258621216
regular_entropy_rao: 2.4624667167663574
semantic_ids: [0, 1, 1, 0, 1, 1, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.9007), tensor(-0.5213)]
semantic_entropy: 0.7110354900360107
log_probs: tensor([-0.9007, -0.5213])
semantic_entropy_rao: 0.6754705905914307
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'get along well' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no']
log_probs: tensor([-0.2189, -0.5184, -0.5184, -0.2189, -0.2189, -0.5184, -0.5184, -0.2189,
        -0.5184, -0.2189])
regular_entropy: 0.36866819858551025
regular_entropy_rao: 2.4228897094726562
semantic_ids: [0, 1, 1, 0, 0, 1, 1, 0, 1, 0]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.5546), tensor(-0.8541)]
semantic_entropy: 0.7043166160583496
log_probs: tensor([-0.5546, -0.8541])
semantic_entropy_rao: 0.682060718536377
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'for own self-interest' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.3212, -0.3212, -0.3212, -0.3733, -0.3733, -0.3212, -0.3212, -0.3733,
        -0.3212, -0.3212])
regular_entropy: 0.3368348479270935
regular_entropy_rao: 2.401745080947876
semantic_ids: [0, 0, 0, 1, 1, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3413), tensor(-1.2407)]
semantic_entropy: 0.7910234332084656
log_probs: tensor([-0.3413, -1.2407])
semantic_entropy_rao: 0.6014136075973511
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'delicious fruit' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0749, -0.0749, -0.0749, -0.0749, -0.0749, -0.0749, -0.0749, -0.0749,
        -0.0749, -0.0749])
regular_entropy: 0.07487928122282028
regular_entropy_rao: 0.6947714686393738
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07

 34%|███▍      | 114/336 [08:55<18:12,  4.92s/it]
 34%|███▍      | 115/336 [09:00<17:56,  4.87s/it]
 35%|███▍      | 116/336 [09:05<18:44,  5.11s/it]
 35%|███▍      | 117/336 [09:10<18:34,  5.09s/it]
 35%|███▌      | 118/336 [09:15<18:21,  5.05s/it]
 35%|███▌      | 119/336 [09:20<18:04,  5.00s/it]
 36%|███▌      | 120/336 [09:25<17:55,  4.98s/it]
 36%|███▌      | 121/336 [09:30<17:55,  5.00s/it]
 36%|███▋      | 122/336 [09:35<17:48,  4.99s/it]
 37%|███▋      | 123/336 [09:39<16:46,  4.73s/it]
 37%|███▋      | 124/336 [09:44<16:10,  4.58s/it]cur_prompt: Is it appropriate to translate the Chinese in the image into English 'banana' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.2189, -0.2189, -0.5184, -0.2189, -0.2189, -0.2189, -0.5184, -0.2189,
        -0.2189, -0.5184])
regular_entropy: 0.3087728023529053
regular_entropy_rao: 2.157266855239868
semantic_ids: [0, 0, 1, 0, 0, 0, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2759), tensor(-1.4226)]
semantic_entropy: 0.8492449522018433
log_probs: tensor([-0.2759, -1.4226])
semantic_entropy_rao: 0.5523197650909424
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'a small amount' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes']
log_probs: tensor([-0.2857, -0.4159, -0.2857, -0.2857, -0.4159, -0.2857, -0.2857, -0.4159,
        -0.4159, -0.2857])
regular_entropy: 0.3377801775932312
regular_entropy_rao: 2.3857522010803223
semantic_ids: [0, 1, 0, 0, 1, 0, 0, 1, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.4608), tensor(-0.9964)]
semantic_entropy: 0.7285948395729065
log_probs: tensor([-0.4608, -0.9964])
semantic_entropy_rao: 0.6585256457328796
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'difficult and dangerous' in the picture?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.2098, -0.2098, -0.2098, -0.5354, -0.2098, -0.5354, -0.2098, -0.5354,
        -0.5354, -0.2098])
regular_entropy: 0.3400576710700989
regular_entropy_rao: 2.274491548538208
semantic_ids: [0, 0, 0, 1, 0, 1, 0, 1, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3930), tensor(-1.1240)]
semantic_entropy: 0.7585036754608154
log_probs: tensor([-0.3930, -1.1240])
semantic_entropy_rao: 0.6305651068687439
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'a delicious dinner' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.0749, -0.0749, -0.9863, -0.0749, -0.0749, -0.0749, -0.9863, -0.0749,
        -0.0749, -0.0749])
regular_entropy: 0.25717097520828247
regular_entropy_rao: 1.2915090322494507
semantic_ids: [0, 0, 1, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0958), tensor(-2.3935)]
semantic_entropy: 1.2446262836456299
log_probs: tensor([-0.0958, -2.3935])
semantic_entropy_rao: 0.3055568337440491
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'hamburger and chips' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.4935, -0.4935, -0.4935, -0.2331, -0.4935, -0.2331, -0.2331, -0.4935,
        -0.2331, -0.2331])
regular_entropy: 0.36333969235420227
regular_entropy_rao: 2.4297068119049072
semantic_ids: [0, 0, 0, 1, 0, 1, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.8318), tensor(-0.5714)]
semantic_entropy: 0.7016005516052246
log_probs: tensor([-0.8318, -0.5714])
semantic_entropy_rao: 0.6847414970397949
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'feeling happy' in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.3337, -0.3598, -0.3337, -0.3337, -0.3337, -0.3598, -0.3598, -0.3598,
        -0.3598, -0.3337])
regular_entropy: 0.3467433452606201
regular_entropy_rao: 2.450438976287842
semantic_ids: [0, 1, 0, 0, 0, 1, 1, 1, 1, 0]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.6802), tensor(-0.7063)]
semantic_entropy: 0.6932321190834045
log_probs: tensor([-0.6802, -0.7063])
semantic_entropy_rao: 0.6930624842643738
cur_prompt: Is it appropriate to translate the Chinese in the image into English 'feeling bored' in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1727, -0.6154, -0.6154, -0.1727, -0.1727, -0.6154, -0.6154, -0.1727,
        -0.1727, -0.1727])
regular_entropy: 0.349778950214386
regular_entropy_rao: 2.202141761779785
semantic_ids: [0, 1, 1, 0, 0, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3564), tensor(-1.2046)]
semantic_entropy: 0.7804992198944092
log_probs: tensor([-0.3564, -1.2046])
semantic_entropy_rao: 0.6107083559036255
cur_prompt: Is there only one bottle in the image?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.1319, -0.7308, -0.1319, -0.1319, -0.1319, -0.7308, -0.1319, -0.7308,
        -0.1319, -0.1319])
regular_entropy: 0.3115702271461487
regular_entropy_rao: 1.8648219108581543
semantic_ids: [0, 1, 0, 0, 0, 1, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2114), tensor(-1.6577)]
semantic_entropy: 0.9345635175704956
log_probs: tensor([-0.2114, -1.6577])
semantic_entropy_rao: 0.4870603382587433
cur_prompt: Is there two bottles in the image?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.1096, -0.1096, -0.1096, -0.1096, -0.1096, -0.1096, -0.1096, -0.1096,
        -0.8127, -0.1096])
regular_entropy: 0.17990458011627197
regular_entropy_rao: 1.2445104122161865
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0535), tensor(-2.9539)]
semantic_entropy: 1.503719449043274
log_probs: tensor([-0.0535, -2.9539])
semantic_entropy_rao: 0.20475813746452332
cur_prompt: Are there three remotes in this image?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.1203, -0.1203, -0.1203, -0.1203, -0.1203, -0.1203, -0.1203, -0.1203,
        -0.1203, -0.7713])
regular_entropy: 0.1853855550289154
regular_entropy_rao: 1.3165113925933838
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0563), tensor(-2.9046)]
semantic_entropy: 1.4804611206054688
log_probs: tensor([-0.0563, -2.9046])
semantic_entropy_rao: 0.21233072876930237
cur_prompt: Are there only two remotes in this image?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0040, -0.0040, -0.0040, -0.0040, -0.0040, -0.0040, -0.0040, -0.0040,
        -0.0040, -0.0040])
regular_entropy: 0.004026428796350956
regular_entropy_rao: 0.04010249301791191
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0

 37%|███▋      | 125/336 [09:47<14:42,  4.18s/it]
 38%|███▊      | 126/336 [09:51<15:08,  4.33s/it]
 38%|███▊      | 127/336 [09:56<14:54,  4.28s/it]
 38%|███▊      | 128/336 [09:59<13:55,  4.02s/it]
 38%|███▊      | 129/336 [10:04<15:06,  4.38s/it]
 39%|███▊      | 130/336 [10:08<14:44,  4.30s/it]
 39%|███▉      | 131/336 [10:12<13:44,  4.02s/it]
 39%|███▉      | 132/336 [10:16<13:54,  4.09s/it]
 40%|███▉      | 133/336 [10:21<14:28,  4.28s/it]
 40%|███▉      | 134/336 [10:25<14:30,  4.31s/it]
 40%|████      | 135/336 [10:30<15:27,  4.62s/it]
 40%|████      | 136/336 [10:36<16:08,  4.84s/it]cur_prompt: Are there three people appear in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.0150, -1.7598, -0.0150, -0.0150, -0.0150, -0.0150, -1.7598, -0.0150,
        -0.0150, -0.0150])
regular_entropy: 0.36398690938949585
regular_entropy_rao: 0.7240811586380005
semantic_ids: [0, 1, 0, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0427), tensor(-3.1738)]
semantic_entropy: 1.6082863807678223
log_probs: tensor([-0.0427, -3.1738])
semantic_entropy_rao: 0.17375785112380981
cur_prompt: Are there only two people appear in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.1926, -0.1926, -0.1926, -0.1926, -0.1926, -0.1926, -0.1926, -0.1926,
        -0.1926, -0.5702])
regular_entropy: 0.23036205768585205
regular_entropy_rao: 1.7521388530731201
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0734), tensor(-2.6482)]
semantic_entropy: 1.3608195781707764
log_probs: tensor([-0.0734, -2.6482])
semantic_entropy_rao: 0.255641907453537
cur_prompt: Is there only one dog in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0162, -0.0162, -0.0162, -0.0162, -0.0162, -0.0162, -0.0162, -0.0162,
        -0.0162, -0.0162])
regular_entropy: 0.016230477020144463
regular_entropy_rao: 0.1596917361021042
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there two dogs in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1545, -0.1545, -0.1545, -0.1545, -0.6624, -0.6624, -0.6624, -0.1545,
        -0.1545, -0.1545])
regular_entropy: 0.3068854808807373
regular_entropy_rao: 1.9514888525009155
semantic_ids: [0, 0, 0, 0, 1, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2295), tensor(-1.5846)]
semantic_entropy: 0.9070137739181519
log_probs: tensor([-0.2295, -1.5846])
semantic_entropy_rao: 0.5073052048683167
cur_prompt: Is there only one necktie in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.0886, -0.0886, -0.0886, -0.0886, -0.0886, -0.0886, -0.0886, -0.0886,
        -0.9089, -0.0886])
regular_entropy: 0.17062687873840332
regular_entropy_rao: 1.0960137844085693
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0478), tensor(-3.0653)]
semantic_entropy: 1.5565310716629028
log_probs: tensor([-0.0478, -3.0653])
semantic_entropy_rao: 0.1885000765323639
cur_prompt: Is there three neckties in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0095, -0.0095, -0.0095, -0.0095, -0.0095, -0.0095, -0.0095, -0.0095,
        -0.0095, -0.0095])
regular_entropy: 0.009457461535930634
regular_entropy_rao: 0.09368439763784409
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Are there two horses in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.0204, -0.0204, -0.0204, -0.0204, -0.0204, -0.0204, -1.6090, -0.0204,
        -0.0204, -0.0204])
regular_entropy: 0.17928454279899597
regular_entropy_rao: 0.5020998120307922
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0224), tensor(-3.8082)]
semantic_entropy: 1.9153207540512085
log_probs: tensor([-0.0224, -3.8082])
semantic_entropy_rao: 0.10643631964921951
cur_prompt: Is there only one horse in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no']
log_probs: tensor([-0.2532, -0.2532, -0.2532, -0.2532, -0.4615, -0.2532, -0.2532, -0.2532,
        -0.4615, -0.4615])
regular_entropy: 0.31568023562431335
regular_entropy_rao: 2.24857234954834
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2986), tensor(-1.3542)]
semantic_entropy: 0.8264176845550537
log_probs: tensor([-0.2986, -1.3542])
semantic_entropy_rao: 0.5711078643798828
cur_prompt: Are there three zippers in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.1260, -0.1260, -0.1260, -0.1260, -0.1260, -0.1260, -0.1260, -0.1260,
        -0.7510, -0.1260])
regular_entropy: 0.18846452236175537
regular_entropy_rao: 1.3538936376571655
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0578), tensor(-2.8800)]
semantic_entropy: 1.4688844680786133
log_probs: tensor([-0.0578, -2.8800])
semantic_entropy_rao: 0.21619753539562225
cur_prompt: Is there a zipper in the picture?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0680, -0.0680, -1.0315, -0.0680, -1.0315, -1.0315, -0.0680, -0.0680,
        -0.0680, -0.0680])
regular_entropy: 0.35701459646224976
regular_entropy_rao: 1.5475199222564697
semantic_ids: [0, 0, 1, 0, 1, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.1514), tensor(-1.9623)]
semantic_entropy: 1.0568666458129883
log_probs: tensor([-0.1514, -1.9623])
semantic_entropy_rao: 0.4059368371963501
cur_prompt: Are there four dogs appear in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2801, -0.2801, -0.2801, -0.2801, -0.4233, -0.2801, -0.2801, -0.4233,
        -0.4233, -0.4233])
regular_entropy: 0.3373619616031647
regular_entropy_rao: 2.3787920475006104
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 1, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.4560), tensor(-1.0047)]
semantic_entropy: 0.7303175926208496
log_probs: tensor([-0.4560, -1.0047])
semantic_entropy_rao: 0.656884491443634
cur_prompt: Are there only three dogs appear in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.0951, -0.0951, -0.8764, -0.0951, -0.0951, -0.0951, -0.0951, -0.8764,
        -0.0951, -0.0951])
regular_entropy: 0.2513996362686157
regular_entropy_rao: 1.4217619895935059
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879

 41%|████      | 137/336 [10:40<15:52,  4.79s/it]
 41%|████      | 138/336 [10:46<16:34,  5.02s/it]
 41%|████▏     | 139/336 [10:51<16:36,  5.06s/it]
 42%|████▏     | 140/336 [10:56<16:08,  4.94s/it]
 42%|████▏     | 141/336 [11:01<15:48,  4.87s/it]
 42%|████▏     | 142/336 [11:04<14:14,  4.40s/it]
 43%|████▎     | 143/336 [11:07<13:09,  4.09s/it]
 43%|████▎     | 144/336 [11:11<12:30,  3.91s/it]
 43%|████▎     | 145/336 [11:14<12:06,  3.80s/it]
 43%|████▎     | 146/336 [11:21<14:27,  4.57s/it]
 44%|████▍     | 147/336 [11:24<13:12,  4.19s/it]
 44%|████▍     | 148/336 [11:27<12:11,  3.89s/it]log_likelihood_per_semantic_id: [tensor(-0.1084), tensor(-2.2759)]
semantic_entropy: 1.1921405792236328
log_probs: tensor([-0.1084, -2.2759])
semantic_entropy_rao: 0.3309819996356964
cur_prompt: Are there three laptops in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.2914, -0.2914, -0.4086, -0.2914, -0.2914, -0.4086, -0.2914, -0.4086,
        -0.2914, -0.2914])
regular_entropy: 0.3265623152256012
regular_entropy_rao: 2.338829755783081
semantic_ids: [0, 0, 1, 0, 0, 1, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3229), tensor(-1.2874)]
semantic_entropy: 0.8051804900169373
log_probs: tensor([-0.3229, -1.2874])
semantic_entropy_rao: 0.5891174077987671
cur_prompt: Are there four laptops in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.0632, -1.0658, -0.0632, -0.0632, -0.0632, -0.0632, -0.0632, -0.0632,
        -0.0632, -1.0658])
regular_entropy: 0.26367512345314026
regular_entropy_rao: 1.2085500955581665
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0878), tensor(-2.4767)]
semantic_entropy: 1.2822133302688599
log_probs: tensor([-0.0878, -2.4767])
semantic_entropy_rao: 0.2884872555732727
cur_prompt: Is there only one ship in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.4854, -0.4854, -0.2380, -0.2380, -0.2380, -0.2380, -0.2380, -0.4854,
        -0.4854, -0.2380])
regular_entropy: 0.33698228001594543
regular_entropy_rao: 2.320625066757202
semantic_ids: [0, 0, 1, 1, 1, 1, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.0719), tensor(-0.4191)]
semantic_entropy: 0.7455053329467773
log_probs: tensor([-1.0719, -0.4191])
semantic_entropy_rao: 0.6425789594650269
cur_prompt: Is there a total of two ships in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2054, -0.2054, -0.2054, -0.5440, -0.2054, -0.5440, -0.2054, -0.2054,
        -0.2054, -0.2054])
regular_entropy: 0.27313268184661865
regular_entropy_rao: 1.969700574874878
semantic_ids: [0, 0, 0, 1, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1640), tensor(-1.8888)]
semantic_entropy: 1.0264074802398682
log_probs: tensor([-0.1640, -1.8888])
semantic_entropy_rao: 0.4248701333999634
cur_prompt: Is there no person in this picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0110, -0.0110, -0.0110, -0.0110, -0.0110, -0.0110, -0.0110, -0.0110,
        -0.0110, -0.0110])
regular_entropy: 0.01103933248668909
regular_entropy_rao: 0.10918137431144714
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Are there two people appear in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0494, -0.0494, -0.0494, -0.0494, -0.0494, -0.0494, -0.0494, -0.0494,
        -0.0494, -0.0494])
regular_entropy: 0.0493636429309845
regular_entropy_rao: 0.46986040472984314
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Are there two bath towels in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0749, -0.0749, -0.0749, -0.0749, -0.0749, -0.0749, -0.0749, -0.0749,
        -0.0749, -0.0749])
regular_entropy: 0.0748792216181755
regular_entropy_rao: 0.6947709918022156
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there only one bath towel in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0292, -0.0292, -0.0292, -0.0292, -0.0292, -0.0292, -0.0292, -0.0292,
        -0.0292, -0.0292])
regular_entropy: 0.029160235077142715
regular_entropy_rao: 0.28322193026542664
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a blue and yellow fire hydrant in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.2144, -0.2144, -0.5269, -0.5269, -0.5269, -0.5269, -0.2144, -0.2144,
        -0.2144, -0.2144])
regular_entropy: 0.33935031294822693
regular_entropy_rao: 2.28230881690979
semantic_ids: [0, 0, 1, 1, 1, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3973), tensor(-1.1152)]
semantic_entropy: 0.7562432289123535
log_probs: tensor([-0.3973, -1.1152])
semantic_entropy_rao: 0.6326392889022827
cur_prompt: Is there a blue and orange fire hydrant in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0047, -0.0047, -0.0047, -0.0047, -0.0047, -0.0047, -0.0047, -0.0047,
        -0.0047, -0.0047])
regular_entropy: 0.004704151768237352
regular_entropy_rao: 0.0468207485973835
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a white plate in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,
        -0.0004, -0.0004])
regular_entropy: 0.00041932164458557963
regular_entropy_rao: 0.0041914586909115314
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a yellow plate in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018,
        -0.0018, -0.0018])
regular_entropy: 0.0017538269748911262
regular_entropy_rao: 0.017507540062069893
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0

 44%|████▍     | 149/336 [11:30<11:32,  3.70s/it]
 45%|████▍     | 150/336 [11:34<11:23,  3.67s/it]
 45%|████▍     | 151/336 [11:37<10:58,  3.56s/it]
 45%|████▌     | 152/336 [11:41<10:42,  3.49s/it]
 46%|████▌     | 153/336 [11:45<11:17,  3.70s/it]
 46%|████▌     | 154/336 [11:48<11:01,  3.63s/it]
 46%|████▌     | 155/336 [11:52<10:34,  3.50s/it]
 46%|████▋     | 156/336 [11:56<11:10,  3.73s/it]
 47%|████▋     | 157/336 [11:59<11:00,  3.69s/it]
 47%|████▋     | 158/336 [12:04<12:06,  4.08s/it]
 47%|████▋     | 159/336 [12:07<10:57,  3.71s/it]
 48%|████▊     | 160/336 [12:10<10:06,  3.44s/it]
 48%|████▊     | 161/336 [12:14<10:27,  3.59s/it]cur_prompt: Are there any green beans in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0110, -0.0110, -0.0110, -0.0110, -0.0110, -0.0110, -0.0110, -0.0110,
        -0.0110, -0.0110])
regular_entropy: 0.01103933248668909
regular_entropy_rao: 0.10918137431144714
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Are there any orange beans in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,
        -0.0022, -0.0022])
regular_entropy: 0.0021592178381979465
regular_entropy_rao: 0.02154560759663582
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a red coat in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001,
        -0.0001, -0.0001])
regular_entropy: 0.00012014852836728096
regular_entropy_rao: 0.0012013409286737442
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a yellow coat in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.0250, -0.0250, -0.0250, -0.0250, -0.0250, -0.0250, -0.0250, -0.0250,
        -0.0250, -1.5094])
regular_entropy: 0.17348337173461914
regular_entropy_rao: 0.5534763932228088
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0249), tensor(-3.7065)]
semantic_entropy: 1.8656706809997559
log_probs: tensor([-0.0249, -3.7065])
semantic_entropy_rao: 0.11530600488185883
cur_prompt: Is there a brown and white animal in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023,
        -0.0023, -0.0023])
regular_entropy: 0.002274399157613516
regular_entropy_rao: 0.022692320868372917
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(-2.9802e-07)]
semantic_entropy: 2.98023280720372e-07
log_probs: tensor([-2.9802e-07])
semantic_entropy_rao: 2.980231954552437e-07
cur_prompt: Is there a green and red animal in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0083, -0.0083, -0.0083, -0.0083, -0.0083, -0.0083, -0.0083, -0.0083,
        -0.0083, -0.0083])
regular_entropy: 0.008312365040183067
regular_entropy_rao: 0.08243554085493088
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a green hat in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0238, -1.5342, -0.0238, -0.0238, -0.0238, -0.0238, -0.0238, -0.0238,
        -0.0238, -0.0238])
regular_entropy: 0.17484615743160248
regular_entropy_rao: 0.540015697479248
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0242), tensor(-3.7319)]
semantic_entropy: 1.8780595064163208
log_probs: tensor([-0.0242, -3.7319])
semantic_entropy_rao: 0.11302905529737473
cur_prompt: Is there a red hat in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0244, -0.0244, -0.0244, -0.0244, -0.0244, -0.0244, -0.0244, -0.0244,
        -0.0244, -0.0244])
regular_entropy: 0.024417536333203316
regular_entropy_rao: 0.2382853925228119
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a skateboard with red wheels in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']
log_probs: tensor([-0.1765, -0.1765, -0.1765, -0.1765, -0.1765, -0.6062, -0.6062, -0.1765,
        -0.1765, -0.6062])
regular_entropy: 0.3054397702217102
regular_entropy_rao: 2.027669906616211
semantic_ids: [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2460), tensor(-1.5230)]
semantic_entropy: 0.8844746947288513
log_probs: tensor([-0.2460, -1.5230])
semantic_entropy_rao: 0.524446427822113
cur_prompt: Is there a skateboard with black wheels in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0032, -0.0032, -0.0032, -0.0032, -0.0032, -0.0032, -0.0032, -0.0032,
        -0.0032, -0.0032])
regular_entropy: 0.003187843132764101
regular_entropy_rao: 0.031776972115039825
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a white plate in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006,
        -0.0006, -0.0006])
regular_entropy: 0.0005730681004934013
regular_entropy_rao: 0.005727397743612528
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a yellow plate in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002,
        -0.0002, -0.0002])
regular_entropy: 0.0001600128598511219
regular_entropy_rao: 0.0015998726012185216
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a man wearing a red shirt in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes']

 48%|████▊     | 162/336 [12:19<11:33,  3.98s/it]
 49%|████▊     | 163/336 [12:23<11:19,  3.93s/it]
 49%|████▉     | 164/336 [12:26<10:51,  3.79s/it]
 49%|████▉     | 165/336 [12:30<10:29,  3.68s/it]
 49%|████▉     | 166/336 [12:33<10:16,  3.63s/it]
 50%|████▉     | 167/336 [12:36<09:58,  3.54s/it]
 50%|█████     | 168/336 [12:40<09:45,  3.48s/it]
 50%|█████     | 169/336 [12:43<09:45,  3.50s/it]
 51%|█████     | 170/336 [12:47<09:46,  3.53s/it]
 51%|█████     | 171/336 [12:52<10:57,  3.98s/it]
 51%|█████     | 172/336 [12:57<11:37,  4.25s/it]
 51%|█████▏    | 173/336 [13:01<11:38,  4.29s/it]log_probs: tensor([-0.1289, -0.7409, -0.7409, -0.1289, -0.1289, -0.7409, -0.1289, -0.1289,
        -0.1289, -0.7409])
regular_entropy: 0.3736853003501892
regular_entropy_rao: 2.0925276279449463
semantic_ids: [0, 1, 1, 0, 0, 1, 0, 0, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3086), tensor(-1.3260)]
semantic_entropy: 0.8173221349716187
log_probs: tensor([-0.3086, -1.3260])
semantic_entropy_rao: 0.5787575244903564
cur_prompt: Is there a man wearing a white shirt in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002,
        -0.0002, -0.0002])
regular_entropy: 0.00016424340719822794
regular_entropy_rao: 0.0016421647742390633
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a red couch in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0257, -0.0257, -0.0257, -0.0257, -0.0257, -0.0257, -0.0257, -0.0257,
        -0.0257, -0.0257])
regular_entropy: 0.025689978152513504
regular_entropy_rao: 0.2503840923309326
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a black couch in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029,
        -0.0029, -0.0029])
regular_entropy: 0.0029489288572221994
regular_entropy_rao: 0.02940245158970356
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a living room painted yellow in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,
        -0.0004, -0.0004])
regular_entropy: 0.0004085421096533537
regular_entropy_rao: 0.004083752166479826
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a living room painted black in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,
        -0.0004, -0.0004])
regular_entropy: 0.0004303390742279589
regular_entropy_rao: 0.004301539622247219
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a red boat in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0215, -0.0215, -0.0215, -0.0215, -0.0215, -0.0215, -0.0215, -0.0215,
        -0.0215, -0.0215])
regular_entropy: 0.02149955742061138
regular_entropy_rao: 0.2104225754737854
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a gray boat in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122,
        -0.0122, -0.0122])
regular_entropy: 0.012236551381647587
regular_entropy_rao: 0.12087731808423996
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is it appropriate to wear a down jacket during the season in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0046, -0.0046, -0.0046, -0.0046, -0.0046, -0.0046, -0.0046, -0.0046,
        -0.0046, -0.0046])
regular_entropy: 0.004583742003887892
regular_entropy_rao: 0.045627791434526443
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is it appropriate to only wear short sleeves during the season in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.4233, -0.2801, -0.2801, -0.4233, -0.4233, -0.4233, -0.2801, -0.2801,
        -0.4233, -0.2801])
regular_entropy: 0.3516848087310791
regular_entropy_rao: 2.444345235824585
semantic_ids: [0, 1, 1, 0, 0, 0, 1, 1, 0, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.7673), tensor(-0.6241)]
semantic_entropy: 0.695709228515625
log_probs: tensor([-0.7673, -0.6241])
semantic_entropy_rao: 0.690589427947998
cur_prompt: I want to go skating. Is the shoe in the picture usually appropriate?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1545, -0.1545, -0.1545, -0.1545, -0.6624, -0.1545, -0.1545, -0.1545,
        -0.1545, -0.1545])
regular_entropy: 0.20532293617725372
regular_entropy_rao: 1.5332465171813965
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0647), tensor(-2.7698)]
semantic_entropy: 1.417245626449585
log_probs: tensor([-0.0647, -2.7698])
semantic_entropy_rao: 0.2342701256275177
cur_prompt: I want to go roller skating. Is the shoe in the picture usually appropriate?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0150, -1.7598, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150,
        -0.0150, -0.0150])
regular_entropy: 0.18950781226158142
regular_entropy_rao: 0.43606314063072205
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0192), tensor(-3.9612)]
semantic_entropy: 1.9902310371398926
log_probs: tensor([-0.0192, -3.9612])
semantic_entropy_rao: 0.09427721053361893
cur_prompt: Can the item in the picture be used to measure length?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.1349, -0.1349, -0.1349, -0.1349, -0.7209, -0.1349, -0.7209, -0.1349,
        -0.1349, -0.7209])
regular_entropy: 0.310712993144989

 52%|█████▏    | 174/336 [13:06<12:20,  4.57s/it]
 52%|█████▏    | 175/336 [13:10<11:26,  4.26s/it]
 52%|█████▏    | 176/336 [13:15<12:00,  4.50s/it]
 53%|█████▎    | 177/336 [13:20<12:30,  4.72s/it]
 53%|█████▎    | 178/336 [13:25<12:29,  4.75s/it]
 53%|█████▎    | 179/336 [13:30<12:52,  4.92s/it]
 54%|█████▎    | 180/336 [13:35<12:41,  4.88s/it]
 54%|█████▍    | 181/336 [13:38<11:17,  4.37s/it]
 54%|█████▍    | 182/336 [13:43<11:49,  4.60s/it]
 54%|█████▍    | 183/336 [13:47<11:04,  4.34s/it]
 55%|█████▍    | 184/336 [13:52<11:35,  4.57s/it]regular_entropy_rao: 1.8770397901535034
semantic_ids: [0, 0, 0, 0, 1, 0, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2139), tensor(-1.6472)]
semantic_entropy: 0.9305475950241089
log_probs: tensor([-0.2139, -1.6472])
semantic_entropy_rao: 0.48996400833129883
cur_prompt: Can the item in the picture be used to measure angles?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0840, -0.0840, -0.0840, -0.0840, -0.0840, -0.0840, -0.0840, -0.0840,
        -0.0840, -0.0840])
regular_entropy: 0.0840059295296669
regular_entropy_rao: 0.7723720669746399
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: The three cats in the picture, the one without a beard, is the middle one?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.4395, -0.4395, -0.2702, -0.4395, -0.2702, -0.2702, -0.4395, -0.4395,
        -0.2702, -0.4395])
regular_entropy: 0.37176141142845154
regular_entropy_rao: 2.524000883102417
semantic_ids: [0, 0, 1, 0, 1, 1, 0, 0, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5820), tensor(-0.8182)]
semantic_entropy: 0.7001044750213623
log_probs: tensor([-0.5820, -0.8182])
semantic_entropy_rao: 0.6862220168113708
cur_prompt: The three cats in the picture, the one without a beard, is the right one?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.3733, -0.3212, -0.3733, -0.3733, -0.3733, -0.3733, -0.3212, -0.3212,
        -0.3212, -0.3212])
regular_entropy: 0.347251832485199
regular_entropy_rao: 2.449815511703491
semantic_ids: [0, 1, 0, 0, 0, 0, 1, 1, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.7195), tensor(-0.6674)]
semantic_entropy: 0.6934863328933716
log_probs: tensor([-0.7195, -0.6674])
semantic_entropy_rao: 0.6928082704544067
cur_prompt: Is it a good time to walk through the road in the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0415, -0.0415, -0.0415, -1.2654, -0.0415, -0.0415, -0.0415, -0.0415,
        -0.0415, -0.0415])
regular_entropy: 0.1638648808002472
regular_entropy_rao: 0.7150610685348511
semantic_ids: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0322), tensor(-3.4533)]
semantic_entropy: 1.7427431344985962
log_probs: tensor([-0.0322, -3.4533])
semantic_entropy_rao: 0.14039748907089233
cur_prompt: Is it a good time to drive a car through the road in the picture?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.1349, -0.1349, -0.7209, -0.7209, -0.1349, -0.1349, -0.1349, -0.7209,
        -0.1349, -0.1349])
regular_entropy: 0.310712993144989
regular_entropy_rao: 1.8770397901535034
semantic_ids: [0, 0, 1, 1, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.2139), tensor(-1.6472)]
semantic_entropy: 0.9305475950241089
log_probs: tensor([-0.2139, -1.6472])
semantic_entropy_rao: 0.48996400833129883
cur_prompt: In this line chart, the vertical axis is height and the horizontal axis is age. Does Maria's height exceed Jane's height in the end?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.0805, -0.0805, -0.0805, -0.9529, -0.0805, -0.0805, -0.0805, -0.9529,
        -0.0805, -0.0805])
regular_entropy: 0.2549775540828705
regular_entropy_rao: 1.329097032546997
semantic_ids: [0, 0, 0, 1, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0994), tensor(-2.3581)]
semantic_entropy: 1.2287256717681885
log_probs: tensor([-0.0994, -2.3581])
semantic_entropy_rao: 0.31305912137031555
cur_prompt: In this line chart, the vertical axis is height and the horizontal axis is age. Does Jane's height exceed Kangkang's height in the end?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,
        -0.0013, -0.0013])
regular_entropy: 0.0013175515923649073
regular_entropy_rao: 0.013158170506358147
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Can the item in the picture output water?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.0573, -0.0573, -0.0573, -0.0573, -0.0573, -0.0573, -0.0573, -0.0573,
        -0.0573, -1.1119])
regular_entropy: 0.1627192497253418
regular_entropy_rao: 0.8523240685462952
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0380), tensor(-3.2899)]
semantic_entropy: 1.663926124572754
log_probs: tensor([-0.0380, -3.2899])
semantic_entropy_rao: 0.1591305434703827
cur_prompt: Can the item in picture be used for blowing air?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081,
        -0.0081, -0.0081])
regular_entropy: 0.0081017492339015
regular_entropy_rao: 0.08036375790834427
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: I feel very thirsty in the desert now. Can the thing in the picture help me?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.2584, -0.2584, -0.2584, -0.2584, -0.2584, -0.2584, -0.4537, -0.2584,
        -0.4537, -0.4537])
regular_entropy: 0.3169877827167511
regular_entropy_rao: 2.2615652084350586
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3020), tensor(-1.3446)]
semantic_entropy: 0.823284387588501
log_probs: tensor([-0.3020, -1.3446])
semantic_entropy_rao: 0.5737321376800537
cur_prompt: I don't like clear cups. Is the cup in the picture my type?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1511, -0.1511, -0.6719, -0.1511, -0.1511, -0.1511, -0.1511, -0.1511,
        -0.1511, -0.1511])
regular_entropy: 0.2031964510679245
regular_entropy_rao: 1.5124489068984985
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0639), tensor(-2.7820)]
semantic_entropy: 1.4229443073272705
log_probs: tensor([-0.0639, -2.7820])

 55%|█████▌    | 185/336 [13:57<11:31,  4.58s/it]
 55%|█████▌    | 186/336 [14:01<11:15,  4.51s/it]
 56%|█████▌    | 187/336 [14:06<11:33,  4.66s/it]
 56%|█████▌    | 188/336 [14:10<10:44,  4.35s/it]
 56%|█████▋    | 189/336 [14:15<10:58,  4.48s/it]
 57%|█████▋    | 190/336 [14:20<11:39,  4.79s/it]
 57%|█████▋    | 191/336 [14:24<10:45,  4.45s/it]
 57%|█████▋    | 192/336 [14:27<10:04,  4.20s/it]
 57%|█████▋    | 193/336 [14:31<09:34,  4.02s/it]
 58%|█████▊    | 194/336 [14:35<09:12,  3.89s/it]
 58%|█████▊    | 195/336 [14:38<08:39,  3.69s/it]
 58%|█████▊    | 196/336 [14:43<09:29,  4.07s/it]semantic_entropy_rao: 0.23220789432525635
cur_prompt: I want to carry one thing with me on a rainy day. Is the thing in the image an appropriate choice?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0974, -0.0974, -0.0974, -0.0974, -0.8657, -0.0974, -0.0974, -0.0974,
        -0.0974, -0.0974])
regular_entropy: 0.17425353825092316
regular_entropy_rao: 1.15971839427948
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0503), tensor(-3.0157)]
semantic_entropy: 1.5329794883728027
log_probs: tensor([-0.0503, -3.0157])
semantic_entropy_rao: 0.19559337198734283
cur_prompt: It is raining outside. I am in a house and I don't need to go out. Is this thing in the picture necessary for me to use?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.4935, -0.2331, -0.4935, -0.2331, -0.4935, -0.4935, -0.4935, -0.4935,
        -0.2331, -0.2331])
regular_entropy: 0.389381468296051
regular_entropy_rao: 2.546344041824341
semantic_ids: [0, 1, 0, 1, 0, 0, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.6233), tensor(-0.7683)]
semantic_entropy: 0.6957747936248779
log_probs: tensor([-0.6233, -0.7683])
semantic_entropy_rao: 0.6905243396759033
cur_prompt: I am going to a formal dinner party. Is the shoe in the picture an appropriate choice?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0051, -0.0051, -0.0051, -0.0051, -0.0051, -0.0051, -0.0051, -0.0051,
        -0.0051, -0.0051])
regular_entropy: 0.005084443837404251
regular_entropy_rao: 0.050586577504873276
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: I am going to play basketball. Is the shoe in the picture an appropriate choice?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.5971, -0.5971, -0.1804, -0.1804, -0.1804, -0.1804, -0.1804, -0.1804,
        -0.1804, -0.5971])
regular_entropy: 0.30544447898864746
regular_entropy_rao: 2.0405197143554688
semantic_ids: [0, 0, 1, 1, 1, 1, 1, 1, 1, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.5128), tensor(-0.2488)]
semantic_entropy: 0.8808183073997498
log_probs: tensor([-1.5128, -0.2488])
semantic_entropy_rao: 0.5272777676582336
cur_prompt: All apples are shown in the picture. If I eat an apple every day, can I eat it for four days?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.4233, -0.2801, -0.2801, -0.2801, -0.4233, -0.2801, -0.4233, -0.2801,
        -0.2801, -0.2801])
regular_entropy: 0.3230428695678711
regular_entropy_rao: 2.3132565021514893
semantic_ids: [0, 1, 1, 1, 0, 1, 0, 1, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.3063), tensor(-0.3158)]
semantic_entropy: 0.8110818266868591
log_probs: tensor([-1.3063, -0.3158])
semantic_entropy_rao: 0.584060549736023
cur_prompt: All apples are shown in the picture. If I eat an apple every day, can I eat it for three days?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0026, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026,
        -0.0026, -0.0026])
regular_entropy: 0.002589838346466422
regular_entropy_rao: 0.025831399485468864
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is it unhealthy to eat the food in the picture too often?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0323, -0.0323, -0.0323, -0.0323, -0.0323, -0.0323, -0.0323, -0.0323,
        -0.0323, -0.0323])
regular_entropy: 0.03226035088300705
regular_entropy_rao: 0.31236228346824646
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the food in the picture usually low in calories?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0026, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026,
        -0.0026, -0.0026])
regular_entropy: 0.002589838346466422
regular_entropy_rao: 0.025831399485468864
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the pineapple on the left of the pot in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0250, -0.0250, -0.0250, -0.0250, -0.0250, -0.0250, -0.0250, -0.0250,
        -0.0250, -0.0250])
regular_entropy: 0.025045860558748245
regular_entropy_rao: 0.24426354467868805
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the pineapple on the right of the pot in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014,
        -0.0014, -0.0014])
regular_entropy: 0.001352268154732883
regular_entropy_rao: 0.013504408299922943
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the dog above the pool in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.3401, -0.3401, -0.3401, -0.3401, -0.3531, -0.3531, -0.3401, -0.3401,
        -0.3531, -0.3401])
regular_entropy: 0.34401172399520874
regular_entropy_rao: 2.43856143951416
semantic_ids: [0, 0, 0, 0, 1, 1, 0, 0, 1, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3528), tensor(-1.2131)]
semantic_entropy: 0.7829461097717285
log_probs: tensor([-0.3528, -1.2131])
semantic_entropy_rao: 0.6085357069969177
cur_prompt: Is the dog under the pool in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0059, -0.0059, -2.2195, -0.0059, -0.0059, -0.0059, -0.0059, -0.0059,
        -0.0059, -0.0059])
regular_entropy: 0.22729353606700897
regular_entropy_rao: 0.29431748390197754
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
 59%|█████▊    | 197/336 [14:48<09:58,  4.31s/it]
 59%|█████▉    | 198/336 [14:51<09:23,  4.08s/it]
 59%|█████▉    | 199/336 [14:55<08:45,  3.83s/it]
 60%|█████▉    | 200/336 [14:58<08:17,  3.66s/it]
 60%|█████▉    | 201/336 [15:01<08:09,  3.62s/it]
 60%|██████    | 202/336 [15:05<08:07,  3.64s/it]
 60%|██████    | 203/336 [15:09<08:02,  3.63s/it]
 61%|██████    | 204/336 [15:13<08:46,  3.99s/it]
 61%|██████    | 205/336 [15:18<08:47,  4.03s/it]
 61%|██████▏   | 206/336 [15:21<08:31,  3.93s/it]
 62%|██████▏   | 207/336 [15:25<08:01,  3.73s/it]
 62%|██████▏   | 208/336 [15:28<07:36,  3.57s/it]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0121), tensor(-4.4228)]
semantic_entropy: 2.217456340789795
log_probs: tensor([-0.0121, -4.4228])
semantic_entropy_rao: 0.06500209122896194
cur_prompt: Is the big red and black umbrella on the top of people?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008,
        -0.0008, -0.0008])
regular_entropy: 0.0007830682443454862
regular_entropy_rao: 0.007824554108083248
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is the big red and black umbrella under people?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,
        -0.0004, -0.0004])
regular_entropy: 0.0003980601322837174
regular_entropy_rao: 0.003979017026722431
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the person on the right of the train?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042,
        -0.0042, -0.0042])
regular_entropy: 0.004240717273205519
regular_entropy_rao: 0.042227718979120255
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the person on the left of the train?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042,
        -0.0042, -0.0042])
regular_entropy: 0.004240776877850294
regular_entropy_rao: 0.042228300124406815
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Are the pedestrians on the right of the bus?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007,
        -0.0007, -0.0007])
regular_entropy: 0.0006698649376630783
regular_entropy_rao: 0.006694164127111435
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(-2.9802e-07)]
semantic_entropy: 2.98023280720372e-07
log_probs: tensor([-2.9802e-07])
semantic_entropy_rao: 2.980231954552437e-07
cur_prompt: Are the pedestrians on the left of the bus?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0129, -0.0129, -0.0129, -0.0129, -0.0129, -0.0129, -0.0129, -0.0129,
        -0.0129, -0.0129])
regular_entropy: 0.012882448732852936
regular_entropy_rao: 0.12717558443546295
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the white mouse on the right of the black keyboard?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.3401, -0.3531, -0.3531, -0.3531, -0.3401, -0.3401, -0.3531, -0.3401,
        -0.3401, -0.3531])
regular_entropy: 0.3466159999370575
regular_entropy_rao: 2.4505934715270996
semantic_ids: [0, 1, 1, 1, 0, 0, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.6867), tensor(-0.6997)]
semantic_entropy: 0.6931684613227844
log_probs: tensor([-0.6867, -0.6997])
semantic_entropy_rao: 0.6931259632110596
cur_prompt: Is the white mouse on the left of the black keyboard?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-1.2159e-05, -1.2159e-05, -1.2159e-05, -1.2159e-05, -1.2159e-05,
        -1.2159e-05, -1.2159e-05, -1.2159e-05, -1.2159e-05, -1.2159e-05])
regular_entropy: 1.2159200196038e-05
regular_entropy_rao: 0.00012159049947513267
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is the refrigerator on the left side of the picture?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-2.4557e-05, -2.4557e-05, -2.4557e-05, -2.4557e-05, -2.4557e-05,
        -2.4557e-05, -2.4557e-05, -2.4557e-05, -2.4557e-05, -2.4557e-05])
regular_entropy: 2.4556506105000153e-05
regular_entropy_rao: 0.00024555905838496983
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is the refrigerator on the right side of the picture
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001,
        -0.0001, -0.0001])
regular_entropy: 0.00011407026613596827
regular_entropy_rao: 0.0011405725963413715
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is the light above the computer in the image?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016,
        -0.0016, -0.0016])
regular_entropy: 0.0015805985312908888
regular_entropy_rao: 0.015781020745635033
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the light under the computer in the image?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.0974, -0.0974, -0.0974, -0.0974, -0.0974, -0.0974, -0.0974, -0.8657,
        -0.0974, -0.0974])
regular_entropy: 0.17425331473350525
regular_entropy_rao: 1.159717082977295
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]

 62%|██████▏   | 209/336 [15:32<08:04,  3.82s/it]
 62%|██████▎   | 210/336 [15:38<09:04,  4.32s/it]
 63%|██████▎   | 211/336 [15:41<08:42,  4.18s/it]
 63%|██████▎   | 212/336 [15:45<08:16,  4.00s/it]
 63%|██████▎   | 213/336 [15:49<07:55,  3.87s/it]
 64%|██████▎   | 214/336 [15:52<07:41,  3.78s/it]
 64%|██████▍   | 215/336 [15:56<07:42,  3.82s/it]
 64%|██████▍   | 216/336 [16:00<07:30,  3.76s/it]
 65%|██████▍   | 217/336 [16:05<08:09,  4.12s/it]
 65%|██████▍   | 218/336 [16:10<08:49,  4.49s/it]
 65%|██████▌   | 219/336 [16:15<08:57,  4.59s/it]
 65%|██████▌   | 220/336 [16:20<09:19,  4.82s/it]cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0503), tensor(-3.0157)]
semantic_entropy: 1.5329794883728027
log_probs: tensor([-0.0503, -3.0157])
semantic_entropy_rao: 0.19559337198734283
cur_prompt: Is the cricket bat above the batter's body?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']
log_probs: tensor([-0.3090, -0.3872, -0.3872, -0.3090, -0.3090, -0.3872, -0.3872, -0.3090,
        -0.3090, -0.3872])
regular_entropy: 0.3480980694293976
regular_entropy_rao: 2.448775053024292
semantic_ids: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.6548), tensor(-0.7330)]
semantic_entropy: 0.6939100027084351
log_probs: tensor([-0.6548, -0.7330])
semantic_entropy_rao: 0.6923848390579224
cur_prompt: Is the cricket bat under the batter's body
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0031, -0.0031, -0.0031, -0.0031, -0.0031, -0.0031, -0.0031, -0.0031,
        -0.0031, -0.0031])
regular_entropy: 0.0031061056070029736
regular_entropy_rao: 0.030964724719524384
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the baby on the right of the dog in the image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006,
        -0.0006, -0.0006])
regular_entropy: 0.0006036689155735075
regular_entropy_rao: 0.0060330466367304325
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the baby on the left of the dog in the image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-7.9208e-05, -7.9208e-05, -7.9208e-05, -7.9208e-05, -7.9208e-05,
        -7.9208e-05, -7.9208e-05, -7.9208e-05, -7.9208e-05, -7.9208e-05])
regular_entropy: 7.92082937550731e-05
regular_entropy_rao: 0.000792020233348012
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is the TV on the left of the bookshelf?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002,
        -0.0002, -0.0002])
regular_entropy: 0.00019707370665855706
regular_entropy_rao: 0.0019703488796949387
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the TV on the right of the bookshelf?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0244, -0.0244, -0.0244, -0.0244, -0.0244, -0.0244, -0.0244, -0.0244,
        -0.0244, -0.0244])
regular_entropy: 0.024417536333203316
regular_entropy_rao: 0.2382853925228119
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the blue umbrella under the black umbrella?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0366, -0.0366, -0.0366, -0.0366, -0.0366, -0.0366, -0.0366, -0.0366,
        -0.0366, -0.0366])
regular_entropy: 0.036586277186870575
regular_entropy_rao: 0.35271909832954407
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the blue umbrella above the black umbrella?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.4014, -0.2972, -0.2972, -0.2972, -0.4014, -0.2972, -0.4014, -0.2972,
        -0.2972, -0.2972])
regular_entropy: 0.3284483253955841
regular_entropy_rao: 2.351541519165039
semantic_ids: [0, 1, 1, 1, 0, 1, 0, 1, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-1.2780), tensor(-0.3265)]
semantic_entropy: 0.8022803068161011
log_probs: tensor([-1.2780, -0.3265])
semantic_entropy_rao: 0.5916171669960022
cur_prompt: Is the word in the logo "cold drinks"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes']
log_probs: tensor([-0.0845, -0.9308, -0.0845, -0.9308, -0.0845, -0.0845, -0.9308, -0.0845,
        -0.0845, -0.9308])
regular_entropy: 0.4230007529258728
regular_entropy_rao: 1.933542251586914
semantic_ids: [0, 1, 0, 1, 0, 0, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.2515), tensor(-1.5033)]
semantic_entropy: 0.8774337768554688
log_probs: tensor([-0.2515, -1.5033])
semantic_entropy_rao: 0.529910683631897
cur_prompt: Is the word in the logo "cold rinks"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -2.0910,
        -0.0077, -0.0077])
regular_entropy: 0.21602587401866913
regular_entropy_rao: 0.32706934213638306
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0137), tensor(-4.2943)]
semantic_entropy: 2.154019832611084
log_probs: tensor([-0.0137, -4.2943])
semantic_entropy_rao: 0.07215351611375809
cur_prompt: Is the word in the logo "penarth pier built 1894"?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no']
log_probs: tensor([-0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.4774,
        -0.2430, -0.4774])
regular_entropy: 0.2898716628551483
regular_entropy_rao: 2.1169419288635254
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1805), tensor(-1.8011)]
semantic_entropy: 0.9907931685447693
log_probs: tensor([-0.1805, -1.8011])
semantic_entropy_rao: 0.4480512738227844
cur_prompt: Is the word in the logo "penarth pies buid 1894"?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,
        -0.0010, -0.0010])
regular_entropy: 0.0009897087002173066
regular_entropy_rao: 0.00988729391247034
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

 66%|██████▌   | 221/336 [16:24<08:33,  4.47s/it]
 66%|██████▌   | 222/336 [16:28<08:16,  4.35s/it]
 66%|██████▋   | 223/336 [16:31<07:44,  4.11s/it]
 67%|██████▋   | 224/336 [16:36<08:00,  4.29s/it]
 67%|██████▋   | 225/336 [16:41<08:14,  4.46s/it]
 67%|██████▋   | 226/336 [16:46<08:17,  4.52s/it]
 68%|██████▊   | 227/336 [16:51<08:31,  4.69s/it]
 68%|██████▊   | 228/336 [16:56<08:50,  4.91s/it]
 68%|██████▊   | 229/336 [16:59<07:50,  4.40s/it]
 68%|██████▊   | 230/336 [17:04<07:54,  4.48s/it]
 69%|██████▉   | 231/336 [17:08<07:47,  4.45s/it]
 69%|██████▉   | 232/336 [17:13<07:45,  4.48s/it]cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the word in the picture "seabreeze motel"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122,
        -0.0122, -0.0122])
regular_entropy: 0.012237249873578548
regular_entropy_rao: 0.12088411301374435
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the word in the picture "seebreeze model"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0506, -0.0506, -0.0506, -0.0506, -0.0506, -0.0506, -0.0506, -0.0506,
        -0.0506, -0.0506])
regular_entropy: 0.05060213804244995
regular_entropy_rao: 0.4810526967048645
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the word in the logo "fenders diner"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.8443, -0.1021, -0.1021, -0.1021, -0.1021, -0.1021, -0.1021, -0.1021,
        -0.1021, -0.1021])
regular_entropy: 0.17635977268218994
regular_entropy_rao: 1.192941427230835
semantic_ids: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-2.9910), tensor(-0.0515)]
semantic_entropy: 1.5212512016296387
log_probs: tensor([-2.9910, -0.0515])
semantic_entropy_rao: 0.19921931624412537
cur_prompt: Is the word in the logo "finders diner"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-1.0773, -0.0616, -0.0616, -0.0616, -0.0616, -0.0616, -0.0616, -1.0773,
        -0.0616, -0.0616])
regular_entropy: 0.2647526264190674
regular_entropy_rao: 1.197227954864502
semantic_ids: [0, 1, 1, 1, 1, 1, 1, 0, 1, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-2.4886), tensor(-0.0867)]
semantic_entropy: 1.2876362800598145
log_probs: tensor([-2.4886, -0.0867])
semantic_entropy_rao: 0.2860994338989258
cur_prompt: Is the word in the logo "beavertails pastry"?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.1203, -0.1203, -0.1203, -0.1203, -0.1203, -0.1203, -0.7713, -0.1203,
        -0.1203, -0.1203])
regular_entropy: 0.18538905680179596
regular_entropy_rao: 1.3165358304977417
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0563), tensor(-2.9046)]
semantic_entropy: 1.4804610013961792
log_probs: tensor([-0.0563, -2.9046])
semantic_entropy_rao: 0.21233069896697998
cur_prompt: Is the word in the logo "beavertalls pastry"?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2637, -0.2637, -0.2637, -0.4460, -0.4460, -0.4460, -0.2637, -0.2637,
        -0.2637, -0.2637])
regular_entropy: 0.3183777630329132
regular_entropy_rao: 2.274535894393921
semantic_ids: [0, 0, 0, 1, 1, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3054), tensor(-1.3350)]
semantic_entropy: 0.8201842308044434
log_probs: tensor([-0.3054, -1.3350])
semantic_entropy_rao: 0.5763402581214905
cur_prompt: Is the phone number in the picture "0131 555 6363"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.3401, -0.3401, -0.3401, -0.3531, -0.3531, -0.3531, -0.3531, -0.3401,
        -0.3401, -0.3401])
regular_entropy: 0.345314621925354
regular_entropy_rao: 2.4445810317993164
semantic_ids: [0, 0, 0, 1, 1, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.5056), tensor(-0.9241)]
semantic_entropy: 0.7148804664611816
log_probs: tensor([-0.5056, -0.9241])
semantic_entropy_rao: 0.6717258095741272
cur_prompt: Is the phone number in the picture "0137 556 6363"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006,
        -0.0006, -0.0006])
regular_entropy: 0.0005730681004934013
regular_entropy_rao: 0.005727397743612528
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the text in the picture "hollywood"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.4694, -0.2481, -0.2481, -0.4694, -0.2481, -0.4694, -0.2481, -0.4694,
        -0.4694, -0.2481])
regular_entropy: 0.3587499260902405
regular_entropy_rao: 2.4356651306152344
semantic_ids: [0, 1, 1, 0, 1, 0, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.8099), tensor(-0.5886)]
semantic_entropy: 0.6992592811584473
log_probs: tensor([-0.8099, -0.5886])
semantic_entropy_rao: 0.6870596408843994
cur_prompt: Is the text in the picture "holly word"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0447, -0.0447, -0.0447, -0.0447, -0.0447, -1.2296, -0.0447, -0.0447,
        -0.0447, -0.0447])
regular_entropy: 0.16318146884441376
regular_entropy_rao: 0.7441951036453247
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0334), tensor(-3.4155)]
semantic_entropy: 1.724470615386963
log_probs: tensor([-0.0334, -3.4155])
semantic_entropy_rao: 0.1445441097021103
cur_prompt: Is the word in the logo "exchange hotel"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.4854, -0.2380, -0.2380, -0.2380, -0.2380, -0.2380, -0.2380, -0.2380,
        -0.2380, -0.2380])
regular_entropy: 0.26276296377182007
regular_entropy_rao: 1.9872021675109863
semantic_ids: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-2.5278), tensor(-0.0832)]
semantic_entropy: 1.3055102825164795
log_probs: tensor([-2.5278, -0.0832])
semantic_entropy_rao: 0.2783607542514801
cur_prompt: Is the word in the logo "excharge hotel"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.6154, -0.6154, -0.6154, -0.1727, -0.6154, -0.6154, -0.1727, -0.1727,
        -0.1727, -0.6154])
regular_entropy: 0.43832212686538696
regular_entropy_rao: 2.5766947269439697

 69%|██████▉   | 233/336 [17:18<07:56,  4.63s/it]
 70%|██████▉   | 234/336 [17:24<08:26,  4.96s/it]
 70%|██████▉   | 235/336 [17:29<08:33,  5.08s/it]
 70%|███████   | 236/336 [17:34<08:23,  5.03s/it]
 71%|███████   | 237/336 [17:38<07:39,  4.64s/it]
 71%|███████   | 238/336 [17:43<07:58,  4.88s/it]
 71%|███████   | 239/336 [17:47<07:08,  4.42s/it]
 71%|███████▏  | 240/336 [17:51<07:14,  4.53s/it]
 72%|███████▏  | 241/336 [17:55<06:54,  4.36s/it]
 72%|███████▏  | 242/336 [18:00<07:05,  4.53s/it]
 72%|███████▏  | 243/336 [18:04<06:36,  4.26s/it]
 73%|███████▎  | 244/336 [18:07<06:12,  4.05s/it]semantic_ids: [0, 0, 0, 1, 0, 0, 1, 1, 1, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.7119), tensor(-0.6747)]
semantic_entropy: 0.6933205723762512
log_probs: tensor([-0.7119, -0.6747])
semantic_entropy_rao: 0.6929738521575928
cur_prompt: Is the word in the logo "hardco industrial construction"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.2914, -0.2914, -0.2914, -0.4086, -0.4086, -0.2914, -0.4086, -0.2914,
        -0.4086, -0.4086])
regular_entropy: 0.350005179643631
regular_entropy_rao: 2.446460008621216
semantic_ids: [0, 0, 0, 1, 1, 0, 1, 0, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.6363), tensor(-0.7535)]
semantic_entropy: 0.6948628425598145
log_probs: tensor([-0.6363, -0.7535])
semantic_entropy_rao: 0.6914335489273071
cur_prompt: Is the word in the logo "hardto industal construction"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.1511, -0.1511, -0.1511, -0.6719, -0.1511, -0.1511, -0.1511, -0.1511,
        -0.6719, -0.1511])
regular_entropy: 0.2552793622016907
regular_entropy_rao: 1.7256977558135986
semantic_ids: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1385), tensor(-2.0456)]
semantic_entropy: 1.0920262336730957
log_probs: tensor([-0.1385, -2.0456])
semantic_entropy_rao: 0.3850611448287964
cur_prompt: Is the word in the logo "casa grecque restaurants"?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.2532, -0.2532, -0.2532, -0.4615, -0.4615, -0.4615, -0.4615, -0.4615,
        -0.2532, -0.2532])
regular_entropy: 0.3573470115661621
regular_entropy_rao: 2.4372811317443848
semantic_ids: [0, 0, 0, 1, 1, 1, 1, 1, 0, 0]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.5944), tensor(-0.8027)]
semantic_entropy: 0.6985626220703125
log_probs: tensor([-0.5944, -0.8027])
semantic_entropy_rao: 0.687751054763794
cur_prompt: Is the word in the logo "case grecque restaurants"?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331, -0.0331,
        -0.0331, -0.0331])
regular_entropy: 0.03308474272489548
regular_entropy_rao: 0.3200804889202118
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is the word in the logo "c'est cheese"?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no']
log_probs: tensor([-0.3337, -0.3598, -0.3598, -0.3598, -0.3598, -0.3337, -0.3598, -0.3337,
        -0.3337, -0.3598])
regular_entropy: 0.3493483364582062
regular_entropy_rao: 2.462470769882202
semantic_ids: [0, 1, 1, 1, 1, 0, 1, 0, 0, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.9007), tensor(-0.5213)]
semantic_entropy: 0.7110354900360107
log_probs: tensor([-0.9007, -0.5213])
semantic_entropy_rao: 0.6754708290100098
cur_prompt: Is the word in the logo "crest cheese"?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0095, -0.0095, -0.0095, -0.0095, -0.0095, -0.0095, -0.0095, -0.0095,
        -0.0095, -0.0095])
regular_entropy: 0.009457402862608433
regular_entropy_rao: 0.09368382394313812
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is the word in the logo "kress"?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1616, -0.6434, -0.1616, -0.1616, -0.1616, -0.6434, -0.1616, -0.1616,
        -0.1616, -0.1616])
regular_entropy: 0.257953941822052
regular_entropy_rao: 1.7760940790176392
semantic_ids: [0, 1, 0, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1436), tensor(-2.0117)]
semantic_entropy: 1.0776329040527344
log_probs: tensor([-0.1436, -2.0117])
semantic_entropy_rao: 0.3934829533100128
cur_prompt: Is the word in the logo "dress"?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes']
log_probs: tensor([-0.0366, -0.0366, -0.0366, -0.0366, -0.0366, -0.0366, -0.0366, -0.0366,
        -1.3256, -0.0366])
regular_entropy: 0.16549253463745117
regular_entropy_rao: 0.6695804595947266
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0302), tensor(-3.5164)]
semantic_entropy: 1.773298740386963
log_probs: tensor([-0.0302, -3.5164])
semantic_entropy_rao: 0.13371507823467255
cur_prompt: Is this an image of Goldener Reiter?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.0519, -0.0519, -0.0519, -0.0519, -1.1586, -0.0519, -0.0519, -1.1586,
        -0.0519, -0.0519])
regular_entropy: 0.2732246518135071
regular_entropy_rao: 1.1214109659194946
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0794), tensor(-2.5725)]
semantic_entropy: 1.3259503841400146
log_probs: tensor([-0.0794, -2.5725])
semantic_entropy_rao: 0.2697524130344391
cur_prompt: Is this an image of Palacio de la Mosquera?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0375, -0.0375, -0.0375, -0.0375, -0.0375, -0.0375, -0.0375, -0.0375,
        -0.0375, -0.0375])
regular_entropy: 0.0375162735581398
regular_entropy_rao: 0.3613487780094147
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a picture of Alexander Nevsky Church, Belgrade?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,
        -0.0004, -0.0004])
regular_entropy: 0.0004085421096533537
regular_entropy_rao: 0.004083752166479826
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a picture of Seppiko-Mineyama Hyogo Prefectural Nature Park?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']

 73%|███████▎  | 245/336 [18:11<05:50,  3.85s/it]
 73%|███████▎  | 246/336 [18:14<05:40,  3.78s/it]
 74%|███████▎  | 247/336 [18:19<06:00,  4.06s/it]
 74%|███████▍  | 248/336 [18:25<06:51,  4.67s/it]
 74%|███████▍  | 249/336 [18:29<06:13,  4.29s/it]
 74%|███████▍  | 250/336 [18:32<05:44,  4.00s/it]
 75%|███████▍  | 251/336 [18:37<06:14,  4.41s/it]
 75%|███████▌  | 252/336 [18:41<05:50,  4.18s/it]
 75%|███████▌  | 253/336 [18:47<06:31,  4.72s/it]
 76%|███████▌  | 254/336 [18:51<06:03,  4.43s/it]
 76%|███████▌  | 255/336 [18:54<05:31,  4.09s/it]
 76%|███████▌  | 256/336 [18:59<05:47,  4.34s/it]log_probs: tensor([-0.0175, -0.0175, -0.0175, -0.0175, -0.0175, -0.0175, -0.0175, -0.0175,
        -0.0175, -0.0175])
regular_entropy: 0.017526431009173393
regular_entropy_rao: 0.17221929132938385
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a picture of 1965)?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,
        -0.0119, -0.0119])
regular_entropy: 0.011925743892788887
regular_entropy_rao: 0.11784366518259048
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this a picture of Plaza Monumental de Toros de Pueblo Nuevo?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
log_probs: tensor([-0.0116, -0.0116, -0.0116, -0.0116, -0.0116, -0.0116, -0.0116, -0.0116,
        -0.0116, -1.8866])
regular_entropy: 0.19912266731262207
regular_entropy_rao: 0.38937538862228394
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0169), tensor(-4.0891)]
semantic_entropy: 2.0530080795288086
log_probs: tensor([-0.0169, -4.0891])
semantic_entropy_rao: 0.08512163162231445
cur_prompt: Is this an image of Beijing Guozijian?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0470, -1.2058, -1.2058, -0.0470, -0.0470, -1.2058, -0.0470, -0.0470,
        -0.0470, -0.0470])
regular_entropy: 0.3946289122104645
regular_entropy_rao: 1.396952509880066
semantic_ids: [0, 1, 1, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.1262), tensor(-2.1323)]
semantic_entropy: 1.1292730569839478
log_probs: tensor([-0.1262, -2.1323])
semantic_entropy_rao: 0.3640427589416504
cur_prompt: Is this an image of Klinikkirche (Pfafferode)?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0458, -0.0458, -0.0458, -0.0458, -0.0458, -0.0458, -0.0458, -0.0458,
        -0.0458, -0.0458])
regular_entropy: 0.04581877961754799
regular_entropy_rao: 0.43766793608665466
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a picture of Teddington Cemetery?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023,
        -0.0023, -0.0023])
regular_entropy: 0.0023342634085565805
regular_entropy_rao: 0.02328820712864399
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a picture of Khutir Nadia?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.4537, -0.2584, -0.2584, -0.2584, -0.2584, -0.4537, -0.2584, -0.2584,
        -0.2584, -0.2584])
regular_entropy: 0.2974567115306854
regular_entropy_rao: 2.1728949546813965
semantic_ids: [0, 1, 1, 1, 1, 0, 1, 1, 1, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-1.7686), tensor(-0.1870)]
semantic_entropy: 0.9778177738189697
log_probs: tensor([-1.7686, -0.1870])
semantic_entropy_rao: 0.45678579807281494
cur_prompt: Is this a photo of Kasteel Lunenburg?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0264, -0.0264, -0.0264, -0.0264, -0.0264, -0.0264, -0.0264, -0.0264,
        -0.0264, -0.0264])
regular_entropy: 0.0263502337038517
regular_entropy_rao: 0.2566497027873993
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a photo of Thomas Paine Cottage?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.1046, -0.1046, -0.1046, -0.1046, -0.8337, -0.1046, -0.1046, -0.8337,
        -0.1046, -0.1046])
regular_entropy: 0.2504059374332428
regular_entropy_rao: 1.4779038429260254
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1138), tensor(-2.2293)]
semantic_entropy: 1.1715753078460693
log_probs: tensor([-0.1138, -2.2293])
semantic_entropy_rao: 0.34147435426712036
cur_prompt: Is this a picture of Castillo de Sax?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0015, -0.0015, -0.0015, -0.0015, -0.0015, -0.0015, -0.0015, -0.0015,
        -0.0015, -0.0015])
regular_entropy: 0.0014619891298934817
regular_entropy_rao: 0.014598529785871506
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a picture of Roman Catholic Diocese of Orlando?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0215, -0.0215, -0.0215, -0.0215, -0.0215, -0.0215, -0.0215, -0.0215,
        -0.0215, -0.0215])
regular_entropy: 0.02149955742061138
regular_entropy_rao: 0.2104225754737854
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a photo of Cotehele?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.2144, -0.2144, -0.2144, -0.5269, -0.2144, -0.2144, -0.5269, -0.2144,
        -0.2144, -0.2144])
regular_entropy: 0.27685052156448364
regular_entropy_rao: 2.006129264831543
semantic_ids: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1680), tensor(-1.8668)]
semantic_entropy: 1.0173697471618652
log_probs: tensor([-0.1680, -1.8668])
semantic_entropy_rao: 0.4306447505950928
cur_prompt: Is this a photo of Mozirje Grove?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0264, -0.0264, -0.0264, -0.0264, -0.0264, -1.4847, -0.0264, -0.0264,
        -0.0264, -0.0264])
regular_entropy: 0.172183558344841
regular_entropy_rao: 0.5673749446868896

 76%|███████▋  | 257/336 [19:03<05:41,  4.32s/it]
 77%|███████▋  | 258/336 [19:07<05:30,  4.24s/it]
 77%|███████▋  | 259/336 [19:11<05:11,  4.05s/it]
 77%|███████▋  | 260/336 [19:14<04:58,  3.92s/it]
 78%|███████▊  | 261/336 [19:19<05:11,  4.15s/it]
 78%|███████▊  | 262/336 [19:24<05:17,  4.30s/it]
 78%|███████▊  | 263/336 [19:28<05:18,  4.36s/it]
 79%|███████▊  | 264/336 [19:32<04:56,  4.12s/it]
 79%|███████▉  | 265/336 [19:36<04:57,  4.19s/it]
 79%|███████▉  | 266/336 [19:40<04:39,  3.99s/it]
 79%|███████▉  | 267/336 [19:44<04:41,  4.08s/it]
 80%|███████▉  | 268/336 [19:47<04:24,  3.90s/it]semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0255), tensor(-3.6811)]
semantic_entropy: 1.8532978296279907
log_probs: tensor([-0.0255, -3.6811])
semantic_entropy_rao: 0.11762343347072601
cur_prompt: Is this a photo of Wurstelprater?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017,
        -0.0017, -0.0017])
regular_entropy: 0.0017088621389120817
regular_entropy_rao: 0.01705944538116455
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this a photo of Nanmyaebonthar Sannandawya Sandamuni Pagoda?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0056, -0.0056, -0.0056, -0.0056, -0.0056, -0.0056, -0.0056, -0.0056,
        -0.0056, -0.0056])
regular_entropy: 0.005639517214149237
regular_entropy_rao: 0.05607802793383598
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this an image of Pietrarsa railway museum?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0071, -0.0071, -0.0071, -0.0071, -0.0071, -0.0071, -0.0071, -0.0071,
        -0.0071, -0.0071])
regular_entropy: 0.0071184514090418816
regular_entropy_rao: 0.07067960500717163
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this an image of Washita Battlefield National Historic Site?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1926, -0.1926, -0.5702, -0.5702, -0.1926, -0.1926, -0.1926, -0.1926,
        -0.1926, -0.1926])
regular_entropy: 0.2681233584880829
regular_entropy_rao: 1.9156837463378906
semantic_ids: [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1582), tensor(-1.9221)]
semantic_entropy: 1.0401275157928467
log_probs: tensor([-0.1582, -1.9221])
semantic_entropy_rao: 0.41624191403388977
cur_prompt: Is this a picture of Galician market square in Skansen, Sanok?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0394, -0.0394, -0.0394, -0.0394, -1.2894, -0.0394, -0.0394, -0.0394,
        -0.0394, -0.0394])
regular_entropy: 0.16444505751132965
regular_entropy_rao: 0.696418285369873
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0313), tensor(-3.4786)]
semantic_entropy: 1.754949927330017
log_probs: tensor([-0.0313, -3.4786])
semantic_entropy_rao: 0.13769027590751648
cur_prompt: Is this a picture of Walworth Castle?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -1.7598, -0.0150,
        -0.0150, -0.0150])
regular_entropy: 0.18950779736042023
regular_entropy_rao: 0.43606314063072205
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0192), tensor(-3.9612)]
semantic_entropy: 1.9902307987213135
log_probs: tensor([-0.0192, -3.9612])
semantic_entropy_rao: 0.09427711367607117
cur_prompt: Is this an image of Museo Universitario del Chopo?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0767, -0.0767, -0.0767, -0.0767, -0.0767, -0.0767, -0.0767, -0.0767,
        -0.0767, -0.0767])
regular_entropy: 0.07671082019805908
regular_entropy_rao: 0.7104631066322327
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this an image of Cedar Park, Seattle, Washington?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0122, -0.0122, -1.8612, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122,
        -0.0122, -0.0122])
regular_entropy: 0.19713249802589417
regular_entropy_rao: 0.39818111062049866
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0173), tensor(-4.0635)]
semantic_entropy: 2.0404295921325684
log_probs: tensor([-0.0173, -4.0635])
semantic_entropy_rao: 0.08688510954380035
cur_prompt: Is this photo taken in a place of recreation room?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,
        -0.0010, -0.0010])
regular_entropy: 0.0010426490334793925
regular_entropy_rao: 0.010415623895823956
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this photo taken in a place of runway?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0951, -0.0951, -0.0951, -0.0951, -0.8764, -0.0951, -0.0951, -0.0951,
        -0.0951, -0.0951])
regular_entropy: 0.1732746660709381
regular_entropy_rao: 1.143449068069458
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0496), tensor(-3.0281)]
semantic_entropy: 1.538856029510498
log_probs: tensor([-0.0496, -3.0281])
semantic_entropy_rao: 0.19380035996437073
cur_prompt: Is this photo taken in a place of chalet?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016,
        -0.0016, -0.0016])
regular_entropy: 0.001622307114303112
regular_entropy_rao: 0.01619677245616913
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this photo taken in a place of throne room?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845,
        -0.0845, -0.0845])

 80%|████████  | 269/336 [19:51<04:07,  3.70s/it]
 80%|████████  | 270/336 [19:54<04:01,  3.66s/it]
 81%|████████  | 271/336 [19:58<03:55,  3.62s/it]
 81%|████████  | 272/336 [20:01<03:50,  3.60s/it]
 81%|████████▏ | 273/336 [20:06<04:09,  3.96s/it]
 82%|████████▏ | 274/336 [20:11<04:16,  4.14s/it]
 82%|████████▏ | 275/336 [20:14<03:59,  3.92s/it]
 82%|████████▏ | 276/336 [20:18<03:48,  3.81s/it]
 82%|████████▏ | 277/336 [20:21<03:34,  3.63s/it]
 83%|████████▎ | 278/336 [20:24<03:23,  3.51s/it]
 83%|████████▎ | 279/336 [20:28<03:26,  3.62s/it]
 83%|████████▎ | 280/336 [20:31<03:18,  3.55s/it]regular_entropy: 0.08445817977190018
regular_entropy_rao: 0.7761793732643127
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Does this image describe a place of campus?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017,
        -0.0017, -0.0017])
regular_entropy: 0.0017088621389120817
regular_entropy_rao: 0.01705944538116455
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this image describe a place of sandbox?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-5.6502e-05, -5.6502e-05, -5.6502e-05, -5.6502e-05, -5.6502e-05,
        -5.6502e-05, -5.6502e-05, -5.6502e-05, -5.6502e-05, -5.6502e-05])
regular_entropy: 5.6502009101677686e-05
regular_entropy_rao: 0.0005649880622513592
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this photo taken in a place of baseball field?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05,
        -4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05])
regular_entropy: 4.2436706280568615e-05
regular_entropy_rao: 0.00042434901115484536
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this photo taken in a place of bus station indoor?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.0696, -0.0696, -0.0696, -1.0202, -0.0696, -0.0696, -0.0696, -0.0696,
        -1.0202, -0.0696])
regular_entropy: 0.2597331702709198
regular_entropy_rao: 1.2551761865615845
semantic_ids: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0922), tensor(-2.4291)]
semantic_entropy: 1.2606544494628906
log_probs: tensor([-0.0922, -2.4291])
semantic_entropy_rao: 0.29816532135009766
cur_prompt: Does this image describe a place of shopping mall indoor?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-7.0570e-04, -7.0570e-04, -7.0570e-04, -7.0570e-04, -7.0570e-04,
        -7.0570e-04, -3.2820e+00, -7.0570e-04, -7.0570e-04, -7.0570e-04])
regular_entropy: 0.32883068919181824
regular_entropy_rao: 0.12959977984428406
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0042), tensor(-5.4826)]
semantic_entropy: 2.7434043884277344
log_probs: tensor([-4.1672e-03, -5.4826e+00])
semantic_entropy_rao: 0.0269484743475914
cur_prompt: Does this image describe a place of mosque outdoor?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-6.2700e-05, -6.2700e-05, -6.2700e-05, -6.2700e-05, -6.2700e-05,
        -6.2700e-05, -6.2700e-05, -6.2700e-05, -6.2700e-05, -6.2700e-05])
regular_entropy: 6.270015001064166e-05
regular_entropy_rao: 0.0006269622826948762
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this picture captured in a place of playground?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0238, -0.0238, -0.0238, -0.0238, -0.0238, -0.0238, -0.0238, -0.0238,
        -0.0238, -0.0238])
regular_entropy: 0.02380695752799511
regular_entropy_rao: 0.23246878385543823
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this picture captured in a place of viaduct?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029,
        -0.0029, -0.0029])
regular_entropy: 0.002873433521017432
regular_entropy_rao: 0.028651881963014603
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this image describe a place of fire escape?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008,
        -0.0008, -0.0008])
regular_entropy: 0.0007629530737176538
regular_entropy_rao: 0.007623712997883558
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this image describe a place of playroom?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023,
        -0.0023, -0.0023])
regular_entropy: 0.002274399157613516
regular_entropy_rao: 0.022692320868372917
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(-2.9802e-07)]
semantic_entropy: 2.98023280720372e-07
log_probs: tensor([-2.9802e-07])
semantic_entropy_rao: 2.980231954552437e-07
cur_prompt: Is this picture captured in a place of driveway?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003,
        -0.0003, -0.0003])
regular_entropy: 0.00033170898677781224
regular_entropy_rao: 0.0033159900922328234
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is this picture captured in a place of badlands?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,
        -0.0022, -0.0022])

 84%|████████▎ | 281/336 [20:35<03:11,  3.48s/it]
 84%|████████▍ | 282/336 [20:38<03:09,  3.50s/it]
 84%|████████▍ | 283/336 [20:43<03:25,  3.88s/it]
 85%|████████▍ | 284/336 [20:47<03:31,  4.06s/it]
 85%|████████▍ | 285/336 [20:51<03:16,  3.85s/it]
 85%|████████▌ | 286/336 [20:56<03:26,  4.13s/it]
 85%|████████▌ | 287/336 [20:59<03:11,  3.91s/it]
 86%|████████▌ | 288/336 [21:03<03:03,  3.82s/it]
 86%|████████▌ | 289/336 [21:06<02:51,  3.64s/it]
 86%|████████▋ | 290/336 [21:09<02:40,  3.50s/it]
 87%|████████▋ | 291/336 [21:12<02:33,  3.41s/it]
 87%|████████▋ | 292/336 [21:16<02:29,  3.39s/it]regular_entropy: 0.0022160701919347048
regular_entropy_rao: 0.022111644968390465
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this image describe a place of village?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003,
        -0.0003, -0.0003])
regular_entropy: 0.00033170898677781224
regular_entropy_rao: 0.0033159900922328234
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Does this image describe a place of underwater ocean deep?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.0257, -0.0257, -0.0257, -0.0257, -0.0257, -0.0257, -0.0257, -1.4970,
        -0.0257, -0.0257])
regular_entropy: 0.17282532155513763
regular_entropy_rao: 0.5603702664375305
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0252), tensor(-3.6938)]
semantic_entropy: 1.8594818115234375
log_probs: tensor([-0.0252, -3.6938])
semantic_entropy_rao: 0.11645969748497009
cur_prompt: Is this photo taken in a place of martial arts gym?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no']
log_probs: tensor([-0.0680, -0.0680, -0.0680, -0.0680, -0.0680, -0.0680, -0.0680, -1.0315,
        -0.0680, -0.0680])
regular_entropy: 0.16430631279945374
regular_entropy_rao: 0.9390921592712402
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0415), tensor(-3.2023)]
semantic_entropy: 1.6219030618667603
log_probs: tensor([-0.0415, -3.2023])
semantic_entropy_rao: 0.17006486654281616
cur_prompt: Is this photo taken in a place of atrium public?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005,
        -0.0005, -0.0005])
regular_entropy: 0.0004533856990747154
regular_entropy_rao: 0.0045318021439015865
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this picture captured in a place of desert sand?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes']
log_probs: tensor([-0.0204, -0.0204, -0.0204, -0.0204, -0.0204, -0.0204, -0.0204, -1.6090,
        -0.0204, -1.6090])
regular_entropy: 0.3381386399269104
regular_entropy_rao: 0.8040274977684021
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 1, 0, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0498), tensor(-3.0246)]
semantic_entropy: 1.5372129678726196
log_probs: tensor([-0.0498, -3.0246])
semantic_entropy_rao: 0.19430027902126312
cur_prompt: Is this picture captured in a place of burial chamber?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0436, -0.0436, -0.0436, -0.0436, -0.0436, -0.0436, -0.0436, -0.0436,
        -0.0436, -0.0436])
regular_entropy: 0.04359174519777298
regular_entropy_rao: 0.41732335090637207
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Does this image describe a place of cottage?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025,
        -0.0025, -0.0025])
regular_entropy: 0.002523481147363782
regular_entropy_rao: 0.02517120912671089
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Does this image describe a place of parking garage indoor?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005,
        -0.0005, -0.0005])
regular_entropy: 0.0005031079635955393
regular_entropy_rao: 0.005028550047427416
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a laptop in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001,
        -0.0001, -0.0001])
regular_entropy: 0.00011710940452758223
regular_entropy_rao: 0.0011709569953382015
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a potted plant in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-8.1711e-05, -8.1711e-05, -8.1711e-05, -8.1711e-05, -8.1711e-05,
        -8.1711e-05, -8.1711e-05, -8.1711e-05, -8.1711e-05, -8.1711e-05])
regular_entropy: 8.171128138201311e-05
regular_entropy_rao: 0.0008170460350811481
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a bus in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-3.7252e-05, -3.7252e-05, -3.7252e-05, -3.7252e-05, -3.7252e-05,
        -3.7252e-05, -3.7252e-05, -3.7252e-05, -3.7252e-05, -3.7252e-05])
regular_entropy: 3.725151327671483e-05
regular_entropy_rao: 0.00037250135210342705
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a cow in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0366, -0.0366, -0.0366, -0.0366, -0.0366, -1.3256, -0.0366, -0.0366,
        -0.0366, -0.0366])
regular_entropy: 0.16549251973628998

 87%|████████▋ | 293/336 [21:20<02:35,  3.62s/it]
 88%|████████▊ | 294/336 [21:25<02:54,  4.16s/it]
 88%|████████▊ | 295/336 [21:28<02:40,  3.92s/it]
 88%|████████▊ | 296/336 [21:32<02:28,  3.70s/it]
 88%|████████▊ | 297/336 [21:35<02:19,  3.57s/it]
 89%|████████▊ | 298/336 [21:38<02:12,  3.48s/it]
 89%|████████▉ | 299/336 [21:41<02:06,  3.41s/it]
 89%|████████▉ | 300/336 [21:46<02:13,  3.71s/it]
 90%|████████▉ | 301/336 [21:49<02:01,  3.46s/it]
 90%|████████▉ | 302/336 [21:52<01:56,  3.43s/it]
 90%|█████████ | 303/336 [21:55<01:52,  3.41s/it]
 90%|█████████ | 304/336 [21:59<01:47,  3.35s/it]regular_entropy_rao: 0.6695799827575684
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0302), tensor(-3.5164)]
semantic_entropy: 1.773298740386963
log_probs: tensor([-0.0302, -3.5164])
semantic_entropy_rao: 0.13371507823467255
cur_prompt: Is there a bottle in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes']
log_probs: tensor([-0.1096, -0.8127, -0.1096, -0.1096, -0.1096, -0.1096, -0.1096, -0.1096,
        -0.1096, -0.8127])
regular_entropy: 0.25021713972091675
regular_entropy_rao: 1.5068566799163818
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1167), tensor(-2.2061)]
semantic_entropy: 1.161388874053955
log_probs: tensor([-0.1167, -2.2061])
semantic_entropy_rao: 0.3467859625816345
cur_prompt: Is there a scissors in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003,
        -0.0003, -0.0003])
regular_entropy: 0.0002556981344241649
regular_entropy_rao: 0.002556327497586608
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a umbrella in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-5.9482e-05, -5.9482e-05, -5.9482e-05, -5.9482e-05, -5.9482e-05,
        -5.9482e-05, -5.9482e-05, -5.9482e-05, -5.9482e-05, -5.9482e-05])
regular_entropy: 5.9481892094481736e-05
regular_entropy_rao: 0.0005947835743427277
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a horse in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-4.1304e-05, -4.1304e-05, -4.1304e-05, -4.1304e-05, -4.1304e-05,
        -4.1304e-05, -4.1304e-05, -4.1304e-05, -4.1304e-05, -4.1304e-05])
regular_entropy: 4.130430897930637e-05
regular_entropy_rao: 0.0004130261077079922
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a chair in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003,
        -0.0003, -0.0003])
regular_entropy: 0.0003149113617837429
regular_entropy_rao: 0.003148121992126107
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a airplane in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003,
        -0.0003, -0.0003])
regular_entropy: 0.00029894712497480214
regular_entropy_rao: 0.002988577587530017
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a skateboard in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes']
log_probs: tensor([-0.1175, -0.1175, -0.1175, -0.1175, -0.7816, -0.1175, -0.1175, -0.1175,
        -0.7816, -0.7816])
regular_entropy: 0.3167443871498108
regular_entropy_rao: 1.8046071529388428
semantic_ids: [0, 0, 0, 0, 1, 0, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.1994), tensor(-1.7107)]
semantic_entropy: 0.955030620098114
log_probs: tensor([-0.1994, -1.7107])
semantic_entropy_rao: 0.47250962257385254
cur_prompt: Is there a banana in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002,
        -0.0002, -0.0002])
regular_entropy: 0.00024271078291349113
regular_entropy_rao: 0.002426518825814128
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a skateboard in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001,
        -0.0001, -0.0001])
regular_entropy: 0.00012014852836728096
regular_entropy_rao: 0.0012013409286737442
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a spoon in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-8.3440e-05, -8.3440e-05, -8.3440e-05, -8.3440e-05, -8.3440e-05,
        -8.3440e-05, -8.3440e-05, -8.3440e-05, -8.3440e-05, -8.3440e-05])
regular_entropy: 8.343953231815249e-05
regular_entropy_rao: 0.0008343258523382246
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a bicycle in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005,
        -0.0005, -0.0005])
regular_entropy: 0.0004901866777800024
regular_entropy_rao: 0.004899464547634125
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a apple in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020,
        -0.0020, -0.0020])
regular_entropy: 0.0020498281810432673
regular_entropy_rao: 0.020456308498978615
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(-2.9802e-07)]

 91%|█████████ | 305/336 [22:02<01:43,  3.33s/it]
 91%|█████████ | 306/336 [22:05<01:38,  3.29s/it]
 91%|█████████▏| 307/336 [22:09<01:38,  3.39s/it]
 92%|█████████▏| 308/336 [22:12<01:30,  3.22s/it]
 92%|█████████▏| 309/336 [22:15<01:29,  3.31s/it]
 92%|█████████▏| 310/336 [22:18<01:25,  3.29s/it]
 93%|█████████▎| 311/336 [22:22<01:23,  3.36s/it]
 93%|█████████▎| 312/336 [22:25<01:19,  3.30s/it]
 93%|█████████▎| 313/336 [22:30<01:26,  3.76s/it]
 93%|█████████▎| 314/336 [22:35<01:29,  4.07s/it]
 94%|█████████▍| 315/336 [22:39<01:28,  4.20s/it]
 94%|█████████▍| 316/336 [22:43<01:23,  4.19s/it]semantic_entropy: 2.98023280720372e-07
log_probs: tensor([-2.9802e-07])
semantic_entropy_rao: 2.980231954552437e-07
cur_prompt: Is there a car in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-4.8277e-05, -4.8277e-05, -4.8277e-05, -4.8277e-05, -4.8277e-05,
        -4.8277e-05, -4.8277e-05, -4.8277e-05, -4.8277e-05, -4.8277e-05])
regular_entropy: 4.827743032365106e-05
regular_entropy_rao: 0.00048275102744810283
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a kite in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0105, -0.0105, -0.0105, -0.0105, -0.0105, -0.0105, -0.0105, -0.0105,
        -0.0105, -0.0105])
regular_entropy: 0.010484912432730198
regular_entropy_rao: 0.10375552624464035
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a bottle in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005,
        -0.0005, -0.0005])
regular_entropy: 0.0004901866777800024
regular_entropy_rao: 0.004899464547634125
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a apple in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-3.6417e-05, -3.6417e-05, -3.6417e-05, -3.6417e-05, -3.6417e-05,
        -3.6417e-05, -3.6417e-05, -3.6417e-05, -3.6417e-05, -3.6417e-05])
regular_entropy: 3.6417106457520276e-05
regular_entropy_rao: 0.00036415786598809063
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a elephant in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002,
        -0.0002, -0.0002])
regular_entropy: 0.00020761947962455451
regular_entropy_rao: 0.0020757634192705154
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a hair drier in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001,
        -0.0001, -0.0001])
regular_entropy: 0.00012014852836728096
regular_entropy_rao: 0.0012013409286737442
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is there a baseball bat in this image?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-2.7239e-05, -2.7239e-05, -2.7239e-05, -2.7239e-05, -2.7239e-05,
        -2.7239e-05, -2.7239e-05, -2.7239e-05, -2.7239e-05, -2.7239e-05])
regular_entropy: 2.7238576876698062e-05
regular_entropy_rao: 0.0002723783836700022
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(2.3842e-07)]
semantic_entropy: -2.3841855067985307e-07
log_probs: tensor([2.3842e-07])
semantic_entropy_rao: -2.3841860752327193e-07
cur_prompt: Is there a giraffe in this image?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.0559, -0.0559, -0.0559, -0.0559, -1.1236, -0.0559, -1.1236, -0.0559,
        -0.0559, -0.0559])
regular_entropy: 0.269400030374527
regular_entropy_rao: 1.1531728506088257
semantic_ids: [0, 0, 0, 0, 1, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0825), tensor(-2.5365)]
semantic_entropy: 1.3094557523727417
log_probs: tensor([-0.0825, -2.5365])
semantic_entropy_rao: 0.27667927742004395
cur_prompt: Is this movie directed by bob rafelson?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0616, -0.0616, -0.0616, -1.0773, -1.0773, -0.0616, -0.0616, -0.0616,
        -0.0616, -0.0616])
regular_entropy: 0.2647519111633301
regular_entropy_rao: 1.1972228288650513
semantic_ids: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.0867), tensor(-2.4886)]
semantic_entropy: 1.2876362800598145
log_probs: tensor([-0.0867, -2.4886])
semantic_entropy_rao: 0.2860994338989258
cur_prompt: Is this movie directed by anthony minghella?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2011, -0.5526, -0.2011, -0.2011, -0.2011, -0.2011, -0.2011, -0.2011,
        -0.2011, -0.2011])
regular_entropy: 0.23623140156269073
regular_entropy_rao: 1.7980495691299438
semantic_ids: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0753), tensor(-2.6241)]
semantic_entropy: 1.3496648073196411
log_probs: tensor([-0.0753, -2.6241])
semantic_entropy_rao: 0.2600787281990051
cur_prompt: Is this movie directed by luke scott?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.1580, -0.1580, -0.1580, -0.1580, -0.1580, -0.6528, -0.1580, -0.1580,
        -0.1580, -0.1580])
regular_entropy: 0.20751619338989258
regular_entropy_rao: 1.554257869720459
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0655), tensor(-2.7576)]
semantic_entropy: 1.4115558862686157
log_probs: tensor([-0.0655, -2.7576])
semantic_entropy_rao: 0.2363462597131729
cur_prompt: Is this movie directed by dominic sena?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no']
log_probs: tensor([-0.4935, -0.2331, -0.2331, -0.4935, -0.2331, -0.2331, -0.4935, -0.4935,
        -0.2331, -0.2331])
regular_entropy: 0.33729857206344604
regular_entropy_rao: 2.3130698204040527
semantic_ids: [0, 1, 1, 0, 1, 1, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-1.0805), tensor(-0.4146)]
semantic_entropy: 0.7475776672363281
log_probs: tensor([-1.0805, -0.4146])

 94%|█████████▍| 317/336 [22:48<01:23,  4.41s/it]
 95%|█████████▍| 318/336 [22:52<01:15,  4.21s/it]
 95%|█████████▍| 319/336 [22:56<01:09,  4.06s/it]
 95%|█████████▌| 320/336 [23:01<01:09,  4.37s/it]
 96%|█████████▌| 321/336 [23:05<01:06,  4.44s/it]
 96%|█████████▌| 322/336 [23:09<00:57,  4.12s/it]
 96%|█████████▌| 323/336 [23:14<00:57,  4.41s/it]
 96%|█████████▋| 324/336 [23:18<00:50,  4.22s/it]
 97%|█████████▋| 325/336 [23:23<00:49,  4.50s/it]
 97%|█████████▋| 326/336 [23:28<00:48,  4.83s/it]
 97%|█████████▋| 327/336 [23:34<00:45,  5.01s/it]
 98%|█████████▊| 328/336 [23:39<00:39,  4.91s/it]semantic_entropy_rao: 0.6406496167182922
cur_prompt: Is this movie titled skiptrace (2016)?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,
        -0.0019, -0.0019])
regular_entropy: 0.001946054631844163
regular_entropy_rao: 0.019422711804509163
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie titled the bourne identity (2002)?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0147, -0.0147, -0.0147, -0.0147, -0.0147, -0.0147, -0.0147, -0.0147,
        -0.0147, -0.0147])
regular_entropy: 0.014663232490420341
regular_entropy_rao: 0.14449790120124817
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie directed by ethan coen,joel coen?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.9418, -0.0825, -0.0825, -0.9418, -0.0825, -0.0825, -0.0825, -0.0825,
        -0.0825, -0.0825])
regular_entropy: 0.2543313801288605
regular_entropy_rao: 1.3419057130813599
semantic_ids: [0, 1, 1, 0, 1, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-2.3463), tensor(-0.1006)]
semantic_entropy: 1.2234549522399902
log_probs: tensor([-2.3463, -0.1006])
semantic_entropy_rao: 0.3155839741230011
cur_prompt: Is this movie directed by john hillcoat?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.4014, -0.4014, -0.4014, -0.4014, -0.2972, -0.2972, -0.2972, -0.4014,
        -0.4014, -0.4014])
regular_entropy: 0.3701147139072418
regular_entropy_rao: 2.5430939197540283
semantic_ids: [0, 0, 0, 0, 1, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3891), tensor(-1.1322)]
semantic_entropy: 0.7606455087661743
log_probs: tensor([-0.3891, -1.1322])
semantic_entropy_rao: 0.6286056041717529
cur_prompt: Is this movie directed by jing wu?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05,
        -4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05, -4.2437e-05])
regular_entropy: 4.2436706280568615e-05
regular_entropy_rao: 0.00042434901115484536
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie directed by david lynch?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes']
log_probs: tensor([-0.0865, -0.0865, -0.0865, -0.0865, -0.0865, -0.9198, -0.0865, -0.9198,
        -0.0865, -0.0865])
regular_entropy: 0.2531708776950836
regular_entropy_rao: 1.3679498434066772
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-0.1031), tensor(-2.3228)]
semantic_entropy: 1.2129567861557007
log_probs: tensor([-0.1031, -2.3228])
semantic_entropy_rao: 0.3206697106361389
cur_prompt: Is this movie titled the fast and the furious (2001)?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005,
        -0.0005, -0.0005])
regular_entropy: 0.0005300214397720993
regular_entropy_rao: 0.005297406110912561
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie titled east of eden (1955)?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes']
log_probs: tensor([-0.2011, -0.5526, -0.2011, -0.5526, -0.2011, -0.5526, -0.5526, -0.2011,
        -0.2011, -0.2011])
regular_entropy: 0.34170055389404297
regular_entropy_rao: 2.258716106414795
semantic_ids: [0, 1, 0, 1, 0, 1, 1, 0, 0, 0]
cluster_assignment_entropy: 0.6730116670092565
log_likelihood_per_semantic_id: [tensor(-0.3846), tensor(-1.1416)]
semantic_entropy: 0.763135552406311
log_probs: tensor([-0.3846, -1.1416])
semantic_entropy_rao: 0.626334547996521
cur_prompt: Is this movie titled primal rage: the legend of konga (2018)?
Answer the question using a single word or phrase.
label: Yes, pred: Yes
validation_is_false[-1]: 0
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no']
log_probs: tensor([-0.1968, -0.1968, -0.5614, -0.1968, -0.1968, -0.5614, -0.5614, -0.5614,
        -0.1968, -0.5614])
regular_entropy: 0.3790929913520813
regular_entropy_rao: 2.4093408584594727
semantic_ids: [0, 0, 1, 0, 0, 1, 1, 1, 0, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.5274), tensor(-0.8920)]
semantic_entropy: 0.7096710205078125
log_probs: tensor([-0.5274, -0.8920])
semantic_entropy_rao: 0.67680424451828
cur_prompt: Is this movie titled the neon demon (2016)?
Answer the question using a single word or phrase.
label: No, pred: Yes
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']
log_probs: tensor([-0.6816, -0.6816, -0.1477, -0.1477, -0.1477, -0.1477, -0.1477, -0.1477,
        -0.1477, -0.1477])
regular_entropy: 0.25452011823654175
regular_entropy_rao: 1.7091618776321411
semantic_ids: [0, 0, 1, 1, 1, 1, 1, 1, 1, 1]
cluster_assignment_entropy: 0.5004024235381879
log_likelihood_per_semantic_id: [tensor(-2.0569), tensor(-0.1368)]
semantic_entropy: 1.0968620777130127
log_probs: tensor([-2.0569, -0.1368])
semantic_entropy_rao: 0.3822695016860962
cur_prompt: Is this movie titled fan (2016)?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no']
log_probs: tensor([-0.5018, -0.5018, -0.2283, -0.5018, -0.5018, -0.5018, -0.5018, -0.5018,
        -0.2283, -0.2283])
regular_entropy: 0.4197254776954651
regular_entropy_rao: 2.6717143058776855
semantic_ids: [0, 0, 1, 0, 0, 0, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.4468), tensor(-1.0207)]
semantic_entropy: 0.7337588667869568
log_probs: tensor([-0.4468, -1.0207])
semantic_entropy_rao: 0.6536173224449158
cur_prompt: Is this movie titled from afar (2015)?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no']
log_probs: tensor([-0.4014, -0.2972, -0.4014, -0.2972, -0.4014, -0.2972, -0.4014, -0.4014,
        -0.2972, -0.2972])
regular_entropy: 0.3493025004863739
regular_entropy_rao: 2.4474143981933594
semantic_ids: [0, 1, 0, 1, 0, 1, 0, 0, 1, 1]
cluster_assignment_entropy: 0.6931471805599453
log_likelihood_per_semantic_id: [tensor(-0.7466), tensor(-0.6424)]
semantic_entropy: 0.6945028305053711

 98%|█████████▊| 329/336 [23:43<00:34,  4.93s/it]
 98%|█████████▊| 330/336 [23:47<00:27,  4.52s/it]
 99%|█████████▊| 331/336 [23:51<00:21,  4.34s/it]
 99%|█████████▉| 332/336 [23:54<00:15,  4.00s/it]
 99%|█████████▉| 333/336 [23:59<00:13,  4.35s/it]
 99%|█████████▉| 334/336 [24:03<00:08,  4.02s/it]
100%|█████████▉| 335/336 [24:07<00:04,  4.28s/it]
100%|██████████| 336/336 [24:11<00:00,  4.16s/it]
100%|██████████| 336/336 [24:11<00:00,  4.32s/it]
log_probs: tensor([-0.7466, -0.6424])
semantic_entropy_rao: 0.6917926669120789
cur_prompt: Is this movie originated from the country or region of usa?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0616, -0.0616, -0.0616, -0.0616, -0.0616, -0.0616, -0.0616, -0.0616,
        -0.0616, -0.0616])
regular_entropy: 0.061638910323381424
regular_entropy_rao: 0.5795427560806274
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie originated from the country or region of canada?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no']
log_probs: tensor([-0.2098, -0.2098, -0.2098, -0.2098, -0.2098, -0.2098, -0.5354, -0.2098,
        -0.2098, -0.2098])
regular_entropy: 0.24240116775035858
regular_entropy_rao: 1.8445676565170288
semantic_ids: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0772), tensor(-2.5999)]
semantic_entropy: 1.3385553359985352
log_probs: tensor([-0.0772, -2.5999])
semantic_entropy_rao: 0.26456910371780396
cur_prompt: Is this movie directed by desmond davis?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0129, -0.0129, -0.0129, -0.0129, -0.0129, -0.0129, -0.0129, -0.0129,
        -0.0129, -0.0129])
regular_entropy: 0.01288239099085331
regular_entropy_rao: 0.1271749883890152
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie directed by edward zwick?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no']
log_probs: tensor([-0.2584, -0.2584, -0.2584, -0.2584, -0.4537, -0.2584, -0.4537, -0.2584,
        -0.4537, -0.2584])
regular_entropy: 0.3169877827167511
regular_entropy_rao: 2.2615649700164795
semantic_ids: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0]
cluster_assignment_entropy: 0.6108643020548934
log_likelihood_per_semantic_id: [tensor(-0.3020), tensor(-1.3446)]
semantic_entropy: 0.823284387588501
log_probs: tensor([-0.3020, -1.3446])
semantic_entropy_rao: 0.5737321376800537
cur_prompt: Is this movie directed by israel horovitz?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0102, -0.0102, -0.0102, -0.0102, -0.0102, -0.0102, -0.0102, -0.0102,
        -0.0102, -0.0102])
regular_entropy: 0.010218100622296333
regular_entropy_rao: 0.10114223510026932
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie directed by mike nichols?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
multi_responses: ['no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0681, -0.0681, -0.0681, -0.0681, -0.0681, -1.0316, -0.0681, -0.0681,
        -0.0681, -0.0681])
regular_entropy: 0.16441187262535095
regular_entropy_rao: 0.9399198889732361
semantic_ids: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
cluster_assignment_entropy: 0.3250829733914482
log_likelihood_per_semantic_id: [tensor(-0.0415), tensor(-3.2023)]
semantic_entropy: 1.6219022274017334
log_probs: tensor([-0.0415, -3.2023])
semantic_entropy_rao: 0.17006513476371765
cur_prompt: Is this movie originated from the country or region of france?
Answer the question using a single word or phrase.
label: Yes, pred: No
validation_is_false[-1]: 1
multi_responses: ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']
log_probs: tensor([-0.0015, -0.0015, -0.0015, -0.0015, -0.0015, -0.0015, -0.0015, -0.0015,
        -0.0015, -0.0015])
regular_entropy: 0.001465852139517665
regular_entropy_rao: 0.014637048356235027
semantic_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cluster_assignment_entropy: -0.0
log_likelihood_per_semantic_id: [tensor(0.)]
semantic_entropy: -0.0
log_probs: tensor([0.])
semantic_entropy_rao: -0.0
cur_prompt: Is this movie originated from the country or region of new zealand?
Answer the question using a single word or phrase.
label: No, pred: No
validation_is_false[-1]: 0
validation_is_false: [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]
all_regular_entropy: [tensor(0.3088), tensor(0.2607), tensor(0.3436), tensor(0.2852), tensor(0.3411), tensor(0.2652), tensor(0.3133), tensor(0.2503), tensor(0.3862), tensor(0.3836), tensor(0.1626), tensor(0.1626), tensor(0.3370), tensor(0.3500), tensor(0.1715), tensor(0.1812), tensor(0.0331), tensor(0.3471), tensor(0.3079), tensor(0.2625), tensor(0.3430), tensor(0.3706), tensor(0.3116), tensor(0.2948), tensor(0.0001), tensor(0.0025), tensor(0.3760), tensor(0.4199), tensor(0.0071), tensor(0.0601), tensor(0.3367), tensor(0.3070), tensor(0.0024), tensor(0.3233), tensor(0.0020), tensor(0.3473), tensor(0.0004), tensor(0.3366), tensor(0.0004), tensor(0.0243), tensor(0.3453), tensor(0.3498), tensor(0.2626), tensor(0.0494), tensor(0.0119), tensor(0.3133), tensor(0.0011), tensor(0.0097), tensor(0.1833), tensor(0.3368), tensor(0.1672), tensor(0.3426), tensor(0.3459), tensor(0.2731), tensor(0.1918), tensor(0.0027), tensor(0.0696), tensor(0.3594), tensor(0.0315), tensor(0.1231), tensor(0.0061), tensor(0.3436), tensor(0.3693), tensor(0.0090), tensor(0.3632), tensor(0.0046), tensor(0.1825), tensor(0.0025), tensor(0.4084), tensor(0.0063), tensor(0.2333), tensor(0.1886), tensor(0.0545), tensor(0.3054), tensor(0.3493), tensor(0.3365), tensor(0.2580), tensor(0.3198), tensor(0.1825), tensor(0.3500), tensor(0.3638), tensor(0.3525), tensor(0.3055), tensor(0.3395), tensor(0.4241), tensor(0.3145), tensor(0.3370), tensor(0.1885), tensor(0.2121), tensor(0.0375), tensor(0.1799), tensor(0.3135), tensor(0.1886), tensor(0.3368), tensor(0.3145), tensor(0.3500), tensor(0.3493), tensor(0.2561), tensor(0.3170), tensor(0.3638), tensor(0.3509), tensor(0.3135), tensor(0.3509), tensor(0.3638), tensor(0.2769), tensor(0.2731), tensor(0.3537), tensor(0.2697), tensor(0.2612), tensor(0.3170), tensor(0.3493), tensor(0.3687), tensor(0.3368), tensor(0.0749), tensor(0.3088), tensor(0.3378), tensor(0.3401), tensor(0.2572), tensor(0.3633), tensor(0.3467), tensor(0.3498), tensor(0.3116), tensor(0.1799), tensor(0.1854), tensor(0.0040), tensor(0.3640), tensor(0.2304), tensor(0.0162), tensor(0.3069), tensor(0.1706), tensor(0.0095), tensor(0.1793), tensor(0.3157), tensor(0.1885), tensor(0.3570), tensor(0.3374), tensor(0.2514), tensor(0.3266), tensor(0.2637), tensor(0.3370), tensor(0.2731), tensor(0.0110), tensor(0.0494), tensor(0.0749), tensor(0.0292), tensor(0.3394), tensor(0.0047), tensor(0.0004), tensor(0.0018), tensor(0.0110), tensor(0.0022), tensor(0.0001), tensor(0.1735), tensor(0.0023), tensor(0.0083), tensor(0.1748), tensor(0.0244), tensor(0.3054), tensor(0.0032), tensor(0.0006), tensor(0.0002), tensor(0.3737), tensor(0.0002), tensor(0.0257), tensor(0.0029), tensor(0.0004), tensor(0.0004), tensor(0.0215), tensor(0.0122), tensor(0.0046), tensor(0.3517), tensor(0.2053), tensor(0.1895), tensor(0.3107), tensor(0.0840), tensor(0.3718), tensor(0.3473), tensor(0.1639), tensor(0.3107), tensor(0.2550), tensor(0.0013), tensor(0.1627), tensor(0.0081), tensor(0.3170), tensor(0.2032), tensor(0.1743), tensor(0.3894), tensor(0.0051), tensor(0.3054), tensor(0.3230), tensor(0.0026), tensor(0.0323), tensor(0.0026), tensor(0.0250), tensor(0.0014), tensor(0.3440), tensor(0.2273), tensor(0.0008), tensor(0.0004), tensor(0.0042), tensor(0.0042), tensor(0.0007), tensor(0.0129), tensor(0.3466), tensor(1.2159e-05), tensor(2.4557e-05), tensor(0.0001), tensor(0.0016), tensor(0.1743), tensor(0.3481), tensor(0.0031), tensor(0.0006), tensor(7.9208e-05), tensor(0.0002), tensor(0.0244), tensor(0.0366), tensor(0.3284), tensor(0.4230), tensor(0.2160), tensor(0.2899), tensor(0.0010), tensor(0.0122), tensor(0.0506), tensor(0.1764), tensor(0.2648), tensor(0.1854), tensor(0.3184), tensor(0.3453), tensor(0.0006), tensor(0.3587), tensor(0.1632), tensor(0.2628), tensor(0.4383), tensor(0.3500), tensor(0.2553), tensor(0.3573), tensor(0.0331), tensor(0.3493), tensor(0.0095), tensor(0.2580), tensor(0.1655), tensor(0.2732), tensor(0.0375), tensor(0.0004), tensor(0.0175), tensor(0.0119), tensor(0.1991), tensor(0.3946), tensor(0.0458), tensor(0.0023), tensor(0.2975), tensor(0.0264), tensor(0.2504), tensor(0.0015), tensor(0.0215), tensor(0.2769), tensor(0.1722), tensor(0.0017), tensor(0.0056), tensor(0.0071), tensor(0.2681), tensor(0.1644), tensor(0.1895), tensor(0.0767), tensor(0.1971), tensor(0.0010), tensor(0.1733), tensor(0.0016), tensor(0.0845), tensor(0.0017), tensor(5.6502e-05), tensor(4.2437e-05), tensor(0.2597), tensor(0.3288), tensor(6.2700e-05), tensor(0.0238), tensor(0.0029), tensor(0.0008), tensor(0.0023), tensor(0.0003), tensor(0.0022), tensor(0.0003), tensor(0.1728), tensor(0.1643), tensor(0.0005), tensor(0.3381), tensor(0.0436), tensor(0.0025), tensor(0.0005), tensor(0.0001), tensor(8.1711e-05), tensor(3.7252e-05), tensor(0.1655), tensor(0.2502), tensor(0.0003), tensor(5.9482e-05), tensor(4.1304e-05), tensor(0.0003), tensor(0.0003), tensor(0.3167), tensor(0.0002), tensor(0.0001), tensor(8.3440e-05), tensor(0.0005), tensor(0.0020), tensor(4.8277e-05), tensor(0.0105), tensor(0.0005), tensor(3.6417e-05), tensor(0.0002), tensor(0.0001), tensor(2.7239e-05), tensor(0.2694), tensor(0.2648), tensor(0.2362), tensor(0.2075), tensor(0.3373), tensor(0.0019), tensor(0.0147), tensor(0.2543), tensor(0.3701), tensor(4.2437e-05), tensor(0.2532), tensor(0.0005), tensor(0.3417), tensor(0.3791), tensor(0.2545), tensor(0.4197), tensor(0.3493), tensor(0.0616), tensor(0.2424), tensor(0.0129), tensor(0.3170), tensor(0.0102), tensor(0.1644), tensor(0.0015)]
auroc of regular_entropy: 0.5176799886621315
all_regular_entropy_rao: [tensor(2.1573), tensor(1.2433), tensor(2.2428), tensor(2.0798), tensor(2.4193), tensor(1.8801), tensor(2.2225), tensor(1.5514), tensor(2.3999), tensor(2.5393), tensor(0.8407), tensor(0.7853), tensor(2.3206), tensor(2.4464), tensor(1.1116), tensor(1.2622), tensor(0.3201), tensor(2.2185), tensor(1.9265), tensor(1.8450), tensor(2.4321), tensor(2.4204), tensor(1.8648), tensor(2.1542), tensor(0.0011), tensor(0.0252), tensor(2.0839), tensor(2.7204), tensor(0.0707), tensor(0.5663), tensor(2.3281), tensor(2.1182), tensor(0.0239), tensor(1.7459), tensor(0.0205), tensor(2.4498), tensor(0.0038), tensor(2.3575), tensor(0.0036), tensor(0.2372), tensor(2.4446), tensor(2.2022), tensor(1.2200), tensor(0.4699), tensor(0.1178), tensor(2.2225), tensor(0.0110), tensor(0.0961), tensor(0.4731), tensor(2.4017), tensor(0.6358), tensor(2.2508), tensor(2.2266), tensor(1.9697), tensor(1.3922), tensor(0.0265), tensor(0.6494), tensor(2.1522), tensor(0.3048), tensor(1.0884), tensor(0.0606), tensor(2.2428), tensor(2.1097), tensor(0.0890), tensor(2.1353), tensor(0.0456), tensor(0.4787), tensor(0.0252), tensor(2.3697), tensor(0.0622), tensor(1.7750), tensor(0.4411), tensor(0.5161), tensor(2.0405), tensor(2.4625), tensor(2.3502), tensor(1.7761), tensor(2.2875), tensor(1.2800), tensor(2.4464), tensor(2.5051), tensor(2.4738), tensor(2.0534), tensor(2.4061), tensor(2.6802), tensor(1.8285), tensor(2.3206), tensor(1.3539), tensor(1.5969), tensor(0.3613), tensor(1.2445), tensor(1.8406), tensor(0.4411), tensor(2.3647), tensor(1.8285), tensor(2.4464), tensor(2.4625), tensor(1.7424), tensor(2.2616), tensor(2.5051), tensor(2.4682), tensor(1.8406), tensor(2.4682), tensor(2.5051), tensor(2.0061), tensor(1.9697), tensor(2.4418), tensor(1.9336), tensor(1.8276), tensor(2.2616), tensor(2.4625), tensor(2.4229), tensor(2.4017), tensor(0.6948), tensor(2.1573), tensor(2.3858), tensor(2.2745), tensor(1.2915), tensor(2.4297), tensor(2.4504), tensor(2.2021), tensor(1.8648), tensor(1.2445), tensor(1.3165), tensor(0.0401), tensor(0.7241), tensor(1.7521), tensor(0.1597), tensor(1.9515), tensor(1.0960), tensor(0.0937), tensor(0.5021), tensor(2.2486), tensor(1.3539), tensor(1.5475), tensor(2.3788), tensor(1.4218), tensor(2.3388), tensor(1.2086), tensor(2.3206), tensor(1.9697), tensor(0.1092), tensor(0.4699), tensor(0.6948), tensor(0.2832), tensor(2.2823), tensor(0.0468), tensor(0.0042), tensor(0.0175), tensor(0.1092), tensor(0.0215), tensor(0.0012), tensor(0.5535), tensor(0.0227), tensor(0.0824), tensor(0.5400), tensor(0.2383), tensor(2.0277), tensor(0.0318), tensor(0.0057), tensor(0.0016), tensor(2.0925), tensor(0.0016), tensor(0.2504), tensor(0.0294), tensor(0.0041), tensor(0.0043), tensor(0.2104), tensor(0.1209), tensor(0.0456), tensor(2.4443), tensor(1.5332), tensor(0.4361), tensor(1.8770), tensor(0.7724), tensor(2.5240), tensor(2.4498), tensor(0.7151), tensor(1.8770), tensor(1.3291), tensor(0.0132), tensor(0.8523), tensor(0.0804), tensor(2.2616), tensor(1.5124), tensor(1.1597), tensor(2.5463), tensor(0.0506), tensor(2.0405), tensor(2.3133), tensor(0.0258), tensor(0.3124), tensor(0.0258), tensor(0.2443), tensor(0.0135), tensor(2.4386), tensor(0.2943), tensor(0.0078), tensor(0.0040), tensor(0.0422), tensor(0.0422), tensor(0.0067), tensor(0.1272), tensor(2.4506), tensor(0.0001), tensor(0.0002), tensor(0.0011), tensor(0.0158), tensor(1.1597), tensor(2.4488), tensor(0.0310), tensor(0.0060), tensor(0.0008), tensor(0.0020), tensor(0.2383), tensor(0.3527), tensor(2.3515), tensor(1.9335), tensor(0.3271), tensor(2.1169), tensor(0.0099), tensor(0.1209), tensor(0.4811), tensor(1.1929), tensor(1.1972), tensor(1.3165), tensor(2.2745), tensor(2.4446), tensor(0.0057), tensor(2.4357), tensor(0.7442), tensor(1.9872), tensor(2.5767), tensor(2.4465), tensor(1.7257), tensor(2.4373), tensor(0.3201), tensor(2.4625), tensor(0.0937), tensor(1.7761), tensor(0.6696), tensor(1.1214), tensor(0.3613), tensor(0.0041), tensor(0.1722), tensor(0.1178), tensor(0.3894), tensor(1.3970), tensor(0.4377), tensor(0.0233), tensor(2.1729), tensor(0.2566), tensor(1.4779), tensor(0.0146), tensor(0.2104), tensor(2.0061), tensor(0.5674), tensor(0.0171), tensor(0.0561), tensor(0.0707), tensor(1.9157), tensor(0.6964), tensor(0.4361), tensor(0.7105), tensor(0.3982), tensor(0.0104), tensor(1.1434), tensor(0.0162), tensor(0.7762), tensor(0.0171), tensor(0.0006), tensor(0.0004), tensor(1.2552), tensor(0.1296), tensor(0.0006), tensor(0.2325), tensor(0.0287), tensor(0.0076), tensor(0.0227), tensor(0.0033), tensor(0.0221), tensor(0.0033), tensor(0.5604), tensor(0.9391), tensor(0.0045), tensor(0.8040), tensor(0.4173), tensor(0.0252), tensor(0.0050), tensor(0.0012), tensor(0.0008), tensor(0.0004), tensor(0.6696), tensor(1.5069), tensor(0.0026), tensor(0.0006), tensor(0.0004), tensor(0.0031), tensor(0.0030), tensor(1.8046), tensor(0.0024), tensor(0.0012), tensor(0.0008), tensor(0.0049), tensor(0.0205), tensor(0.0005), tensor(0.1038), tensor(0.0049), tensor(0.0004), tensor(0.0021), tensor(0.0012), tensor(0.0003), tensor(1.1532), tensor(1.1972), tensor(1.7980), tensor(1.5543), tensor(2.3131), tensor(0.0194), tensor(0.1445), tensor(1.3419), tensor(2.5431), tensor(0.0004), tensor(1.3679), tensor(0.0053), tensor(2.2587), tensor(2.4093), tensor(1.7092), tensor(2.6717), tensor(2.4474), tensor(0.5795), tensor(1.8446), tensor(0.1272), tensor(2.2616), tensor(0.1011), tensor(0.9399), tensor(0.0146)]
auroc of regular_entropy_rao: 0.5385841836734694
all_semantic_entropy: [tensor(0.8492), tensor(1.2660), tensor(0.7679), tensor(0.9996), tensor(0.7206), tensor(1.0494), tensor(0.8328), tensor(1.1462), tensor(0.7134), tensor(0.6968), tensor(1.6700), tensor(1.7002), tensor(0.7455), tensor(0.6949), tensor(1.5506), tensor(1.4979), tensor(-2.3842e-07), tensor(0.7754), tensor(0.9147), tensor(1.0587), tensor(0.7176), tensor(0.7053), tensor(0.9346), tensor(0.9821), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(0.8204), tensor(0.8574), tensor(-0.), tensor(-2.3842e-07), tensor(0.7435), tensor(0.8595), tensor(-0.), tensor(0.9761), tensor(2.9802e-07), tensor(0.6935), tensor(-0.), tensor(0.7357), tensor(-0.), tensor(-0.), tensor(0.7149), tensor(0.7805), tensor(1.2768), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(0.8328), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(1.9465), tensor(0.7910), tensor(1.7978), tensor(0.7655), tensor(0.7728), tensor(1.0264), tensor(1.4573), tensor(-0.), tensor(-0.), tensor(0.7968), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.7679), tensor(0.8113), tensor(-0.), tensor(0.8025), tensor(-0.), tensor(1.9402), tensor(-0.), tensor(0.7250), tensor(-0.), tensor(1.3552), tensor(1.9840), tensor(-2.3842e-07), tensor(0.8808), tensor(0.7110), tensor(0.7376), tensor(1.0776), tensor(0.8171), tensor(1.4921), tensor(0.6949), tensor(0.7026), tensor(0.7087), tensor(0.8772), tensor(0.7237), tensor(0.7320), tensor(0.9468), tensor(0.7455), tensor(1.4689), tensor(1.4002), tensor(-0.), tensor(1.5037), tensor(0.9427), tensor(1.9840), tensor(0.7339), tensor(0.9468), tensor(0.6949), tensor(0.7110), tensor(1.0872), tensor(0.8233), tensor(0.7026), tensor(0.7098), tensor(0.9427), tensor(0.7098), tensor(0.7026), tensor(1.0174), tensor(1.0264), tensor(0.6967), tensor(1.0355), tensor(1.0634), tensor(0.8233), tensor(0.7110), tensor(0.7043), tensor(0.7910), tensor(-2.3842e-07), tensor(0.8492), tensor(0.7286), tensor(0.7585), tensor(1.2446), tensor(0.7016), tensor(0.6932), tensor(0.7805), tensor(0.9346), tensor(1.5037), tensor(1.4805), tensor(-0.), tensor(1.6083), tensor(1.3608), tensor(-0.), tensor(0.9070), tensor(1.5565), tensor(-2.3842e-07), tensor(1.9153), tensor(0.8264), tensor(1.4689), tensor(1.0569), tensor(0.7303), tensor(1.1921), tensor(0.8052), tensor(1.2822), tensor(0.7455), tensor(1.0264), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(0.7562), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(1.8657), tensor(2.9802e-07), tensor(-0.), tensor(1.8781), tensor(-0.), tensor(0.8845), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(0.8173), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.6957), tensor(1.4172), tensor(1.9902), tensor(0.9305), tensor(-0.), tensor(0.7001), tensor(0.6935), tensor(1.7427), tensor(0.9305), tensor(1.2287), tensor(-0.), tensor(1.6639), tensor(-0.), tensor(0.8233), tensor(1.4229), tensor(1.5330), tensor(0.6958), tensor(-0.), tensor(0.8808), tensor(0.8111), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.7829), tensor(2.2175), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(2.9802e-07), tensor(-0.), tensor(0.6932), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-0.), tensor(1.5330), tensor(0.6939), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.8023), tensor(0.8774), tensor(2.1540), tensor(0.9908), tensor(-0.), tensor(-0.), tensor(-0.), tensor(1.5213), tensor(1.2876), tensor(1.4805), tensor(0.8202), tensor(0.7149), tensor(-0.), tensor(0.6993), tensor(1.7245), tensor(1.3055), tensor(0.6933), tensor(0.6949), tensor(1.0920), tensor(0.6986), tensor(-0.), tensor(0.7110), tensor(-2.3842e-07), tensor(1.0776), tensor(1.7733), tensor(1.3260), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(2.0530), tensor(1.1293), tensor(-0.), tensor(-0.), tensor(0.9778), tensor(-0.), tensor(1.1716), tensor(-0.), tensor(-0.), tensor(1.0174), tensor(1.8533), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(1.0401), tensor(1.7549), tensor(1.9902), tensor(-0.), tensor(2.0404), tensor(-2.3842e-07), tensor(1.5389), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(1.2607), tensor(2.7434), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(2.9802e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-2.3842e-07), tensor(1.8595), tensor(1.6219), tensor(-0.), tensor(1.5372), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-2.3842e-07), tensor(1.7733), tensor(1.1614), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.9550), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(2.9802e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(1.3095), tensor(1.2876), tensor(1.3497), tensor(1.4116), tensor(0.7476), tensor(-0.), tensor(-0.), tensor(1.2235), tensor(0.7606), tensor(-0.), tensor(1.2130), tensor(-0.), tensor(0.7631), tensor(0.7097), tensor(1.0969), tensor(0.7338), tensor(0.6945), tensor(-0.), tensor(1.3386), tensor(-0.), tensor(0.8233), tensor(-0.), tensor(1.6219), tensor(-0.)]
auroc of semantic_entropy: 0.5288761337868481
all_semantic_entropy_rao: [tensor(0.5523), tensor(0.2957), tensor(0.6220), tensor(0.4422), tensor(0.6662), tensor(0.4105), tensor(0.5658), tensor(0.3548), tensor(0.6732), tensor(0.6895), tensor(0.1576), tensor(0.1502), tensor(0.6426), tensor(0.6914), tensor(0.1903), tensor(0.2066), tensor(-2.3842e-07), tensor(0.6153), tensor(0.5015), tensor(0.4048), tensor(0.6690), tensor(0.6811), tensor(0.4871), tensor(0.4539), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(0.5762), tensor(0.5457), tensor(-0.), tensor(-2.3842e-07), tensor(0.6445), tensor(0.5441), tensor(-0.), tensor(0.4579), tensor(2.9802e-07), tensor(0.6928), tensor(-0.), tensor(0.6518), tensor(-0.), tensor(-0.), tensor(0.6717), tensor(0.6107), tensor(0.2909), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(0.5658), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(0.1012), tensor(0.6014), tensor(0.1286), tensor(0.6242), tensor(0.6176), tensor(0.4249), tensor(0.2201), tensor(-0.), tensor(-0.), tensor(0.5964), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.6220), tensor(0.5839), tensor(-0.), tensor(0.5914), tensor(-0.), tensor(0.1022), tensor(-0.), tensor(0.6619), tensor(-0.), tensor(0.2579), tensor(0.0952), tensor(-2.3842e-07), tensor(0.5273), tensor(0.6755), tensor(0.6500), tensor(0.3935), tensor(0.5789), tensor(0.2085), tensor(0.6914), tensor(0.6838), tensor(0.6778), tensor(0.5301), tensor(0.6632), tensor(0.6553), tensor(0.4783), tensor(0.6426), tensor(0.2162), tensor(0.2405), tensor(-0.), tensor(0.2048), tensor(0.4812), tensor(0.0952), tensor(0.6535), tensor(0.4783), tensor(0.6914), tensor(0.6755), tensor(0.3879), tensor(0.5737), tensor(0.6838), tensor(0.6766), tensor(0.4812), tensor(0.6766), tensor(0.6838), tensor(0.4306), tensor(0.4249), tensor(0.6896), tensor(0.4191), tensor(0.4020), tensor(0.5737), tensor(0.6755), tensor(0.6821), tensor(0.6014), tensor(-2.3842e-07), tensor(0.5523), tensor(0.6585), tensor(0.6306), tensor(0.3056), tensor(0.6847), tensor(0.6931), tensor(0.6107), tensor(0.4871), tensor(0.2048), tensor(0.2123), tensor(-0.), tensor(0.1738), tensor(0.2556), tensor(-0.), tensor(0.5073), tensor(0.1885), tensor(-2.3842e-07), tensor(0.1064), tensor(0.5711), tensor(0.2162), tensor(0.4059), tensor(0.6569), tensor(0.3310), tensor(0.5891), tensor(0.2885), tensor(0.6426), tensor(0.4249), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(0.6326), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(0.1153), tensor(2.9802e-07), tensor(-0.), tensor(0.1130), tensor(-0.), tensor(0.5244), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(0.5788), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.6906), tensor(0.2343), tensor(0.0943), tensor(0.4900), tensor(-0.), tensor(0.6862), tensor(0.6928), tensor(0.1404), tensor(0.4900), tensor(0.3131), tensor(-0.), tensor(0.1591), tensor(-0.), tensor(0.5737), tensor(0.2322), tensor(0.1956), tensor(0.6905), tensor(-0.), tensor(0.5273), tensor(0.5841), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.6085), tensor(0.0650), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(2.9802e-07), tensor(-0.), tensor(0.6931), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-0.), tensor(0.1956), tensor(0.6924), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.5916), tensor(0.5299), tensor(0.0722), tensor(0.4481), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.1992), tensor(0.2861), tensor(0.2123), tensor(0.5763), tensor(0.6717), tensor(-0.), tensor(0.6871), tensor(0.1445), tensor(0.2784), tensor(0.6930), tensor(0.6914), tensor(0.3851), tensor(0.6878), tensor(-0.), tensor(0.6755), tensor(-2.3842e-07), tensor(0.3935), tensor(0.1337), tensor(0.2698), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(0.0851), tensor(0.3640), tensor(-0.), tensor(-0.), tensor(0.4568), tensor(-0.), tensor(0.3415), tensor(-0.), tensor(-0.), tensor(0.4306), tensor(0.1176), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(0.4162), tensor(0.1377), tensor(0.0943), tensor(-0.), tensor(0.0869), tensor(-2.3842e-07), tensor(0.1938), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.2982), tensor(0.0269), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(2.9802e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-2.3842e-07), tensor(0.1165), tensor(0.1701), tensor(-0.), tensor(0.1943), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(-2.3842e-07), tensor(0.1337), tensor(0.3468), tensor(-2.3842e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(0.4725), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(-0.), tensor(2.9802e-07), tensor(-2.3842e-07), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-0.), tensor(-2.3842e-07), tensor(0.2767), tensor(0.2861), tensor(0.2601), tensor(0.2363), tensor(0.6406), tensor(-0.), tensor(-0.), tensor(0.3156), tensor(0.6286), tensor(-0.), tensor(0.3207), tensor(-0.), tensor(0.6263), tensor(0.6768), tensor(0.3823), tensor(0.6536), tensor(0.6918), tensor(-0.), tensor(0.2646), tensor(-0.), tensor(0.5737), tensor(-0.), tensor(0.1701), tensor(-0.)]
auroc of semantic_entropy_rao: 0.5275120464852607
all_cluster_assignment_entropy: [0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.5004024235381879, 0.6931471805599453, 0.6730116670092565, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, -0.0, 0.6730116670092565, 0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.6931471805599453, 0.6108643020548934, 0.5004024235381879, -0.0, -0.0, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, 0.6730116670092565, 0.6108643020548934, -0.0, 0.6108643020548934, -0.0, 0.6931471805599453, -0.0, 0.6730116670092565, -0.0, -0.0, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, 0.6108643020548934, -0.0, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, 0.6730116670092565, 0.6730116670092565, -0.0, 0.6730116670092565, -0.0, 0.3250829733914482, -0.0, 0.6931471805599453, -0.0, 0.3250829733914482, 0.3250829733914482, -0.0, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.3250829733914482, 0.6931471805599453, 0.6730116670092565, 0.6730116670092565, 0.6108643020548934, 0.6730116670092565, 0.6108643020548934, 0.6108643020548934, 0.6730116670092565, 0.3250829733914482, 0.3250829733914482, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6730116670092565, 0.6108643020548934, 0.6931471805599453, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.5004024235381879, 0.6931471805599453, 0.5004024235381879, 0.5004024235381879, 0.6108643020548934, 0.6730116670092565, 0.6931471805599453, 0.6108643020548934, -0.0, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.6931471805599453, 0.6931471805599453, 0.6730116670092565, 0.6108643020548934, 0.3250829733914482, 0.3250829733914482, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, 0.6108643020548934, 0.3250829733914482, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6108643020548934, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, -0.0, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, -0.0, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, 0.6108643020548934, -0.0, 0.6730116670092565, 0.6931471805599453, 0.3250829733914482, 0.6108643020548934, 0.5004024235381879, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, -0.0, 0.6108643020548934, 0.6108643020548934, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6931471805599453, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.6931471805599453, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, 0.6730116670092565, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, 0.3250829733914482, 0.5004024235381879, 0.3250829733914482, 0.6108643020548934, 0.6730116670092565, -0.0, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, 0.6931471805599453, 0.5004024235381879, 0.6931471805599453, -0.0, 0.6730116670092565, -0.0, 0.5004024235381879, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.6108643020548934, -0.0, -0.0, 0.5004024235381879, -0.0, 0.5004024235381879, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, 0.3250829733914482, -0.0, 0.3250829733914482, -0.0, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.3250829733914482, -0.0, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.5004024235381879, 0.5004024235381879, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, -0.0, -0.0, 0.5004024235381879, 0.6108643020548934, -0.0, 0.5004024235381879, -0.0, 0.6730116670092565, 0.6931471805599453, 0.5004024235381879, 0.6108643020548934, 0.6931471805599453, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, -0.0, 0.3250829733914482, -0.0]
auroc of cluster_assignment_entropy: 0.5128082482993197
aurac of regular_entropy: 0.5055762081784386
aurac of regular_entropy_rao: 0.516728624535316
aurac of semantic_entropy: 0.516728624535316
aurac of semantic_entropy_rao: 0.5018587360594795
aurac of cluster_assignment_entropy: 0.4944237918215613
----------------------二次检测-----------------------------
all_cluster_assignment_entropy: [0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.5004024235381879, 0.6931471805599453, 0.6730116670092565, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, -0.0, 0.6730116670092565, 0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.6931471805599453, 0.6108643020548934, 0.5004024235381879, -0.0, -0.0, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, 0.6730116670092565, 0.6108643020548934, -0.0, 0.6108643020548934, -0.0, 0.6931471805599453, -0.0, 0.6730116670092565, -0.0, -0.0, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, 0.6108643020548934, -0.0, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, 0.6730116670092565, 0.6730116670092565, -0.0, 0.6730116670092565, -0.0, 0.3250829733914482, -0.0, 0.6931471805599453, -0.0, 0.3250829733914482, 0.3250829733914482, -0.0, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.3250829733914482, 0.6931471805599453, 0.6730116670092565, 0.6730116670092565, 0.6108643020548934, 0.6730116670092565, 0.6108643020548934, 0.6108643020548934, 0.6730116670092565, 0.3250829733914482, 0.3250829733914482, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6730116670092565, 0.6108643020548934, 0.6931471805599453, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.5004024235381879, 0.6931471805599453, 0.5004024235381879, 0.5004024235381879, 0.6108643020548934, 0.6730116670092565, 0.6931471805599453, 0.6108643020548934, -0.0, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.6931471805599453, 0.6931471805599453, 0.6730116670092565, 0.6108643020548934, 0.3250829733914482, 0.3250829733914482, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, 0.6108643020548934, 0.3250829733914482, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6108643020548934, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, -0.0, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, -0.0, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, 0.6108643020548934, -0.0, 0.6730116670092565, 0.6931471805599453, 0.3250829733914482, 0.6108643020548934, 0.5004024235381879, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, -0.0, 0.6108643020548934, 0.6108643020548934, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6931471805599453, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.6931471805599453, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, 0.6730116670092565, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, 0.3250829733914482, 0.5004024235381879, 0.3250829733914482, 0.6108643020548934, 0.6730116670092565, -0.0, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, 0.6931471805599453, 0.5004024235381879, 0.6931471805599453, -0.0, 0.6730116670092565, -0.0, 0.5004024235381879, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.6108643020548934, -0.0, -0.0, 0.5004024235381879, -0.0, 0.5004024235381879, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, 0.3250829733914482, -0.0, 0.3250829733914482, -0.0, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.3250829733914482, -0.0, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.5004024235381879, 0.5004024235381879, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, -0.0, -0.0, 0.5004024235381879, 0.6108643020548934, -0.0, 0.5004024235381879, -0.0, 0.6730116670092565, 0.6931471805599453, 0.5004024235381879, 0.6108643020548934, 0.6931471805599453, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, -0.0, 0.3250829733914482, -0.0]; labels: ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No']
total_samples: 335; high_entropy_num: 67
updated_validation: [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]
combined_sorted: [(0.6931471805599453, 'Yes', 'Yes', 'code_reasoning/0003.png', 8), (0.6931471805599453, 'No', 'Yes', 'code_reasoning/0015.png', 13), (0.6931471805599453, 'No', 'Yes', 'code_reasoning/0002.png', 21), (0.6931471805599453, 'No', 'Yes', 'artwork/images/10881.jpg', 35), (0.6931471805599453, 'Yes', 'No', 'celebrity/images/tt0116629_shot_1570_img_2.jpg', 68), (0.6931471805599453, 'No', 'No', 'numerical_calculation/0009.png', 79), (0.6931471805599453, 'No', 'Yes', 'numerical_calculation/0005.png', 95), (0.6931471805599453, 'Yes', 'No', 'text_translation/0007.png', 106), (0.6931471805599453, 'No', 'No', 'text_translation/0019.png', 111), (0.6931471805599453, 'Yes', 'No', 'text_translation/0005.png', 118), (0.6931471805599453, 'No', 'No', 'text_translation/0005.png', 119), (0.6931471805599453, 'Yes', 'Yes', 'commonsense_reasoning/0024.png', 170), (0.6931471805599453, 'Yes', 'No', 'commonsense_reasoning/0036.png', 176), (0.6931471805599453, 'No', 'Yes', 'position/000000426241.jpg', 203), (0.6931471805599453, 'No', 'No', 'position/000000006471.jpg', 209), (0.6931471805599453, 'No', 'No', 'OCR/0015.jpg', 229), (0.6931471805599453, 'No', 'No', 'OCR/0017.jpg', 233), (0.6931471805599453, 'No', 'Yes', 'OCR/0012.jpg', 235), (0.6931471805599453, 'No', 'Yes', 'posters/images/tt5688868.jpg', 325), (0.6931471805599453, 'Yes', 'No', 'posters/images/tt1560747.jpg', 328), (0.6730116670092565, 'Yes', 'Yes', 'code_reasoning/0014.png', 2), (0.6730116670092565, 'Yes', 'Yes', 'code_reasoning/0013.png', 4), (0.6730116670092565, 'No', 'Yes', 'code_reasoning/0003.png', 9), (0.6730116670092565, 'Yes', 'Yes', 'code_reasoning/0015.png', 12), (0.6730116670092565, 'No', 'Yes', 'code_reasoning/0017.png', 17), (0.6730116670092565, 'Yes', 'Yes', 'code_reasoning/0002.png', 20), (0.6730116670092565, 'Yes', 'Yes', 'artwork/images/24291.jpg', 26), (0.6730116670092565, 'Yes', 'Yes', 'artwork/images/38740.jpg', 30), (0.6730116670092565, 'No', 'No', 'artwork/images/13288.jpg', 37), (0.6730116670092565, 'Yes', 'No', 'artwork/images/9405.jpg', 40), (0.6730116670092565, 'No', 'No', 'artwork/images/9405.jpg', 41), (0.6730116670092565, 'No', 'Yes', 'celebrity/images/tt0061722_shot_0259_img_0.jpg', 51), (0.6730116670092565, 'Yes', 'Yes', 'celebrity/images/tt0064665_shot_0300_img_0.jpg', 52), (0.6730116670092565, 'No', 'No', 'celebrity/images/tt0070511_shot_0639_img_0.jpg', 57), (0.6730116670092565, 'No', 'No', 'celebrity/images/tt0111280_shot_1479_img_2.jpg', 61), (0.6730116670092565, 'Yes', 'No', 'celebrity/images/tt0107614_shot_0116_img_0.jpg', 62), (0.6730116670092565, 'Yes', 'No', 'celebrity/images/tt0072684_shot_0512_img_1.jpg', 64), (0.6730116670092565, 'Yes', 'No', 'numerical_calculation/0014.png', 74), (0.6730116670092565, 'No', 'No', 'numerical_calculation/0014.png', 75), (0.6730116670092565, 'Yes', 'No', 'numerical_calculation/0003.png', 80), (0.6730116670092565, 'No', 'No', 'numerical_calculation/0003.png', 81), (0.6730116670092565, 'No', 'Yes', 'numerical_calculation/0007.png', 83), (0.6730116670092565, 'Yes', 'Yes', 'numerical_calculation/0019.png', 86), (0.6730116670092565, 'No', 'No', 'numerical_calculation/0002.png', 93), (0.6730116670092565, 'Yes', 'No', 'text_translation/0020.png', 96), (0.6730116670092565, 'No', 'No', 'text_translation/0014.png', 99), (0.6730116670092565, 'Yes', 'No', 'text_translation/0013.png', 100), (0.6730116670092565, 'Yes', 'No', 'text_translation/0009.png', 102), (0.6730116670092565, 'No', 'No', 'text_translation/0009.png', 103), (0.6730116670092565, 'Yes', 'No', 'text_translation/0019.png', 110), (0.6730116670092565, 'No', 'Yes', 'text_translation/0012.png', 115), (0.6730116670092565, 'Yes', 'No', 'text_translation/0002.png', 116), (0.6730116670092565, 'Yes', 'Yes', 'count/000000470121.jpg', 120), (0.6730116670092565, 'No', 'No', 'count/000000372819.jpg', 135), (0.6730116670092565, 'No', 'No', 'count/000000410612.jpg', 139), (0.6730116670092565, 'No', 'No', 'color/000000338560.jpg', 145), (0.6730116670092565, 'No', 'No', 'color/000000442456.jpg', 161), (0.6730116670092565, 'No', 'No', 'commonsense_reasoning/0029.png', 175), (0.6730116670092565, 'Yes', 'No', 'commonsense_reasoning/0013.png', 186), (0.6730116670092565, 'No', 'No', 'OCR/0020.jpg', 217), (0.6730116670092565, 'No', 'No', 'OCR/0007.jpg', 227), (0.6730116670092565, 'Yes', 'No', 'OCR/0017.jpg', 232), (0.6730116670092565, 'No', 'Yes', 'OCR/0002.jpg', 237), (0.6730116670092565, 'Yes', 'No', 'posters/images/tt2238032.jpg', 316), (0.6730116670092565, 'Yes', 'Yes', 'posters/images/tt5688868.jpg', 324), (0.6108643020548934, 'Yes', 'No', 'code_reasoning/0020.png', 0), (0.6108643020548934, 'Yes', 'Yes', 'code_reasoning/0009.png', 6), (0.6108643020548934, 'Yes', 'Yes', 'code_reasoning/0012.png', 18), (0.6108643020548934, 'Yes', 'No', 'code_reasoning/0005.png', 22), (0.6108643020548934, 'No', 'Yes', 'artwork/images/38740.jpg', 31), (0.6108643020548934, 'No', 'No', 'artwork/images/42288.jpg', 33), (0.6108643020548934, 'No', 'No', 'artwork/images/38178.jpg', 45), (0.6108643020548934, 'No', 'Yes', 'celebrity/images/tt0096320_shot_0085_img_0.jpg', 49), (0.6108643020548934, 'No', 'Yes', 'numerical_calculation/0020.png', 73), (0.6108643020548934, 'No', 'No', 'numerical_calculation/0013.png', 77), (0.6108643020548934, 'Yes', 'Yes', 'numerical_calculation/0007.png', 82), (0.6108643020548934, 'Yes', 'No', 'numerical_calculation/0015.png', 84), (0.6108643020548934, 'No', 'No', 'numerical_calculation/0015.png', 85), (0.6108643020548934, 'No', 'Yes', 'numerical_calculation/0012.png', 91), (0.6108643020548934, 'Yes', 'Yes', 'numerical_calculation/0005.png', 94), (0.6108643020548934, 'Yes', 'No', 'text_translation/0014.png', 98), (0.6108643020548934, 'No', 'No', 'text_translation/0013.png', 101), (0.6108643020548934, 'No', 'Yes', 'text_translation/0015.png', 109), (0.6108643020548934, 'Yes', 'No', 'text_translation/0017.png', 112), (0.6108643020548934, 'Yes', 'Yes', 'text_translation/0012.png', 114), (0.6108643020548934, 'No', 'Yes', 'count/000000470121.jpg', 121), (0.6108643020548934, 'Yes', 'No', 'count/000000491867.jpg', 128), (0.6108643020548934, 'Yes', 'Yes', 'count/000000432468.jpg', 132), (0.6108643020548934, 'Yes', 'No', 'count/000000372819.jpg', 134), (0.6108643020548934, 'No', 'No', 'count/000000097994.jpg', 137), (0.6108643020548934, 'No', 'No', 'color/000000492362.jpg', 157), (0.6108643020548934, 'No', 'Yes', 'commonsense_reasoning/0020.png', 173), (0.6108643020548934, 'Yes', 'Yes', 'commonsense_reasoning/0014.png', 178), (0.6108643020548934, 'No', 'No', 'commonsense_reasoning/0025.png', 183), (0.6108643020548934, 'Yes', 'Yes', 'commonsense_reasoning/0038.png', 188), (0.6108643020548934, 'No', 'Yes', 'commonsense_reasoning/0038.png', 189), (0.6108643020548934, 'No', 'No', 'position/000000067213.jpg', 195), (0.6108643020548934, 'Yes', 'No', 'OCR/0020.jpg', 216), (0.6108643020548934, 'Yes', 'No', 'OCR/0007.jpg', 226), (0.6108643020548934, 'No', 'No', 'landmark/images/2a895eb889d6fd99.jpg', 247), (0.6108643020548934, 'No', 'No', 'existence/000000424521.jpg', 299), (0.6108643020548934, 'Yes', 'No', 'posters/images/tt7131870.jpg', 320), (0.6108643020548934, 'No', 'No', 'posters/images/tt3495026.jpg', 327), (0.6108643020548934, 'Yes', 'No', 'posters/images/tt2908856.jpg', 332), (0.5004024235381879, 'No', 'No', 'code_reasoning/0020.png', 1), (0.5004024235381879, 'No', 'Yes', 'code_reasoning/0014.png', 3), (0.5004024235381879, 'No', 'Yes', 'code_reasoning/0013.png', 5), (0.5004024235381879, 'No', 'Yes', 'code_reasoning/0009.png', 7), (0.5004024235381879, 'No', 'Yes', 'code_reasoning/0012.png', 19), (0.5004024235381879, 'No', 'No', 'code_reasoning/0005.png', 23), (0.5004024235381879, 'No', 'Yes', 'artwork/images/24291.jpg', 27), (0.5004024235381879, 'Yes', 'No', 'artwork/images/13821.jpg', 42), (0.5004024235381879, 'No', 'Yes', 'celebrity/images/tt0064665_shot_0300_img_0.jpg', 53), (0.5004024235381879, 'Yes', 'No', 'numerical_calculation/0013.png', 76), (0.5004024235381879, 'No', 'No', 'text_translation/0020.png', 97), (0.5004024235381879, 'Yes', 'Yes', 'text_translation/0003.png', 104), (0.5004024235381879, 'No', 'Yes', 'text_translation/0003.png', 105), (0.5004024235381879, 'No', 'No', 'text_translation/0007.png', 107), (0.5004024235381879, 'Yes', 'Yes', 'text_translation/0015.png', 108), (0.5004024235381879, 'No', 'No', 'text_translation/0002.png', 117), (0.5004024235381879, 'No', 'No', 'count/000000301867.jpg', 125), (0.5004024235381879, 'Yes', 'No', 'count/000000097994.jpg', 136), (0.5004024235381879, 'Yes', 'No', 'count/000000410612.jpg', 138), (0.5004024235381879, 'Yes', 'No', 'count/000000423944.jpg', 140), (0.5004024235381879, 'No', 'Yes', 'commonsense_reasoning/0014.png', 179), (0.5004024235381879, 'No', 'Yes', 'OCR/0014.jpg', 219), (0.5004024235381879, 'Yes', 'Yes', 'OCR/0003.jpg', 224), (0.5004024235381879, 'Yes', 'Yes', 'OCR/0012.jpg', 234), (0.5004024235381879, 'No', 'No', 'OCR/0005.jpg', 239), (0.5004024235381879, 'No', 'No', 'landmark/images/02e3e418198427e7.jpg', 241), (0.5004024235381879, 'Yes', 'No', 'landmark/images/092d0859ff6424de.jpg', 250), (0.5004024235381879, 'Yes', 'No', 'landmark/images/0713451824a443d4.jpg', 252), (0.5004024235381879, 'No', 'No', 'landmark/images/0f92862c0366ab60.jpg', 255), (0.5004024235381879, 'Yes', 'No', 'landmark/images/015543ddea466c54.jpg', 260), (0.5004024235381879, 'Yes', 'No', 'scene/images/Places365_val_00000010.jpg', 272), (0.5004024235381879, 'No', 'No', 'scene/images/Places365_val_00000106.jpg', 285), (0.5004024235381879, 'No', 'No', 'existence/000000009590.jpg', 293), (0.5004024235381879, 'Yes', 'No', 'posters/images/tt0065724.jpg', 312), (0.5004024235381879, 'No', 'No', 'posters/images/tt0065724.jpg', 313), (0.5004024235381879, 'No', 'No', 'posters/images/tt1403865.jpg', 319), (0.5004024235381879, 'Yes', 'No', 'posters/images/tt0232500.jpg', 322), (0.5004024235381879, 'Yes', 'No', 'posters/images/tt3495026.jpg', 326), (0.3250829733914482, 'Yes', 'No', 'code_reasoning/0007.png', 10), (0.3250829733914482, 'No', 'No', 'code_reasoning/0007.png', 11), (0.3250829733914482, 'Yes', 'Yes', 'code_reasoning/0019.png', 14), (0.3250829733914482, 'No', 'Yes', 'code_reasoning/0019.png', 15), (0.3250829733914482, 'Yes', 'Yes', 'celebrity/images/tt0096320_shot_0085_img_0.jpg', 48), (0.3250829733914482, 'Yes', 'Yes', 'celebrity/images/tt0061722_shot_0259_img_0.jpg', 50), (0.3250829733914482, 'Yes', 'No', 'celebrity/images/tt0077405_shot_0150_img_0.jpg', 54), (0.3250829733914482, 'Yes', 'No', 'celebrity/images/tt0118715_shot_0079_img_0.jpg', 66), (0.3250829733914482, 'Yes', 'No', 'celebrity/images/tt0065724_shot_0320_img_1.jpg', 70), (0.3250829733914482, 'No', 'No', 'celebrity/images/tt0065724_shot_0320_img_1.jpg', 71), (0.3250829733914482, 'Yes', 'No', 'numerical_calculation/0009.png', 78), (0.3250829733914482, 'No', 'Yes', 'numerical_calculation/0019.png', 87), (0.3250829733914482, 'Yes', 'No', 'numerical_calculation/0017.png', 88), (0.3250829733914482, 'Yes', 'Yes', 'numerical_calculation/0012.png', 90), (0.3250829733914482, 'Yes', 'No', 'numerical_calculation/0002.png', 92), (0.3250829733914482, 'Yes', 'Yes', 'count/000000430286.jpg', 122), (0.3250829733914482, 'No', 'Yes', 'count/000000430286.jpg', 123), (0.3250829733914482, 'Yes', 'No', 'count/000000067213.jpg', 126), (0.3250829733914482, 'No', 'No', 'count/000000491867.jpg', 129), (0.3250829733914482, 'No', 'No', 'count/000000476215.jpg', 131), (0.3250829733914482, 'No', 'Yes', 'count/000000432468.jpg', 133), (0.3250829733914482, 'Yes', 'No', 'color/000000014831.jpg', 152), (0.3250829733914482, 'No', 'No', 'color/000000053529.jpg', 155), (0.3250829733914482, 'No', 'Yes', 'commonsense_reasoning/0024.png', 171), (0.3250829733914482, 'Yes', 'Yes', 'commonsense_reasoning/0020.png', 172), (0.3250829733914482, 'No', 'No', 'commonsense_reasoning/0036.png', 177), (0.3250829733914482, 'No', 'Yes', 'commonsense_reasoning/0056.png', 181), (0.3250829733914482, 'Yes', 'No', 'commonsense_reasoning/0066.png', 184), (0.3250829733914482, 'No', 'No', 'commonsense_reasoning/0066.png', 185), (0.3250829733914482, 'Yes', 'Yes', 'position/000000530162.jpg', 196), (0.3250829733914482, 'Yes', 'No', 'position/000000006471.jpg', 208), (0.3250829733914482, 'Yes', 'Yes', 'OCR/0014.jpg', 218), (0.3250829733914482, 'No', 'No', 'OCR/0009.jpg', 223), (0.3250829733914482, 'No', 'Yes', 'OCR/0003.jpg', 225), (0.3250829733914482, 'Yes', 'No', 'OCR/0019.jpg', 230), (0.3250829733914482, 'No', 'No', 'OCR/0019.jpg', 231), (0.3250829733914482, 'Yes', 'No', 'landmark/images/02e3e418198427e7.jpg', 240), (0.3250829733914482, 'Yes', 'No', 'landmark/images/2a895eb889d6fd99.jpg', 246), (0.3250829733914482, 'Yes', 'No', 'landmark/images/05685b1070b828f5.jpg', 256), (0.3250829733914482, 'No', 'No', 'landmark/images/015543ddea466c54.jpg', 261), (0.3250829733914482, 'Yes', 'No', 'landmark/images/06483ba2bff074bc.jpg', 262), (0.3250829733914482, 'Yes', 'No', 'scene/images/Places365_val_00000022.jpg', 264), (0.3250829733914482, 'Yes', 'No', 'scene/images/Places365_val_00000163.jpg', 266), (0.3250829733914482, 'No', 'No', 'scene/images/Places365_val_00000010.jpg', 273), (0.3250829733914482, 'Yes', 'No', 'scene/images/Places365_val_00000089.jpg', 282), (0.3250829733914482, 'No', 'No', 'scene/images/Places365_val_00000089.jpg', 283), (0.3250829733914482, 'Yes', 'No', 'existence/000000009590.jpg', 292), (0.3250829733914482, 'Yes', 'No', 'posters/images/tt4520364.jpg', 314), (0.3250829733914482, 'No', 'No', 'posters/images/tt4520364.jpg', 315), (0.3250829733914482, 'Yes', 'No', 'posters/images/tt0082186.jpg', 330), (0.3250829733914482, 'Yes', 'No', 'posters/images/tt0100112.jpg', 334), (-0.0, 'Yes', 'Yes', 'code_reasoning/0017.png', 16), (-0.0, 'Yes', 'Yes', 'artwork/images/14777.jpg', 24), (-0.0, 'No', 'Yes', 'artwork/images/14777.jpg', 25), (-0.0, 'Yes', 'Yes', 'artwork/images/13239.jpg', 28), (-0.0, 'No', 'Yes', 'artwork/images/13239.jpg', 29), (-0.0, 'Yes', 'No', 'artwork/images/42288.jpg', 32), (-0.0, 'Yes', 'Yes', 'artwork/images/10881.jpg', 34), (-0.0, 'Yes', 'No', 'artwork/images/13288.jpg', 36), (-0.0, 'Yes', 'Yes', 'artwork/images/10970.jpg', 38), (-0.0, 'No', 'Yes', 'artwork/images/10970.jpg', 39), (-0.0, 'No', 'No', 'artwork/images/13821.jpg', 43), (-0.0, 'Yes', 'No', 'artwork/images/38178.jpg', 44), (-0.0, 'Yes', 'No', 'artwork/images/10256.jpg', 46), (-0.0, 'No', 'No', 'artwork/images/10256.jpg', 47), (-0.0, 'No', 'No', 'celebrity/images/tt0077405_shot_0150_img_0.jpg', 55), (-0.0, 'Yes', 'No', 'celebrity/images/tt0070511_shot_0639_img_0.jpg', 56), (-0.0, 'Yes', 'No', 'celebrity/images/tt0118883_shot_0691_img_1.jpg', 58), (-0.0, 'No', 'No', 'celebrity/images/tt0118883_shot_0691_img_1.jpg', 59), (-0.0, 'Yes', 'No', 'celebrity/images/tt0111280_shot_1479_img_2.jpg', 60), (-0.0, 'No', 'No', 'celebrity/images/tt0107614_shot_0116_img_0.jpg', 63), (-0.0, 'No', 'No', 'celebrity/images/tt0072684_shot_0512_img_1.jpg', 65), (-0.0, 'No', 'No', 'celebrity/images/tt0118715_shot_0079_img_0.jpg', 67), (-0.0, 'No', 'No', 'celebrity/images/tt0116629_shot_1570_img_2.jpg', 69), (-0.0, 'Yes', 'Yes', 'numerical_calculation/0020.png', 72), (-0.0, 'No', 'No', 'numerical_calculation/0017.png', 89), (-0.0, 'No', 'No', 'text_translation/0017.png', 113), (-0.0, 'Yes', 'No', 'count/000000301867.jpg', 124), (-0.0, 'No', 'No', 'count/000000067213.jpg', 127), (-0.0, 'Yes', 'No', 'count/000000476215.jpg', 130), (-0.0, 'No', 'No', 'count/000000423944.jpg', 141), (-0.0, 'Yes', 'No', 'count/000000565045.jpg', 142), (-0.0, 'No', 'No', 'count/000000565045.jpg', 143), (-0.0, 'Yes', 'No', 'color/000000338560.jpg', 144), (-0.0, 'Yes', 'No', 'color/000000047112.jpg', 146), (-0.0, 'No', 'No', 'color/000000047112.jpg', 147), (-0.0, 'Yes', 'No', 'color/000000512929.jpg', 148), (-0.0, 'No', 'No', 'color/000000512929.jpg', 149), (-0.0, 'Yes', 'No', 'color/000000038118.jpg', 150), (-0.0, 'No', 'No', 'color/000000038118.jpg', 151), (-0.0, 'No', 'No', 'color/000000014831.jpg', 153), (-0.0, 'Yes', 'No', 'color/000000053529.jpg', 154), (-0.0, 'Yes', 'No', 'color/000000492362.jpg', 156), (-0.0, 'Yes', 'No', 'color/000000008277.jpg', 158), (-0.0, 'No', 'No', 'color/000000008277.jpg', 159), (-0.0, 'Yes', 'No', 'color/000000442456.jpg', 160), (-0.0, 'Yes', 'No', 'color/000000564280.jpg', 162), (-0.0, 'No', 'No', 'color/000000564280.jpg', 163), (-0.0, 'Yes', 'No', 'color/000000532761.jpg', 164), (-0.0, 'No', 'No', 'color/000000532761.jpg', 165), (-0.0, 'Yes', 'No', 'color/000000410612.jpg', 166), (-0.0, 'No', 'No', 'color/000000410612.jpg', 167), (-0.0, 'Yes', 'No', 'commonsense_reasoning/0065.png', 168), (-0.0, 'No', 'No', 'commonsense_reasoning/0065.png', 169), (-0.0, 'Yes', 'No', 'commonsense_reasoning/0029.png', 174), (-0.0, 'Yes', 'Yes', 'commonsense_reasoning/0056.png', 180), (-0.0, 'Yes', 'No', 'commonsense_reasoning/0025.png', 182), (-0.0, 'No', 'No', 'commonsense_reasoning/0013.png', 187), (-0.0, 'Yes', 'No', 'commonsense_reasoning/0068.png', 190), (-0.0, 'No', 'No', 'commonsense_reasoning/0068.png', 191), (-0.0, 'Yes', 'No', 'position/000000472046.jpg', 192), (-0.0, 'No', 'No', 'position/000000472046.jpg', 193), (-0.0, 'Yes', 'No', 'position/000000067213.jpg', 194), (-0.0, 'No', 'Yes', 'position/000000530162.jpg', 197), (-0.0, 'Yes', 'No', 'position/000000482585.jpg', 198), (-0.0, 'No', 'No', 'position/000000482585.jpg', 199), (-0.0, 'Yes', 'No', 'position/000000052007.jpg', 200), (-0.0, 'No', 'No', 'position/000000052007.jpg', 201), (-0.0, 'Yes', 'Yes', 'position/000000426241.jpg', 202), (-0.0, 'Yes', 'No', 'position/000000014038.jpg', 204), (-0.0, 'No', 'No', 'position/000000014038.jpg', 205), (-0.0, 'Yes', 'Yes', 'position/000000097994.jpg', 206), (-0.0, 'No', 'Yes', 'position/000000097994.jpg', 207), (-0.0, 'Yes', 'No', 'position/000000494869.jpg', 210), (-0.0, 'No', 'No', 'position/000000494869.jpg', 211), (-0.0, 'Yes', 'No', 'position/000000395701.jpg', 212), (-0.0, 'No', 'No', 'position/000000395701.jpg', 213), (-0.0, 'Yes', 'Yes', 'position/000000212800.jpg', 214), (-0.0, 'No', 'Yes', 'position/000000212800.jpg', 215), (-0.0, 'Yes', 'No', 'OCR/0013.jpg', 220), (-0.0, 'No', 'No', 'OCR/0013.jpg', 221), (-0.0, 'Yes', 'No', 'OCR/0009.jpg', 222), (-0.0, 'Yes', 'No', 'OCR/0015.jpg', 228), (-0.0, 'Yes', 'Yes', 'OCR/0002.jpg', 236), (-0.0, 'Yes', 'No', 'OCR/0005.jpg', 238), (-0.0, 'Yes', 'No', 'landmark/images/19fe04377265454e.jpg', 242), (-0.0, 'No', 'No', 'landmark/images/19fe04377265454e.jpg', 243), (-0.0, 'Yes', 'No', 'landmark/images/00f4fb71575efb0b.jpg', 244), (-0.0, 'No', 'No', 'landmark/images/00f4fb71575efb0b.jpg', 245), (-0.0, 'Yes', 'No', 'landmark/images/083dd5a3ba3d96dc.jpg', 248), (-0.0, 'No', 'No', 'landmark/images/083dd5a3ba3d96dc.jpg', 249), (-0.0, 'No', 'No', 'landmark/images/092d0859ff6424de.jpg', 251), (-0.0, 'No', 'No', 'landmark/images/0713451824a443d4.jpg', 253), (-0.0, 'Yes', 'No', 'landmark/images/0f92862c0366ab60.jpg', 254), (-0.0, 'No', 'No', 'landmark/images/05685b1070b828f5.jpg', 257), (-0.0, 'Yes', 'No', 'landmark/images/03d5e3bfc958be38.jpg', 258), (-0.0, 'No', 'No', 'landmark/images/03d5e3bfc958be38.jpg', 259), (-0.0, 'No', 'No', 'landmark/images/06483ba2bff074bc.jpg', 263), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000022.jpg', 265), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000163.jpg', 267), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000012.jpg', 268), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000012.jpg', 269), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000011.jpg', 270), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000011.jpg', 271), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000165.jpg', 274), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000165.jpg', 275), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000072.jpg', 276), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000072.jpg', 277), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000145.jpg', 278), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000145.jpg', 279), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000197.jpg', 280), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000197.jpg', 281), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000106.jpg', 284), (-0.0, 'Yes', 'No', 'scene/images/Places365_val_00000180.jpg', 286), (-0.0, 'No', 'No', 'scene/images/Places365_val_00000180.jpg', 287), (-0.0, 'Yes', 'No', 'existence/000000494427.jpg', 288), (-0.0, 'No', 'No', 'existence/000000494427.jpg', 289), (-0.0, 'Yes', 'No', 'existence/000000015517.jpg', 290), (-0.0, 'No', 'No', 'existence/000000015517.jpg', 291), (-0.0, 'Yes', 'No', 'existence/000000530162.jpg', 294), (-0.0, 'No', 'No', 'existence/000000530162.jpg', 295), (-0.0, 'Yes', 'No', 'existence/000000061418.jpg', 296), (-0.0, 'No', 'No', 'existence/000000061418.jpg', 297), (-0.0, 'Yes', 'No', 'existence/000000424521.jpg', 298), (-0.0, 'Yes', 'No', 'existence/000000007977.jpg', 300), (-0.0, 'No', 'No', 'existence/000000007977.jpg', 301), (-0.0, 'Yes', 'No', 'existence/000000050145.jpg', 302), (-0.0, 'No', 'No', 'existence/000000050145.jpg', 303), (-0.0, 'Yes', 'No', 'existence/000000417779.jpg', 304), (-0.0, 'No', 'No', 'existence/000000417779.jpg', 305), (-0.0, 'Yes', 'No', 'existence/000000010363.jpg', 306), (-0.0, 'No', 'No', 'existence/000000010363.jpg', 307), (-0.0, 'Yes', 'No', 'existence/000000007108.jpg', 308), (-0.0, 'No', 'No', 'existence/000000007108.jpg', 309), (-0.0, 'Yes', 'No', 'existence/000000006471.jpg', 310), (-0.0, 'No', 'No', 'existence/000000006471.jpg', 311), (-0.0, 'No', 'No', 'posters/images/tt2238032.jpg', 317), (-0.0, 'Yes', 'No', 'posters/images/tt1403865.jpg', 318), (-0.0, 'No', 'No', 'posters/images/tt7131870.jpg', 321), (-0.0, 'No', 'No', 'posters/images/tt0232500.jpg', 323), (-0.0, 'No', 'No', 'posters/images/tt1560747.jpg', 329), (-0.0, 'No', 'No', 'posters/images/tt0082186.jpg', 331), (-0.0, 'No', 'No', 'posters/images/tt2908856.jpg', 333)]

Processing High-Entropy Samples:   0%|          | 0/67 [00:00<?, ?it/s]
Processing High-Entropy Samples:   1%|▏         | 1/67 [00:00<00:57,  1.15it/s]
Processing High-Entropy Samples:   3%|▎         | 2/67 [00:01<00:55,  1.18it/s]
Processing High-Entropy Samples:   4%|▍         | 3/67 [00:02<00:47,  1.34it/s]
Processing High-Entropy Samples:   6%|▌         | 4/67 [00:04<01:15,  1.21s/it]
Processing High-Entropy Samples:   7%|▋         | 5/67 [00:05<01:09,  1.12s/it]
Processing High-Entropy Samples:   9%|▉         | 6/67 [00:06<01:02,  1.02s/it]
Processing High-Entropy Samples:  10%|█         | 7/67 [00:07<01:02,  1.03s/it]
Processing High-Entropy Samples:  12%|█▏        | 8/67 [00:09<01:26,  1.47s/it]
Processing High-Entropy Samples:  13%|█▎        | 9/67 [00:09<01:07,  1.16s/it]
Processing High-Entropy Samples:  15%|█▍        | 10/67 [00:10<00:53,  1.07it/s]
Processing High-Entropy Samples:  16%|█▋        | 11/67 [00:10<00:42,  1.33it/s]
Processing High-Entropy Samples:  18%|█▊        | 12/67 [00:14<01:37,  1.76s/it]
Processing High-Entropy Samples:  19%|█▉        | 13/67 [00:20<02:46,  3.09s/it]
Processing High-Entropy Samples:  21%|██        | 14/67 [00:21<02:06,  2.39s/it]
Processing High-Entropy Samples:  22%|██▏       | 15/67 [00:22<01:44,  2.00s/it]
Processing High-Entropy Samples:  24%|██▍       | 16/67 [00:24<01:32,  1.81s/it]
Processing High-Entropy Samples:  25%|██▌       | 17/67 [00:24<01:13,  1.47s/it]
Processing High-Entropy Samples:  27%|██▋       | 18/67 [00:25<01:04,  1.32s/it]
Processing High-Entropy Samples:  28%|██▊       | 19/67 [00:28<01:26,  1.80s/it]
Processing High-Entropy Samples:  30%|██▉       | 20/67 [00:30<01:26,  1.84s/it]
Processing High-Entropy Samples:  31%|███▏      | 21/67 [00:31<01:07,  1.48s/it]
Processing High-Entropy Samples:  33%|███▎      | 22/67 [00:32<01:00,  1.34s/it]
Processing High-Entropy Samples:  34%|███▍      | 23/67 [00:32<00:48,  1.10s/it]
Processing High-Entropy Samples:  36%|███▌      | 24/67 [00:33<00:42,  1.02it/s]
Processing High-Entropy Samples:  37%|███▋      | 25/67 [00:34<00:34,  1.22it/s]
Processing High-Entropy Samples:  39%|███▉      | 26/67 [00:34<00:31,  1.32it/s]
Processing High-Entropy Samples:  40%|████      | 27/67 [00:37<00:52,  1.30s/it]
Processing High-Entropy Samples:  42%|████▏     | 28/67 [00:40<01:15,  1.95s/it]
Processing High-Entropy Samples:  43%|████▎     | 29/67 [00:43<01:25,  2.25s/it]
Processing High-Entropy Samples:  45%|████▍     | 30/67 [00:46<01:29,  2.41s/it]
Processing High-Entropy Samples:  46%|████▋     | 31/67 [00:49<01:30,  2.52s/it]
Processing High-Entropy Samples:  48%|████▊     | 32/67 [00:52<01:32,  2.65s/it]
Processing High-Entropy Samples:  49%|████▉     | 33/67 [00:53<01:19,  2.34s/it]
Processing High-Entropy Samples:  51%|█████     | 34/67 [00:54<01:03,  1.92s/it]
Processing High-Entropy Samples:  52%|█████▏    | 35/67 [00:55<00:52,  1.63s/it]
Processing High-Entropy Samples:  54%|█████▎    | 36/67 [00:56<00:41,  1.33s/it]
Processing High-Entropy Samples:  55%|█████▌    | 37/67 [00:57<00:38,  1.28s/it]idx: 8
question_id: code_reasoning/0003.png
q: The image shows a python code. Is the output of the code '12'?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 13
question_id: code_reasoning/0015.png
q: The image shows a python code. Is the output of the code '9'?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 21
question_id: code_reasoning/0002.png
q: The image shows a python code. Is the output of the code 'a dog'?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 35
question_id: artwork/images/10881.jpg
q: Does this artwork exist in the form of tapestry?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 68
question_id: celebrity/images/tt0116629_shot_1570_img_2.jpg
q: Is the person inside the red bounding box called Will Smith?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 79
question_id: numerical_calculation/0009.png
q: Should the value of "a" in the picture equal 3?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: No
idx: 95
question_id: numerical_calculation/0005.png
q: Is the area of the square in the picture equal to 8?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 106
question_id: text_translation/0007.png
q: Is it appropriate to translate the Chinese in the image into English 'walking very slowly' in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 111
question_id: text_translation/0019.png
q: Is it appropriate to translate the Chinese in the image into English 'for own self-interest' in the picture?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 118
question_id: text_translation/0005.png
q: Is it appropriate to translate the Chinese in the image into English 'feeling happy' in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 119
question_id: text_translation/0005.png
q: Is it appropriate to translate the Chinese in the image into English 'feeling bored' in the picture?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 170
question_id: commonsense_reasoning/0024.png
q: I want to go skating. Is the shoe in the picture usually appropriate?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 176
question_id: commonsense_reasoning/0036.png
q: Is it a good time to walk through the road in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 203
question_id: position/000000426241.jpg
q: Is the white mouse on the left of the black keyboard?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 209
question_id: position/000000006471.jpg
q: Is the cricket bat under the batter's body
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 229
question_id: OCR/0015.jpg
q: Is the text in the picture "holly word"?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 233
question_id: OCR/0017.jpg
q: Is the word in the logo "hardto industal construction"?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 235
question_id: OCR/0012.jpg
q: Is the word in the logo "case grecque restaurants"?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: No
idx: 325
question_id: posters/images/tt5688868.jpg
q: Is this movie titled the neon demon (2016)?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 328
question_id: posters/images/tt1560747.jpg
q: Is this movie originated from the country or region of usa?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 2
question_id: code_reasoning/0014.png
q: The image shows a python code. Is the output of the code '7'?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: Yes
idx: 4
question_id: code_reasoning/0013.png
q: The image shows a python code. Is the output of the code 'a cat'?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 9
question_id: code_reasoning/0003.png
q: The image shows a python code. Is the output of the code '5'?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 12
question_id: code_reasoning/0015.png
q: The image shows a python code. Is the output of the code '11'?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 17
question_id: code_reasoning/0017.png
q: The image shows a python code. Will the number 6 appear in the output of the code?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 20
question_id: code_reasoning/0002.png
q: The image shows a python code. Is the output of the code 'a cat'?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 26
question_id: artwork/images/24291.jpg
q: Is this artwork titled virgin and child with sts catherine, cecilia, barbara, and ursula?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 30
question_id: artwork/images/38740.jpg
q: Is this artwork displayed in musée toulouse-lautrec, albi?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 37
question_id: artwork/images/13288.jpg
q: Does this artwork exist in the form of metalwork?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 40
question_id: artwork/images/9405.jpg
q: Is this artwork created by courbet, gustave?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 41
question_id: artwork/images/9405.jpg
q: Is this artwork created by milani, aureliano?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 51
question_id: celebrity/images/tt0061722_shot_0259_img_0.jpg
q: Is the actor inside the red bounding box called Christopher Olsen?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 52
question_id: celebrity/images/tt0064665_shot_0300_img_0.jpg
q: Is the actor inside the red bounding box called Jon Voight?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 57
question_id: celebrity/images/tt0070511_shot_0639_img_0.jpg
q: Is the person inside the red bounding box called Fernando Lueches?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: No
idx: 61
question_id: celebrity/images/tt0111280_shot_1479_img_2.jpg
q: Is the actor inside the red bounding box called Richard Rohrbough?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 62
question_id: celebrity/images/tt0107614_shot_0116_img_0.jpg
q: Is the person inside the red bounding box called Sally Field?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 64
question_id: celebrity/images/tt0072684_shot_0512_img_1.jpg
q: Is the person inside the red bounding box named Marisa Berenson?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 74
question_id: numerical_calculation/0014.png

Processing High-Entropy Samples:  57%|█████▋    | 38/67 [00:58<00:37,  1.28s/it]
Processing High-Entropy Samples:  58%|█████▊    | 39/67 [00:59<00:32,  1.17s/it]
Processing High-Entropy Samples:  60%|█████▉    | 40/67 [01:00<00:29,  1.10s/it]
Processing High-Entropy Samples:  61%|██████    | 41/67 [01:01<00:25,  1.01it/s]
Processing High-Entropy Samples:  63%|██████▎   | 42/67 [01:02<00:24,  1.01it/s]
Processing High-Entropy Samples:  64%|██████▍   | 43/67 [01:03<00:22,  1.08it/s]
Processing High-Entropy Samples:  66%|██████▌   | 44/67 [01:04<00:21,  1.06it/s]
Processing High-Entropy Samples:  67%|██████▋   | 45/67 [01:04<00:16,  1.31it/s]
Processing High-Entropy Samples:  69%|██████▊   | 46/67 [01:04<00:14,  1.47it/s]
Processing High-Entropy Samples:  70%|███████   | 47/67 [01:05<00:11,  1.69it/s]
Processing High-Entropy Samples:  72%|███████▏  | 48/67 [01:05<00:10,  1.89it/s]
Processing High-Entropy Samples:  73%|███████▎  | 49/67 [01:06<00:08,  2.00it/s]
Processing High-Entropy Samples:  75%|███████▍  | 50/67 [01:06<00:09,  1.83it/s]
Processing High-Entropy Samples:  76%|███████▌  | 51/67 [01:07<00:07,  2.05it/s]
Processing High-Entropy Samples:  78%|███████▊  | 52/67 [01:07<00:06,  2.26it/s]
Processing High-Entropy Samples:  79%|███████▉  | 53/67 [01:08<00:08,  1.63it/s]
Processing High-Entropy Samples:  81%|████████  | 54/67 [01:09<00:11,  1.13it/s]
Processing High-Entropy Samples:  82%|████████▏ | 55/67 [01:10<00:10,  1.15it/s]
Processing High-Entropy Samples:  84%|████████▎ | 56/67 [01:12<00:11,  1.05s/it]
Processing High-Entropy Samples:  85%|████████▌ | 57/67 [01:13<00:11,  1.19s/it]
Processing High-Entropy Samples:  87%|████████▋ | 58/67 [01:16<00:13,  1.54s/it]
Processing High-Entropy Samples:  88%|████████▊ | 59/67 [01:19<00:17,  2.20s/it]
Processing High-Entropy Samples:  90%|████████▉ | 60/67 [01:20<00:12,  1.84s/it]
Processing High-Entropy Samples:  91%|█████████ | 61/67 [01:23<00:11,  1.97s/it]
Processing High-Entropy Samples:  93%|█████████▎| 62/67 [01:23<00:07,  1.59s/it]
Processing High-Entropy Samples:  94%|█████████▍| 63/67 [01:25<00:05,  1.49s/it]
Processing High-Entropy Samples:  96%|█████████▌| 64/67 [01:27<00:04,  1.64s/it]
Processing High-Entropy Samples:  97%|█████████▋| 65/67 [01:28<00:03,  1.56s/it]
Processing High-Entropy Samples:  99%|█████████▊| 66/67 [01:28<00:01,  1.21s/it]
Processing High-Entropy Samples: 100%|██████████| 67/67 [01:29<00:00,  1.04it/s]
Processing High-Entropy Samples: 100%|██████████| 67/67 [01:29<00:00,  1.33s/it]
q: Is the answer to the arithmetic question in the image 200?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 75
question_id: numerical_calculation/0014.png
q: Is the answer to the arithmetic question in the image 400?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: No
idx: 80
question_id: numerical_calculation/0003.png
q: Is the answer to the arithmetic question in the image 65?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 81
question_id: numerical_calculation/0003.png
q: Is the answer to the arithmetic question in the image 56?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: No
idx: 83
question_id: numerical_calculation/0007.png
q: Is the answer to the arithmetic question in the image 39?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: No
idx: 86
question_id: numerical_calculation/0019.png
q: Is the answer to the arithmetic question in the image 18?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 93
question_id: numerical_calculation/0002.png
q: Is the answer to the arithmetic question in the image 17?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 96
question_id: text_translation/0020.png
q: Is it appropriate to translate the Chinese in the image into English 'rank first' in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 99
question_id: text_translation/0014.png
q: Is it appropriate to translate the Chinese in the image into English 'sleeping for a long time' in the picture?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 100
question_id: text_translation/0013.png
q: Is it appropriate to translate the Chinese in the image into English 'feeling frustrated' in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 102
question_id: text_translation/0009.png
q: Is it appropriate to translate the Chinese in the image into English 'creative people' in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 103
question_id: text_translation/0009.png
q: Is it appropriate to translate the Chinese in the image into English 'leading people' in the picture?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 110
question_id: text_translation/0019.png
q: Is it appropriate to translate the Chinese in the image into English 'get along well' in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 115
question_id: text_translation/0012.png
q: Is it appropriate to translate the Chinese in the image into English 'difficult and dangerous' in the picture?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 116
question_id: text_translation/0002.png
q: Is it appropriate to translate the Chinese in the image into English 'a delicious dinner' in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 120
question_id: count/000000470121.jpg
q: Is there only one bottle in the image?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
idx: 135
question_id: count/000000372819.jpg
q: Are there only three dogs appear in this image?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: No
idx: 139
question_id: count/000000410612.jpg
q: Is there a total of two ships in the picture?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 145
question_id: color/000000338560.jpg
q: Is there a blue and orange fire hydrant in the image?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 161
question_id: color/000000442456.jpg
q: Is there a man wearing a white shirt in the image?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 175
question_id: commonsense_reasoning/0029.png
q: The three cats in the picture, the one without a beard, is the right one?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 186
question_id: commonsense_reasoning/0013.png
q: I am going to a formal dinner party. Is the shoe in the picture an appropriate choice?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 217
question_id: OCR/0020.jpg
q: Is the word in the logo "cold rinks"?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 227
question_id: OCR/0007.jpg
q: Is the phone number in the picture "0137 556 6363"?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: No
label: No
idx: 232
question_id: OCR/0017.jpg
q: Is the word in the logo "hardco industrial construction"?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 237
question_id: OCR/0002.jpg
q: Is the word in the logo "crest cheese"?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: No
idx: 316
question_id: posters/images/tt2238032.jpg
q: Is this movie titled skiptrace (2016)?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 324
question_id: posters/images/tt5688868.jpg
q: Is this movie titled primal rage: the legend of konga (2018)?
Answer the question using a single word or phrase.
doubao_response: no
original_pred: Yes
label: Yes
idx: 0
question_id: code_reasoning/0020.png
q: Is a python code shown in the picture?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: No
label: Yes
idx: 6
question_id: code_reasoning/0009.png
q: The image shows a python code. Is the output of the code '36'?
Answer the question using a single word or phrase.
doubao_response: yes
original_pred: Yes
label: Yes
-------------------------------------------------------------
new_entropy_list: [0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.5004024235381879, 0.6931471805599453, 0.6730116670092565, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, -0.0, 0.6730116670092565, 0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.6931471805599453, 0.6108643020548934, 0.5004024235381879, -0.0, -0.0, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, 0.6730116670092565, 0.6108643020548934, -0.0, 0.6108643020548934, -0.0, 0.6931471805599453, -0.0, 0.6730116670092565, -0.0, -0.0, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, 0.6108643020548934, -0.0, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, 0.6730116670092565, 0.6730116670092565, -0.0, 0.6730116670092565, -0.0, 0.3250829733914482, -0.0, 0.6931471805599453, -0.0, 0.3250829733914482, 0.3250829733914482, -0.0, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.3250829733914482, 0.6931471805599453, 0.6730116670092565, 0.6730116670092565, 0.6108643020548934, 0.6730116670092565, 0.6108643020548934, 0.6108643020548934, 0.6730116670092565, 0.3250829733914482, 0.3250829733914482, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6730116670092565, 0.6108643020548934, 0.6931471805599453, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.5004024235381879, 0.6931471805599453, 0.5004024235381879, 0.5004024235381879, 0.6108643020548934, 0.6730116670092565, 0.6931471805599453, 0.6108643020548934, -0.0, 0.6108643020548934, 0.6730116670092565, 0.6730116670092565, 0.5004024235381879, 0.6931471805599453, 0.6931471805599453, 0.6730116670092565, 0.6108643020548934, 0.3250829733914482, 0.3250829733914482, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, 0.6108643020548934, 0.3250829733914482, -0.0, 0.3250829733914482, 0.6108643020548934, 0.3250829733914482, 0.6108643020548934, 0.6730116670092565, 0.5004024235381879, 0.6108643020548934, 0.5004024235381879, 0.6730116670092565, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, -0.0, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, -0.0, -0.0, -0.0, 0.6730116670092565, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, 0.6108643020548934, -0.0, 0.6730116670092565, 0.6931471805599453, 0.3250829733914482, 0.6108643020548934, 0.5004024235381879, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, -0.0, 0.6108643020548934, 0.6108643020548934, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6931471805599453, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.6931471805599453, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, 0.6730116670092565, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, 0.3250829733914482, 0.5004024235381879, 0.3250829733914482, 0.6108643020548934, 0.6730116670092565, -0.0, 0.6931471805599453, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, 0.6931471805599453, 0.5004024235381879, 0.6931471805599453, -0.0, 0.6730116670092565, -0.0, 0.5004024235381879, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.6108643020548934, -0.0, -0.0, 0.5004024235381879, -0.0, 0.5004024235381879, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, 0.3250829733914482, -0.0, 0.3250829733914482, -0.0, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, 0.5004024235381879, 0.3250829733914482, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.3250829733914482, -0.0, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.3250829733914482, 0.5004024235381879, -0.0, -0.0, -0.0, -0.0, -0.0, 0.6108643020548934, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.5004024235381879, 0.5004024235381879, 0.3250829733914482, 0.3250829733914482, 0.6730116670092565, -0.0, -0.0, 0.5004024235381879, 0.6108643020548934, -0.0, 0.5004024235381879, -0.0, 0.6730116670092565, 0.6931471805599453, 0.5004024235381879, 0.6108643020548934, 0.6931471805599453, -0.0, 0.3250829733914482, -0.0, 0.6108643020548934, -0.0, 0.3250829733914482, -0.0]
validation_is_false: [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]
new_check_is_false: [0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]
aurac of cluster_assignment_entropy: 0.4944237918215613
aurac of semantic_entropy_rao_check: 0.4944237918215613
位置下标：0, list1的元素：1, list2的元素：0
位置下标：2, list1的元素：0, list2的元素：1
位置下标：9, list1的元素：1, list2的元素：0
位置下标：13, list1的元素：1, list2的元素：0
位置下标：17, list1的元素：1, list2的元素：0
位置下标：21, list1的元素：1, list2的元素：0
位置下标：35, list1的元素：1, list2的元素：0
位置下标：40, list1的元素：1, list2的元素：0
位置下标：51, list1的元素：1, list2的元素：0
位置下标：57, list1的元素：0, list2的元素：1
位置下标：62, list1的元素：1, list2的元素：0
位置下标：64, list1的元素：1, list2的元素：0
位置下标：68, list1的元素：1, list2的元素：0
位置下标：74, list1的元素：1, list2的元素：0
位置下标：75, list1的元素：0, list2的元素：1
位置下标：79, list1的元素：0, list2的元素：1
位置下标：80, list1的元素：1, list2的元素：0
位置下标：81, list1的元素：0, list2的元素：1
位置下标：95, list1的元素：1, list2的元素：0
位置下标：96, list1的元素：1, list2的元素：0
位置下标：100, list1的元素：1, list2的元素：0
位置下标：102, list1的元素：1, list2的元素：0
位置下标：106, list1的元素：1, list2的元素：0
位置下标：110, list1的元素：1, list2的元素：0
位置下标：115, list1的元素：1, list2的元素：0
位置下标：116, list1的元素：1, list2的元素：0
位置下标：118, list1的元素：1, list2的元素：0
位置下标：135, list1的元素：0, list2的元素：1
位置下标：176, list1的元素：1, list2的元素：0
位置下标：186, list1的元素：1, list2的元素：0
位置下标：203, list1的元素：1, list2的元素：0
位置下标：232, list1的元素：1, list2的元素：0
位置下标：237, list1的元素：1, list2的元素：0
位置下标：316, list1的元素：1, list2的元素：0
位置下标：324, list1的元素：0, list2的元素：1
位置下标：325, list1的元素：1, list2的元素：0
位置下标：328, list1的元素：1, list2的元素：0

统计结果：
均为0的数量：161
均为1的数量：138
list1为0且list2为1的数量：7
list1为1且list2为0的数量：30
原始准确率：0.5
修正后准确率：0.5684523809523809
Saving calculation data to ./playground/data/eval/pope/answers/calc_values.pkl
Results saved to:
- ./playground/data/eval/MME/answers/llava-v1.5-7b.jsonl
- ./playground/data/eval/MME/answers/detailed_results.json

=========== Perception ===========
total score: 1521.25 

	 existence  score: 186.66666666666669
	 count  score: 136.25
	 position  score: 157.91666666666669
	 color  score: 185.41666666666666
	 posters  score: 120.41666666666666
	 celebrity  score: 145.83333333333331
	 scene  score: 177.08333333333334
	 landmark  score: 160.0
	 artwork  score: 122.5
	 OCR  score: 129.16666666666666


=========== Cognition ===========
total score: 349.5833333333333 

	 commonsense_reasoning  score: 127.08333333333334
	 numerical_calculation  score: 58.33333333333333
	 text_translation  score: 82.08333333333333
	 code_reasoning  score: 82.08333333333333


